<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-927edb3cde42616945691bbf0360b549.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.30">

  <meta name="author" content="Prof.&nbsp;Dr.&nbsp;Philipp Pelz">
  <title>ECLIPSE Presentations – Data Science for Electron Microscopy  Lecture 2: Optimization, Regression, Sensor Fusion</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #97947a;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #97947a;  padding-left: 4px; }
    div.sourceCode
      { color: #f8f8f2; background-color: #2b2b2b; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #f8f8f2; } /* Normal */
    code span.al { color: #dcc6e0; } /* Alert */
    code span.an { color: #d4d0ab; } /* Annotation */
    code span.at { color: #ffd700; } /* Attribute */
    code span.bn { color: #dcc6e0; } /* BaseN */
    code span.bu { color: #f5ab35; } /* BuiltIn */
    code span.cf { color: #ffa07a; } /* ControlFlow */
    code span.ch { color: #abe338; } /* Char */
    code span.cn { color: #ffa07a; } /* Constant */
    code span.co { color: #d4d0ab; } /* Comment */
    code span.cv { color: #d4d0ab; font-style: italic; } /* CommentVar */
    code span.do { color: #d4d0ab; font-style: italic; } /* Documentation */
    code span.dt { color: #dcc6e0; } /* DataType */
    code span.dv { color: #dcc6e0; } /* DecVal */
    code span.er { color: #dcc6e0; } /* Error */
    code span.ex { color: #ffd700; } /* Extension */
    code span.fl { color: #f5ab35; } /* Float */
    code span.fu { color: #ffd700; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #d4d0ab; } /* Information */
    code span.kw { color: #ffa07a; } /* Keyword */
    code span.op { color: #00e0e0; } /* Operator */
    code span.ot { color: #ffa07a; } /* Other */
    code span.pp { color: #dcc6e0; } /* Preprocessor */
    code span.sc { color: #00e0e0; } /* SpecialChar */
    code span.ss { color: #abe338; } /* SpecialString */
    code span.st { color: #abe338; } /* String */
    code span.va { color: #f5ab35; } /* Variable */
    code span.vs { color: #abe338; } /* VerbatimString */
    code span.wa { color: #d4d0ab; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-ce804447b3af982f2c55816970ecc9a3.css">
  <link rel="stylesheet" href="custom.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
  <script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
    <h1 class="title"><p>Data Science for Electron Microscopy<br> Lecture 2: Optimization, Regression, Sensor Fusion</p></h1>
    
  <div class="quarto-title-authors">
    <div class="quarto-title-author">
  <div class="quarto-title-author-name">
  Prof.&nbsp;Dr.&nbsp;Philipp Pelz 
  </div>
                <p class="quarto-title-affiliation">
                FAU Erlangen-Nürnberg
              </p>
            <p class="quarto-title-affiliation">
                Institute of Micro- and Nanostructure Research
              </p>
          </div>
    </div>
  
    <div class="footer-logos1">
    <img src="logos/FAU.png" alt="FAU Logo" width="20%">
    <img src="logos/imn.png" alt="IMN Logo" width="20%">
    <img src="logos/cenem.png" alt="CENEM Logo" width="20%">
    <img src="logos/erc.jpg" alt="Elettra Logo" width="20%">
  </div>
  </section>
<section class="slide level2">

<!-- ## Outline

::: {.outline-container}

::: {.outline-box .fragment}
### Formalities
![](02_imaging.png) 
:::

::: {.outline-box .fragment}
### Introduction <br>to<br> Electron<br> Microscopy<br> Data
![](02_imaging.png)
:::

::: {.outline-box .fragment}
### Basic Pytorch<br> Knowledge
![](02_imaging.png)
:::

::: {.outline-box .fragment}
### .
![](02_imaging.png)  
:::-->
<!-- ---
title: "Optimization and Deep Learning"
format: 
  revealjs:
    theme: custom.scss
    css: custom.css
    width: 1920
    height: 1080
    menu:
      side: right
      width: wide
    template-partials:
      - title-slide.html
    slide-number: c/t
    logo: "eclipse_logo_small.png"
    highlight-style: a11y
    incremental: false
    background-transition: fade
    footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy"
execute:
  eval: true
  echo: true
--- -->
</section>
<section>
<section id="optimization-and-deep-learning" class="title-slide slide level1 center">
<h1>Optimization and Deep Learning</h1>
<ul>
<li>Optimization and deep learning are closely related</li>
<li>Deep learning typically involves:
<ul>
<li>Defining a loss function</li>
<li>Using optimization to minimize the loss</li>
</ul></li>
<li>Note: Most optimization algorithms minimize by convention
<ul>
<li>To maximize: simply flip the sign of the objective</li>
</ul></li>
</ul>
</section>
<section id="goals-of-optimization-vs-deep-learning" class="slide level2">
<h2>Goals of Optimization vs Deep Learning</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="optimization">Optimization</h3>
<ul>
<li>Primary goal: Minimize objective function</li>
<li>Focus on training error</li>
<li>Direct mathematical approach</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="deep-learning">Deep Learning</h3>
<ul>
<li>Primary goal: Find suitable model</li>
<li>Focus on generalization error</li>
<li>Must handle finite data</li>
<li>Must prevent overfitting</li>
</ul>
</div></div>
</section>
<section id="visualizing-the-difference" class="slide level2">
<h2>Visualizing the Difference</h2>
<p>Let’s examine empirical risk vs.&nbsp;risk:</p>
<div id="cell-setup3" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-2"><a></a><span class="im">import</span> d2l</span>
<span id="cb1-3"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a></a><span class="im">from</span> mpl_toolkits <span class="im">import</span> mplot3d</span>
<span id="cb1-5"><a></a><span class="im">import</span> torch</span>
<span id="cb1-6"><a></a></span>
<span id="cb1-7"><a></a><span class="kw">def</span> f(x):</span>
<span id="cb1-8"><a></a>    <span class="cf">return</span> x <span class="op">*</span> d2l.cos(np.pi <span class="op">*</span> x)</span>
<span id="cb1-9"><a></a></span>
<span id="cb1-10"><a></a><span class="kw">def</span> g(x):</span>
<span id="cb1-11"><a></a>    <span class="cf">return</span> f(x) <span class="op">+</span> <span class="fl">0.2</span> <span class="op">*</span> d2l.cos(<span class="dv">5</span> <span class="op">*</span> np.pi <span class="op">*</span> x)</span>
<span id="cb1-12"><a></a></span>
<span id="cb1-13"><a></a><span class="kw">def</span> annotate(text, xy, xytext):</span>
<span id="cb1-14"><a></a>    d2l.plt.gca().annotate(text, xy<span class="op">=</span>xy, xytext<span class="op">=</span>xytext,</span>
<span id="cb1-15"><a></a>                           arrowprops<span class="op">=</span><span class="bu">dict</span>(arrowstyle<span class="op">=</span><span class="st">'-&gt;'</span>))</span>
<span id="cb1-16"><a></a></span>
<span id="cb1-17"><a></a>x <span class="op">=</span> d2l.arange(<span class="fl">0.5</span>, <span class="fl">1.5</span>, <span class="fl">0.01</span>)</span>
<span id="cb1-18"><a></a>d2l.set_figsize((<span class="fl">4.5</span>, <span class="fl">2.5</span>))</span>
<span id="cb1-19"><a></a>d2l.plot(x, [f(x), g(x)], <span class="st">'x'</span>, <span class="st">'risk'</span>)</span>
<span id="cb1-20"><a></a>annotate(<span class="st">'min of</span><span class="ch">\n</span><span class="st">empirical risk'</span>, (<span class="fl">1.0</span>, <span class="op">-</span><span class="fl">1.2</span>), (<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">1.1</span>))</span>
<span id="cb1-21"><a></a>annotate(<span class="st">'min of risk'</span>, (<span class="fl">1.1</span>, <span class="op">-</span><span class="fl">1.05</span>), (<span class="fl">0.95</span>, <span class="op">-</span><span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="template_files/figure-revealjs/setup3-output-1.svg" id="setup3" class="r-stretch"></section>
<section id="key-challenges-in-deep-learning-optimization" class="slide level2">
<h2>Key Challenges in Deep Learning Optimization</h2>
<ol type="1">
<li>Local Minima</li>
<li>Saddle Points</li>
<li>Vanishing Gradients</li>
</ol>
</section>
<section id="local-minima" class="slide level2">
<h2>Local Minima</h2>
<ul>
<li>Definition: Point where function value is smaller than nearby points</li>
<li>Global minimum: Smallest value over entire domain</li>
<li>Example function: <span class="math inline">\(f(x) = x \cdot \textrm{cos}(\pi x)\)</span></li>
</ul>
<div id="cell-local-minima1" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>x <span class="op">=</span> d2l.arange(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">0.01</span>)</span>
<span id="cb2-2"><a></a>d2l.plot(x, [f(x), ], <span class="st">'x'</span>, <span class="st">'f(x)'</span>)</span>
<span id="cb2-3"><a></a>annotate(<span class="st">'local minimum'</span>, (<span class="op">-</span><span class="fl">0.3</span>, <span class="op">-</span><span class="fl">0.25</span>), (<span class="op">-</span><span class="fl">0.77</span>, <span class="op">-</span><span class="fl">1.0</span>))</span>
<span id="cb2-4"><a></a>annotate(<span class="st">'global minimum'</span>, (<span class="fl">1.1</span>, <span class="op">-</span><span class="fl">0.95</span>), (<span class="fl">0.6</span>, <span class="fl">0.8</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="template_files/figure-revealjs/local-minima1-output-1.svg" id="local-minima1" class="r-stretch"></section>
<section id="impact-of-local-minima" class="slide level2">
<h2>Impact of Local Minima</h2>
<ul>
<li>Deep learning models often have many local optima</li>
<li>Gradient approaches zero near local minimum</li>
<li>Minibatch SGD can help escape local minima
<ul>
<li>Natural gradient variation provides “noise”</li>
<li>Can dislodge parameters from local minima</li>
</ul></li>
</ul>
</section>
<section id="saddle-points" class="slide level2">
<h2>Saddle Points</h2>
<ul>
<li>Characteristics:
<ul>
<li>All gradients vanish</li>
<li>Neither global nor local minimum</li>
</ul></li>
<li>Example: <span class="math inline">\(f(x) = x^3\)</span>
<ul>
<li>First and second derivatives vanish at <span class="math inline">\(x=0\)</span></li>
<li>Optimization can stall here</li>
</ul></li>
</ul>
<div id="cell-saddle-points" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a>x <span class="op">=</span> d2l.arange(<span class="op">-</span><span class="fl">2.0</span>, <span class="fl">2.0</span>, <span class="fl">0.01</span>)</span>
<span id="cb3-2"><a></a>d2l.plot(x, [x<span class="op">**</span><span class="dv">3</span>], <span class="st">'x'</span>, <span class="st">'f(x)'</span>)</span>
<span id="cb3-3"><a></a>annotate(<span class="st">'saddle point'</span>, (<span class="dv">0</span>, <span class="op">-</span><span class="fl">0.2</span>), (<span class="op">-</span><span class="fl">0.52</span>, <span class="op">-</span><span class="fl">5.0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="template_files/figure-revealjs/saddle-points-output-1.svg" id="saddle-points" class="r-stretch"></section>
<section id="higher-dimensional-saddle-points" class="slide level2">
<h2>Higher-Dimensional Saddle Points</h2>
<ul>
<li>More complex in higher dimensions</li>
<li>Example: <span class="math inline">\(f(x,y) = x^2 - y^2\)</span></li>
<li>Has saddle point at <span class="math inline">\((0,0)\)</span>
<ul>
<li>Maximum with respect to <span class="math inline">\(y\)</span></li>
<li>Minimum with respect to <span class="math inline">\(x\)</span></li>
</ul></li>
</ul>
<div id="d-saddle" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>x, y <span class="op">=</span> d2l.meshgrid(</span>
<span id="cb4-2"><a></a>    d2l.linspace(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">1.0</span>, <span class="dv">101</span>), d2l.linspace(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">1.0</span>, <span class="dv">101</span>))</span>
<span id="cb4-3"><a></a>z <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> y<span class="op">**</span><span class="dv">2</span></span>
<span id="cb4-4"><a></a></span>
<span id="cb4-5"><a></a>ax <span class="op">=</span> d2l.plt.figure().add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb4-6"><a></a>ax.plot_wireframe(x, y, z, <span class="op">**</span>{<span class="st">'rstride'</span>: <span class="dv">10</span>, <span class="st">'cstride'</span>: <span class="dv">10</span>})</span>
<span id="cb4-7"><a></a>ax.plot([<span class="dv">0</span>], [<span class="dv">0</span>], [<span class="dv">0</span>], <span class="st">'rx'</span>)</span>
<span id="cb4-8"><a></a>ticks <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb4-9"><a></a>d2l.plt.xticks(ticks)</span>
<span id="cb4-10"><a></a>d2l.plt.yticks(ticks)</span>
<span id="cb4-11"><a></a>ax.set_zticks(ticks)</span>
<span id="cb4-12"><a></a>d2l.plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb4-13"><a></a>d2l.plt.ylabel(<span class="st">'y'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="d-saddle-1" class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Text(0.5, 0.5, 'y')</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/d-saddle-output-2.svg" id="d-saddle-2" class="r-stretch"></section>
<section id="hessian-matrix-analysis" class="slide level2">
<h2>Hessian Matrix Analysis</h2>
<p>For a <span class="math inline">\(k\)</span>-dimensional input vector:</p>
<ul>
<li>All positive eigenvalues → Local minimum</li>
<li>All negative eigenvalues → Local maximum</li>
<li>Mixed signs → Saddle point</li>
</ul>
</section>
<section id="vanishing-gradients" class="slide level2">
<h2>Vanishing Gradients</h2>
<ul>
<li>Most insidious optimization problem</li>
<li>Example: <span class="math inline">\(f(x) = \tanh(x)\)</span>
<ul>
<li>At <span class="math inline">\(x = 4\)</span>: gradient ≈ 0.0013</li>
<li>Optimization stalls</li>
</ul></li>
<li>Historical context:
<ul>
<li>Major challenge before ReLU activation</li>
<li>Made deep learning training difficult</li>
</ul></li>
</ul>
<div id="cell-vanishing-gradients" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a>x <span class="op">=</span> d2l.arange(<span class="op">-</span><span class="fl">2.0</span>, <span class="fl">5.0</span>, <span class="fl">0.01</span>)</span>
<span id="cb6-2"><a></a>d2l.plot(x, [d2l.tanh(x)], <span class="st">'x'</span>, <span class="st">'f(x)'</span>)</span>
<span id="cb6-3"><a></a>annotate(<span class="st">'vanishing gradient'</span>, (<span class="dv">4</span>, <span class="dv">1</span>), (<span class="dv">2</span>, <span class="fl">0.0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="template_files/figure-revealjs/vanishing-gradients-output-1.svg" id="vanishing-gradients" class="r-stretch"></section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Key takeaways:
<ul>
<li>Training error minimization ≠ best generalization</li>
<li>Many local minima exist</li>
<li>Saddle points are common in non-convex problems</li>
<li>Vanishing gradients can stall optimization</li>
</ul></li>
<li>Good news:
<ul>
<li>Robust algorithms exist</li>
<li>Perfect solutions not always necessary</li>
<li>Local optima can be useful</li>
<li>Many practical solutions available</li>
</ul></li>
</ul>
</section>
<section id="exercises" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li><p>Consider a simple MLP with a single hidden layer of <span class="math inline">\(d\)</span> dimensions:</p>
<ul>
<li>Show that for any local minimum there are at least <span class="math inline">\(d!\)</span> equivalent solutions</li>
<li>Why does this happen?</li>
</ul></li>
<li><p>For a symmetric random matrix <span class="math inline">\(\mathbf{M}\)</span>:</p>
<ul>
<li>Prove that eigenvalue distribution is symmetric</li>
<li>Why doesn’t this imply <span class="math inline">\(P(\lambda &gt; 0) = 0.5\)</span>?</li>
</ul></li>
<li><p>Additional challenges in deep learning optimization?</p></li>
<li><p>Balancing a ball on a saddle:</p>
<ul>
<li>Why is this hard?</li>
<li>How might this relate to optimization algorithms?</li>
</ul></li>
</ol>
<!-- ---
title: "Convexity"
format: 
  revealjs:
    theme: custom.scss
    css: custom.css
    width: 1920
    height: 1080
    menu:
      side: right
      width: wide
    template-partials:
      - title-slide.html
    slide-number: c/t
    logo: "eclipse_logo_small.png"
    highlight-style: a11y
    incremental: false
    background-transition: fade
    footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy"
execute:
  eval: true
  echo: true
--- -->
</section></section>
<section>
<section id="convexity" class="title-slide slide level1 center">
<h1>Convexity</h1>
<ul>
<li>Convexity is crucial for optimization algorithm design</li>
<li>Benefits:
<ul>
<li>Easier algorithm analysis and testing</li>
<li>Better understanding of deep learning optimization</li>
<li>Properties near local minima often resemble convex functions</li>
</ul></li>
<li>Even nonconvex problems can benefit from convex analysis</li>
</ul>
<div id="setup1" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a><span class="op">%</span>matplotlib inline</span>
<span id="cb7-2"><a></a><span class="im">import</span> d2l</span>
<span id="cb7-3"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-4"><a></a><span class="im">from</span> mpl_toolkits <span class="im">import</span> mplot3d</span>
<span id="cb7-5"><a></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="definitions" class="slide level2">
<h2>Definitions</h2>
<h3 id="convex-sets">Convex Sets</h3>
<ul>
<li>A set <span class="math inline">\(\mathcal{X}\)</span> is convex if:
<ul>
<li>For any <span class="math inline">\(a, b \in \mathcal{X}\)</span></li>
<li>Line segment connecting <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> is in <span class="math inline">\(\mathcal{X}\)</span></li>
</ul></li>
<li>Mathematical definition: <span class="math display">\[\lambda a + (1-\lambda) b \in \mathcal{X} \textrm{ whenever } a, b \in \mathcal{X}\]</span> for all <span class="math inline">\(\lambda \in [0, 1]\)</span></li>
</ul>
<h3 id="visual-examples">Visual Examples</h3>

<img data-src="./img/pacman.svg" class="r-stretch quarto-figure-center"><p class="caption">The first set is nonconvex and the other two are convex.</p></section>
<section class="slide level2">

<h3 id="set-operations">Set Operations</h3>
<ul>
<li>Intersections of convex sets are convex</li>
<li>Unions of convex sets need not be convex</li>
<li>Example: <span class="math inline">\(\mathbb{R}^d\)</span> is convex</li>
<li>Bounded sets (e.g., balls) are often convex</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/convex-intersect.svg"></p>
<figcaption>The intersection between two convex sets is convex.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/nonconvex.svg"></p>
<figcaption>The union of two convex sets need not be convex.</figcaption>
</figure>
</div>
</section>
<section id="convex-functions" class="slide level2">
<h2>Convex Functions</h2>
<h3 id="definition">Definition</h3>
<ul>
<li>Function <span class="math inline">\(f: \mathcal{X} \to \mathbb{R}\)</span> is convex if:
<ul>
<li>For all <span class="math inline">\(x, x' \in \mathcal{X}\)</span></li>
<li>For all <span class="math inline">\(\lambda \in [0, 1]\)</span></li>
<li>Satisfies: <span class="math inline">\(\lambda f(x) + (1-\lambda) f(x') \geq f(\lambda x + (1-\lambda) x')\)</span></li>
</ul></li>
</ul>
<h3 id="examples">Examples</h3>
<div id="cell-function-examples" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>f <span class="op">=</span> <span class="kw">lambda</span> x: <span class="fl">0.5</span> <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span>  <span class="co"># Convex</span></span>
<span id="cb8-2"><a></a>g <span class="op">=</span> <span class="kw">lambda</span> x: d2l.cos(np.pi <span class="op">*</span> x)  <span class="co"># Nonconvex</span></span>
<span id="cb8-3"><a></a>h <span class="op">=</span> <span class="kw">lambda</span> x: d2l.exp(<span class="fl">0.5</span> <span class="op">*</span> x)  <span class="co"># Convex</span></span>
<span id="cb8-4"><a></a></span>
<span id="cb8-5"><a></a>x, segment <span class="op">=</span> d2l.arange(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="fl">0.01</span>), d2l.tensor([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">1</span>])</span>
<span id="cb8-6"><a></a>d2l.use_svg_display()</span>
<span id="cb8-7"><a></a>_, axes <span class="op">=</span> d2l.plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">3</span>))</span>
<span id="cb8-8"><a></a><span class="cf">for</span> ax, func <span class="kw">in</span> <span class="bu">zip</span>(axes, [f, g, h]):</span>
<span id="cb8-9"><a></a>    d2l.plot([x, segment], [func(x), func(segment)], axes<span class="op">=</span>ax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="template_files/figure-revealjs/function-examples-output-1.svg" id="function-examples" class="r-stretch"></section>
<section id="jensens-inequality" class="slide level2">
<h2>Jensen’s Inequality</h2>
<h3 id="definition-1">Definition</h3>
<ul>
<li>Generalization of convexity</li>
<li>For convex function <span class="math inline">\(f\)</span>: <span class="math display">\[\sum_i \alpha_i f(x_i) \geq f\left(\sum_i \alpha_i x_i\right)\]</span> <span class="math display">\[E_X[f(X)] \geq f\left(E_X[X]\right)\]</span></li>
<li>Where <span class="math inline">\(\alpha_i \geq 0\)</span> and <span class="math inline">\(\sum_i \alpha_i = 1\)</span></li>
</ul>
<h3 id="applications">Applications</h3>
<ul>
<li>Bounding complex expressions</li>
<li>Log-likelihood of partially observed variables</li>
<li>Variational methods</li>
<li>Clustering algorithms</li>
</ul>
</section>
<section id="properties" class="slide level2">
<h2>Properties</h2>
<h3 id="local-vs-global-minima">Local vs Global Minima</h3>
<ul>
<li>Local minima of convex functions are global minima</li>
<li>Proof by contradiction</li>
<li>Example: <span class="math inline">\(f(x) = (x-1)^2\)</span></li>
</ul>
<div id="cell-local-global-minima" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>f <span class="op">=</span> <span class="kw">lambda</span> x: (x <span class="op">-</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb9-2"><a></a>d2l.set_figsize((<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb9-3"><a></a>d2l.plot([x, segment], [f(x), f(segment)], <span class="st">'x'</span>, <span class="st">'f(x)'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="template_files/figure-revealjs/local-global-minima-output-1.svg" id="local-global-minima" class="r-stretch"></section>
<section class="slide level2">

<h3 id="below-sets">Below Sets</h3>
<ul>
<li>Given convex function <span class="math inline">\(f\)</span> on convex set <span class="math inline">\(\mathcal{X}\)</span></li>
<li>Below set <span class="math inline">\(\mathcal{S}_b = \{x | x \in \mathcal{X} \textrm{ and } f(x) \leq b\}\)</span> is convex</li>
<li>Proof uses definition of convexity</li>
</ul>
<h3 id="second-derivatives">Second Derivatives</h3>
<ul>
<li>For twice-differentiable <span class="math inline">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span></li>
<li>Convex if and only if Hessian is positive semidefinite</li>
<li>One-dimensional case: <span class="math inline">\(f'' \geq 0\)</span></li>
<li>Multidimensional case: <span class="math inline">\(\nabla^2f \succeq 0\)</span></li>
</ul>
</section>
<section id="constraints" class="slide level2">
<h2>Constraints</h2>
<h3 id="constrained-optimization">Constrained Optimization</h3>
<ul>
<li>Form: <span class="math display">\[\begin{aligned} \mathop{\textrm{minimize~}}_{\mathbf{x}} &amp; f(\mathbf{x}) \\
  \textrm{ subject to } &amp; c_i(\mathbf{x}) \leq 0 \textrm{ for all } i \in \{1, \ldots, n\}\end{aligned}\]</span></li>
<li>Examples:
<ul>
<li>Unit ball constraint: <span class="math inline">\(c_1(\mathbf{x}) = \|\mathbf{x}\|_2 - 1\)</span></li>
<li>Half-space constraint: <span class="math inline">\(c_2(\mathbf{x}) = \mathbf{v}^\top \mathbf{x} + b\)</span></li>
</ul></li>
</ul>
<h3 id="lagrangian">Lagrangian</h3>
<ul>
<li>Combines objective and constraints</li>
<li>Form: <span class="math inline">\(L(\mathbf{x}, \alpha_1, \ldots, \alpha_n) = f(\mathbf{x}) + \sum_{i=1}^n \alpha_i c_i(\mathbf{x})\)</span></li>
<li>Lagrange multipliers <span class="math inline">\(\alpha_i \geq 0\)</span></li>
<li>Saddle point optimization</li>
</ul>
</section>
<section class="slide level2">

<h3 id="penalties">Penalties</h3>
<ul>
<li>Alternative to exact constraint satisfaction</li>
<li>Add <span class="math inline">\(\alpha_i c_i(\mathbf{x})\)</span> to objective</li>
<li>Example: weight decay</li>
<li>More robust than exact satisfaction</li>
<li>Works well for nonconvex problems</li>
</ul>
</section>
<section class="slide level2">

<h3 id="projections">Projections</h3>
<ul>
<li>Projection on convex set <span class="math inline">\(\mathcal{X}\)</span>: <span class="math display">\[\textrm{Proj}_\mathcal{X}(\mathbf{x}) = \mathop{\mathrm{argmin}}_{\mathbf{x}' \in \mathcal{X}} \|\mathbf{x} - \mathbf{x}'\|\]</span></li>
<li>Example: gradient clipping</li>
<li>Applications:
<ul>
<li>Sparse weight vectors</li>
<li><span class="math inline">\(\ell_1\)</span> ball projections</li>
</ul></li>
</ul>

<img data-src="./img/projections.svg" class="r-stretch quarto-figure-center"><p class="caption">Convex Projections.</p></section>
<section id="summary-1" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Key properties:
<ul>
<li>Intersections of convex sets are convex</li>
<li>Jensen’s inequality for expectations</li>
<li>Hessian positive semidefinite for convex functions</li>
<li>Local minima are global minima</li>
</ul></li>
<li>Constraint handling:
<ul>
<li>Lagrangian approach</li>
<li>Penalty methods</li>
<li>Projections</li>
</ul></li>
<li>Applications in deep learning:
<ul>
<li>Algorithm motivation</li>
<li>Understanding optimization</li>
<li>Gradient descent analysis</li>
</ul></li>
</ul>
<!-- ---
title: "Gradient Descent"
format: 
  revealjs:
    theme: custom.scss
    css: custom.css
    width: 1920
    height: 1080
    menu:
      side: right
      width: wide
    template-partials:
      - title-slide.html
    slide-number: c/t
    logo: "eclipse_logo_small.png"
    highlight-style: a11y
    incremental: false
    background-transition: fade
    footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy"
execute:
  eval: true
  echo: true
--- -->
</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<ul>
<li>Gradient descent is fundamental to understanding optimization</li>
<li>Key concepts apply to more advanced algorithms</li>
<li>Important considerations:
<ul>
<li>Learning rate selection</li>
<li>Divergence issues</li>
<li>Preconditioning techniques</li>
</ul></li>
</ul>
</section>
<section id="one-dimensional-gradient-descent" class="slide level2">
<h2>One-Dimensional Gradient Descent</h2>
<h3 id="mathematical-foundation">Mathematical Foundation</h3>
<ul>
<li>For continuously differentiable <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span></li>
<li>Taylor expansion: <span class="math display">\[f(x + \epsilon) = f(x) + \epsilon f'(x) + \mathcal{O}(\epsilon^2)\]</span></li>
<li>Moving in negative gradient direction:
<ul>
<li>Choose <span class="math inline">\(\epsilon = -\eta f'(x)\)</span></li>
<li>Fixed step size <span class="math inline">\(\eta &gt; 0\)</span></li>
<li>Results in: <span class="math inline">\(f(x - \eta f'(x)) \lessapprox f(x)\)</span></li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="implementation">Implementation</h3>
<div id="setup2" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a><span class="op">%</span>matplotlib inline</span>
<span id="cb10-2"><a></a><span class="im">import</span> d2l</span>
<span id="cb10-3"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-4"><a></a><span class="im">import</span> torch</span>
<span id="cb10-5"><a></a></span>
<span id="cb10-6"><a></a><span class="kw">def</span> f(x):  <span class="co"># Objective function</span></span>
<span id="cb10-7"><a></a>    <span class="cf">return</span> x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb10-8"><a></a></span>
<span id="cb10-9"><a></a><span class="kw">def</span> f_grad(x):  <span class="co"># Gradient (derivative) of the objective function</span></span>
<span id="cb10-10"><a></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<h3 id="basic-gradient-descent">Basic Gradient Descent</h3>
<div id="gd-implementation" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a><span class="kw">def</span> gd(eta, f_grad):</span>
<span id="cb11-2"><a></a>    x <span class="op">=</span> <span class="fl">10.0</span></span>
<span id="cb11-3"><a></a>    results <span class="op">=</span> [x]</span>
<span id="cb11-4"><a></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb11-5"><a></a>        x <span class="op">-=</span> eta <span class="op">*</span> f_grad(x)</span>
<span id="cb11-6"><a></a>        results.append(<span class="bu">float</span>(x))</span>
<span id="cb11-7"><a></a>    <span class="bu">print</span>(<span class="ss">f'epoch 10, x: </span><span class="sc">{</span>x<span class="sc">:f}</span><span class="ss">'</span>)</span>
<span id="cb11-8"><a></a>    <span class="cf">return</span> results</span>
<span id="cb11-9"><a></a></span>
<span id="cb11-10"><a></a>results <span class="op">=</span> gd(<span class="fl">0.2</span>, f_grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 10, x: 0.060466</code></pre>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="visualization">Visualization</h3>
<div id="cell-gd-visualization" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a><span class="kw">def</span> show_trace(results, f):</span>
<span id="cb13-2"><a></a>    n <span class="op">=</span> <span class="bu">max</span>(<span class="bu">abs</span>(<span class="bu">min</span>(results)), <span class="bu">abs</span>(<span class="bu">max</span>(results)))</span>
<span id="cb13-3"><a></a>    f_line <span class="op">=</span> d2l.arange(<span class="op">-</span>n, n, <span class="fl">0.01</span>)</span>
<span id="cb13-4"><a></a>    d2l.set_figsize()</span>
<span id="cb13-5"><a></a>    d2l.plot([f_line, results], [[f(x) <span class="cf">for</span> x <span class="kw">in</span> f_line], [</span>
<span id="cb13-6"><a></a>        f(x) <span class="cf">for</span> x <span class="kw">in</span> results]], <span class="st">'x'</span>, <span class="st">'f(x)'</span>, fmts<span class="op">=</span>[<span class="st">'-'</span>, <span class="st">'-o'</span>])</span>
<span id="cb13-7"><a></a></span>
<span id="cb13-8"><a></a>show_trace(results, f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="template_files/figure-revealjs/gd-visualization-output-1.svg" id="gd-visualization" class="r-stretch"></section>
<section id="learning-rate-effects" class="slide level2">
<h2>Learning Rate Effects</h2>
<h3 id="too-small-learning-rate">Too Small Learning Rate</h3>
<ul>
<li>Slow convergence</li>
<li>More iterations needed</li>
<li>Example with <span class="math inline">\(\eta = 0.05\)</span>:</li>
</ul>
<div id="cell-small-lr" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>show_trace(gd(<span class="fl">0.05</span>, f_grad), f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 10, x: 3.486784</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/small-lr-output-2.svg" id="small-lr" class="r-stretch"></section>
<section class="slide level2">

<h3 id="too-large-learning-rate">Too Large Learning Rate</h3>
<ul>
<li>Solution oscillates</li>
<li>May diverge</li>
<li>Example with <span class="math inline">\(\eta = 1.1\)</span>:</li>
</ul>
<div id="cell-large-lr" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a>show_trace(gd(<span class="fl">1.1</span>, f_grad), f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 10, x: 61.917364</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/large-lr-output-2.svg" id="large-lr" class="r-stretch"></section>
<section class="slide level2">

<h3 id="local-minima-1">Local Minima</h3>
<ul>
<li>Nonconvex functions have multiple minima</li>
<li>Example: <span class="math inline">\(f(x) = x \cdot \cos(cx)\)</span></li>
<li>High learning rates can lead to poor local minima</li>
</ul>
<div id="cell-local-minima" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a>c <span class="op">=</span> d2l.tensor(<span class="fl">0.15</span> <span class="op">*</span> np.pi)</span>
<span id="cb18-2"><a></a></span>
<span id="cb18-3"><a></a><span class="kw">def</span> f(x):  <span class="co"># Objective function</span></span>
<span id="cb18-4"><a></a>    <span class="cf">return</span> x <span class="op">*</span> d2l.cos(c <span class="op">*</span> x)</span>
<span id="cb18-5"><a></a></span>
<span id="cb18-6"><a></a><span class="kw">def</span> f_grad(x):  <span class="co"># Gradient of the objective function</span></span>
<span id="cb18-7"><a></a>    <span class="cf">return</span> d2l.cos(c <span class="op">*</span> x) <span class="op">-</span> c <span class="op">*</span> x <span class="op">*</span> d2l.sin(c <span class="op">*</span> x)</span>
<span id="cb18-8"><a></a></span>
<span id="cb18-9"><a></a>show_trace(gd(<span class="dv">2</span>, f_grad), f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 10, x: -1.528166</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/local-minima-output-2.svg" id="local-minima" class="r-stretch"></section>
<section id="multivariate-gradient-descent" class="slide level2">
<h2>Multivariate Gradient Descent</h2>
<h3 id="mathematical-foundation-1">Mathematical Foundation</h3>
<ul>
<li>For <span class="math inline">\(f: \mathbb{R}^d \to \mathbb{R}\)</span></li>
<li>Gradient vector: <span class="math inline">\(\nabla f(\mathbf{x}) = [\frac{\partial f(\mathbf{x})}{\partial x_1}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_d}]^\top\)</span></li>
<li>Taylor expansion: <span class="math display">\[f(\mathbf{x} + \boldsymbol{\epsilon}) = f(\mathbf{x}) + \mathbf{\boldsymbol{\epsilon}}^\top \nabla f(\mathbf{x}) + \mathcal{O}(\|\boldsymbol{\epsilon}\|^2)\]</span></li>
<li>Update rule: <span class="math inline">\(\mathbf{x} \leftarrow \mathbf{x} - \eta \nabla f(\mathbf{x})\)</span></li>
</ul>
</section>
<section class="slide level2">

<h3 id="implementation-1">Implementation</h3>
<div id="multivariate-gd" class="cell" data-code-block-height="800" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a></a><span class="kw">def</span> train_2d(trainer, steps<span class="op">=</span><span class="dv">20</span>, f_grad<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb20-2"><a></a>    <span class="co">"""Optimize a 2D objective function with a customized trainer."""</span></span>
<span id="cb20-3"><a></a>    x1, x2, s1, s2 <span class="op">=</span> <span class="op">-</span><span class="dv">5</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb20-4"><a></a>    results <span class="op">=</span> [(x1, x2)]</span>
<span id="cb20-5"><a></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="cb20-6"><a></a>        <span class="cf">if</span> f_grad:</span>
<span id="cb20-7"><a></a>            x1, x2, s1, s2 <span class="op">=</span> trainer(x1, x2, s1, s2, f_grad)</span>
<span id="cb20-8"><a></a>        <span class="cf">else</span>:</span>
<span id="cb20-9"><a></a>            x1, x2, s1, s2 <span class="op">=</span> trainer(x1, x2, s1, s2)</span>
<span id="cb20-10"><a></a>        results.append((x1, x2))</span>
<span id="cb20-11"><a></a>    <span class="bu">print</span>(<span class="ss">f'epoch </span><span class="sc">{</span>i <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">, x1: </span><span class="sc">{</span><span class="bu">float</span>(x1)<span class="sc">:f}</span><span class="ss">, x2: </span><span class="sc">{</span><span class="bu">float</span>(x2)<span class="sc">:f}</span><span class="ss">'</span>)</span>
<span id="cb20-12"><a></a>    <span class="cf">return</span> results</span>
<span id="cb20-13"><a></a></span>
<span id="cb20-14"><a></a><span class="kw">def</span> show_trace_2d(f, results):</span>
<span id="cb20-15"><a></a>    <span class="co">"""Show the trace of 2D variables during optimization."""</span></span>
<span id="cb20-16"><a></a>    d2l.set_figsize()</span>
<span id="cb20-17"><a></a>    d2l.plt.plot(<span class="op">*</span><span class="bu">zip</span>(<span class="op">*</span>results), <span class="st">'-o'</span>, color<span class="op">=</span><span class="st">'#ff7f0e'</span>)</span>
<span id="cb20-18"><a></a>    x1, x2 <span class="op">=</span> d2l.meshgrid(d2l.arange(<span class="op">-</span><span class="fl">5.5</span>, <span class="fl">1.0</span>, <span class="fl">0.1</span>),</span>
<span id="cb20-19"><a></a>                          d2l.arange(<span class="op">-</span><span class="fl">3.0</span>, <span class="fl">1.0</span>, <span class="fl">0.1</span>), indexing<span class="op">=</span><span class="st">'ij'</span>)</span>
<span id="cb20-20"><a></a>    d2l.plt.contour(x1, x2, f(x1, x2), colors<span class="op">=</span><span class="st">'#1f77b4'</span>)</span>
<span id="cb20-21"><a></a>    d2l.plt.xlabel(<span class="st">'x1'</span>)</span>
<span id="cb20-22"><a></a>    d2l.plt.ylabel(<span class="st">'x2'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section class="slide level2">

<h3 id="example-quadratic-function">Example: Quadratic Function</h3>
<div id="cell-quadratic-example" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a><span class="kw">def</span> f_2d(x1, x2):  <span class="co"># Objective function</span></span>
<span id="cb21-2"><a></a>    <span class="cf">return</span> x1 <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> x2 <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb21-3"><a></a></span>
<span id="cb21-4"><a></a><span class="kw">def</span> f_2d_grad(x1, x2):  <span class="co"># Gradient of the objective function</span></span>
<span id="cb21-5"><a></a>    <span class="cf">return</span> (<span class="dv">2</span> <span class="op">*</span> x1, <span class="dv">4</span> <span class="op">*</span> x2)</span>
<span id="cb21-6"><a></a></span>
<span id="cb21-7"><a></a><span class="kw">def</span> gd_2d(x1, x2, s1, s2, f_grad):</span>
<span id="cb21-8"><a></a>    g1, g2 <span class="op">=</span> f_grad(x1, x2)</span>
<span id="cb21-9"><a></a>    <span class="cf">return</span> (x1 <span class="op">-</span> eta <span class="op">*</span> g1, x2 <span class="op">-</span> eta <span class="op">*</span> g2, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb21-10"><a></a></span>
<span id="cb21-11"><a></a>eta <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb21-12"><a></a>show_trace_2d(f_2d, train_2d(gd_2d, f_grad<span class="op">=</span>f_2d_grad))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 20, x1: -0.057646, x2: -0.000073</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/quadratic-example-output-2.svg" id="quadratic-example" class="r-stretch"></section>
<section id="adaptive-methods" class="slide level2">
<h2>Adaptive Methods</h2>
<h3 id="newtons-method">Newton’s Method</h3>
<ul>
<li>Uses second-order information</li>
<li>Taylor expansion with Hessian: <span class="math display">\[f(\mathbf{x} + \boldsymbol{\epsilon}) = f(\mathbf{x}) + \boldsymbol{\epsilon}^\top \nabla f(\mathbf{x}) + \frac{1}{2} \boldsymbol{\epsilon}^\top \nabla^2 f(\mathbf{x}) \boldsymbol{\epsilon} + \mathcal{O}(\|\boldsymbol{\epsilon}\|^3)\]</span></li>
<li>Update rule: <span class="math inline">\(\boldsymbol{\epsilon} = -\mathbf{H}^{-1} \nabla f(\mathbf{x})\)</span></li>
</ul>
</section>
<section class="slide level2">

<h3 id="implementation-2">Implementation</h3>
<div id="cell-newton-method" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a></a>c <span class="op">=</span> d2l.tensor(<span class="fl">0.5</span>)</span>
<span id="cb23-2"><a></a></span>
<span id="cb23-3"><a></a><span class="kw">def</span> f(x):  <span class="co"># Objective function</span></span>
<span id="cb23-4"><a></a>    <span class="cf">return</span> d2l.cosh(c <span class="op">*</span> x)</span>
<span id="cb23-5"><a></a></span>
<span id="cb23-6"><a></a><span class="kw">def</span> f_grad(x):  <span class="co"># Gradient of the objective function</span></span>
<span id="cb23-7"><a></a>    <span class="cf">return</span> c <span class="op">*</span> d2l.sinh(c <span class="op">*</span> x)</span>
<span id="cb23-8"><a></a></span>
<span id="cb23-9"><a></a><span class="kw">def</span> f_hess(x):  <span class="co"># Hessian of the objective function</span></span>
<span id="cb23-10"><a></a>    <span class="cf">return</span> c<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> d2l.cosh(c <span class="op">*</span> x)</span>
<span id="cb23-11"><a></a></span>
<span id="cb23-12"><a></a><span class="kw">def</span> newton(eta<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb23-13"><a></a>    x <span class="op">=</span> <span class="fl">10.0</span></span>
<span id="cb23-14"><a></a>    results <span class="op">=</span> [x]</span>
<span id="cb23-15"><a></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb23-16"><a></a>        x <span class="op">-=</span> eta <span class="op">*</span> f_grad(x) <span class="op">/</span> f_hess(x)</span>
<span id="cb23-17"><a></a>        results.append(<span class="bu">float</span>(x))</span>
<span id="cb23-18"><a></a>    <span class="bu">print</span>(<span class="st">'epoch 10, x:'</span>, x)</span>
<span id="cb23-19"><a></a>    <span class="cf">return</span> results</span>
<span id="cb23-20"><a></a></span>
<span id="cb23-21"><a></a>show_trace(newton(), f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 10, x: tensor(0.)</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/newton-method-output-2.svg" id="newton-method" class="r-stretch"></section>
<section class="slide level2">

<h3 id="nonconvex-example">Nonconvex Example</h3>
<div id="cell-nonconvex-newton" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a></a>c <span class="op">=</span> d2l.tensor(<span class="fl">0.15</span> <span class="op">*</span> np.pi)</span>
<span id="cb25-2"><a></a></span>
<span id="cb25-3"><a></a><span class="kw">def</span> f(x):  <span class="co"># Objective function</span></span>
<span id="cb25-4"><a></a>    <span class="cf">return</span> x <span class="op">*</span> d2l.cos(c <span class="op">*</span> x)</span>
<span id="cb25-5"><a></a></span>
<span id="cb25-6"><a></a><span class="kw">def</span> f_grad(x):  <span class="co"># Gradient of the objective function</span></span>
<span id="cb25-7"><a></a>    <span class="cf">return</span> d2l.cos(c <span class="op">*</span> x) <span class="op">-</span> c <span class="op">*</span> x <span class="op">*</span> d2l.sin(c <span class="op">*</span> x)</span>
<span id="cb25-8"><a></a></span>
<span id="cb25-9"><a></a><span class="kw">def</span> f_hess(x):  <span class="co"># Hessian of the objective function</span></span>
<span id="cb25-10"><a></a>    <span class="cf">return</span> <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> c <span class="op">*</span> d2l.sin(c <span class="op">*</span> x) <span class="op">-</span> x <span class="op">*</span> c<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> d2l.cos(c <span class="op">*</span> x)</span>
<span id="cb25-11"><a></a></span>
<span id="cb25-12"><a></a>show_trace(newton(<span class="fl">0.5</span>), f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 10, x: tensor(7.2699)</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/nonconvex-newton-output-2.svg" id="nonconvex-newton" class="r-stretch"></section>
<section id="preconditioning" class="slide level2">
<h2>Preconditioning</h2>
<h3 id="key-concepts">Key Concepts</h3>
<ul>
<li>Avoid full Hessian computation</li>
<li>Use diagonal entries only</li>
<li>Update rule: <span class="math inline">\(\mathbf{x} \leftarrow \mathbf{x} - \eta \textrm{diag}(\mathbf{H})^{-1} \nabla f(\mathbf{x})\)</span></li>
<li>Benefits:
<ul>
<li>Different learning rates per variable</li>
<li>Handles scale mismatches</li>
<li>More efficient than full Newton’s method</li>
</ul></li>
</ul>
</section>
<section id="summary-2" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Learning rate selection is crucial</li>
<li>Local minima can trap gradient descent</li>
<li>High dimensions require careful learning rate adjustment</li>
<li>Preconditioning helps with scale issues</li>
<li>Newton’s method:
<ul>
<li>Fast convergence for convex problems</li>
<li>Requires careful handling for nonconvex problems</li>
<li>Computationally expensive for large problems</li>
</ul></li>
</ul>
</section>
<section id="exercises-1" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>Experiment with different learning rates and objective functions</li>
<li>Implement line search for convex optimization</li>
<li>Design a slow-converging 2D objective function</li>
<li>Implement lightweight Newton’s method with preconditioning</li>
<li>Test algorithms on rotated coordinate systems</li>
</ol>
<!-- ---
title: "Stochastic Gradient Descent"
format: 
  revealjs:
    theme: custom.scss
    css: custom.css
    width: 1920
    height: 1080
    menu:
      side: right
      width: wide
    template-partials:
      - title-slide.html
    slide-number: c/t
    logo: "eclipse_logo_small.png"
    highlight-style: a11y
    incremental: false
    background-transition: fade
    footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy"
execute:
  eval: true
  echo: true
--- -->
</section></section>
<section>
<section id="stochastic-gradient-descent" class="title-slide slide level1 center">
<h1>Stochastic Gradient Descent</h1>
<ul>
<li>Previously used SGD without detailed explanation</li>
<li>Now diving deeper into its principles</li>
<li>Building on gradient descent fundamentals</li>
<li>Understanding why and how it works</li>
</ul>
<div id="setup4" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a></a><span class="op">%</span>matplotlib inline</span>
<span id="cb27-2"><a></a><span class="im">import</span> d2l</span>
<span id="cb27-3"><a></a><span class="im">import</span> math</span>
<span id="cb27-4"><a></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="stochastic-gradient-updates" class="slide level2">
<h2>Stochastic Gradient Updates</h2>
<h3 id="objective-function">Objective Function</h3>
<ul>
<li>Training dataset with <span class="math inline">\(n\)</span> examples</li>
<li>Loss function <span class="math inline">\(f_i(\mathbf{x})\)</span> for example <span class="math inline">\(i\)</span></li>
<li>Overall objective: <span class="math display">\[f(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n f_i(\mathbf{x})\]</span></li>
<li>Full gradient: <span class="math display">\[\nabla f(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\mathbf{x})\]</span></li>
</ul>
</section>
<section class="slide level2">

<h3 id="computational-cost">Computational Cost</h3>
<ul>
<li>Gradient descent: <span class="math inline">\(\mathcal{O}(n)\)</span> per iteration</li>
<li>SGD: <span class="math inline">\(\mathcal{O}(1)\)</span> per iteration</li>
<li>Update rule: <span class="math display">\[\mathbf{x} \leftarrow \mathbf{x} - \eta \nabla f_i(\mathbf{x})\]</span></li>
<li>Unbiased estimate: <span class="math display">\[\mathbb{E}_i \nabla f_i(\mathbf{x}) = \nabla f(\mathbf{x})\]</span></li>
</ul>
<h3 id="implementation-3">Implementation</h3>
<div id="objective-fn" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a></a><span class="kw">def</span> f(x1, x2):  <span class="co"># Objective function</span></span>
<span id="cb28-2"><a></a>    <span class="cf">return</span> x1 <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> x2 <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb28-3"><a></a></span>
<span id="cb28-4"><a></a><span class="kw">def</span> f_grad(x1, x2):  <span class="co"># Gradient of the objective function</span></span>
<span id="cb28-5"><a></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> x1, <span class="dv">4</span> <span class="op">*</span> x2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section class="slide level2">

<div id="sgd-implementation" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a></a><span class="kw">def</span> sgd(x1, x2, s1, s2, f_grad):</span>
<span id="cb29-2"><a></a>    g1, g2 <span class="op">=</span> f_grad(x1, x2)</span>
<span id="cb29-3"><a></a>    <span class="co"># Simulate noisy gradient</span></span>
<span id="cb29-4"><a></a>    g1 <span class="op">+=</span> torch.normal(<span class="fl">0.0</span>, <span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb29-5"><a></a>    g2 <span class="op">+=</span> torch.normal(<span class="fl">0.0</span>, <span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb29-6"><a></a>    eta_t <span class="op">=</span> eta <span class="op">*</span> lr()</span>
<span id="cb29-7"><a></a>    <span class="cf">return</span> (x1 <span class="op">-</span> eta_t <span class="op">*</span> g1, x2 <span class="op">-</span> eta_t <span class="op">*</span> g2, <span class="dv">0</span>, <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-constant-lr" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a></a><span class="kw">def</span> constant_lr():</span>
<span id="cb30-2"><a></a>    <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb30-3"><a></a></span>
<span id="cb30-4"><a></a>eta <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb30-5"><a></a>lr <span class="op">=</span> constant_lr  <span class="co"># Constant learning rate</span></span>
<span id="cb30-6"><a></a>d2l.show_trace_2d(f, d2l.train_2d(sgd, steps<span class="op">=</span><span class="dv">50</span>, f_grad<span class="op">=</span>f_grad))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 50, x1: 0.112101, x2: 0.220222</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/constant-lr-output-2.svg" id="constant-lr" class="r-stretch"></section>
<section id="dynamic-learning-rate" class="slide level2">
<h2>Dynamic Learning Rate</h2>
<h3 id="learning-rate-strategies">Learning Rate Strategies</h3>
<ul>
<li>Piecewise constant: <span class="math inline">\(\eta(t) = \eta_i \textrm{ if } t_i \leq t \leq t_{i+1}\)</span></li>
<li>Exponential decay: <span class="math inline">\(\eta(t) = \eta_0 \cdot e^{-\lambda t}\)</span></li>
<li>Polynomial decay: <span class="math inline">\(\eta(t) = \eta_0 \cdot (\beta t + 1)^{-\alpha}\)</span></li>
</ul>
<h3 id="exponential-decay-implementation">Exponential Decay Implementation</h3>
<div id="cell-exponential-lr" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a></a><span class="kw">def</span> exponential_lr():</span>
<span id="cb32-2"><a></a>    <span class="kw">global</span> t</span>
<span id="cb32-3"><a></a>    t <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb32-4"><a></a>    <span class="cf">return</span> math.exp(<span class="op">-</span><span class="fl">0.1</span> <span class="op">*</span> t)</span>
<span id="cb32-5"><a></a></span>
<span id="cb32-6"><a></a>t <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb32-7"><a></a>lr <span class="op">=</span> exponential_lr</span>
<span id="cb32-8"><a></a>d2l.show_trace_2d(f, d2l.train_2d(sgd, steps<span class="op">=</span><span class="dv">1000</span>, f_grad<span class="op">=</span>f_grad))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 1000, x1: -0.875382, x2: -0.111930</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/exponential-lr-output-2.svg" id="exponential-lr" class="r-stretch"></section>
<section class="slide level2">

<h3 id="polynomial-decay-implementation">Polynomial Decay Implementation</h3>
<div id="cell-polynomial-lr" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a></a><span class="kw">def</span> polynomial_lr():</span>
<span id="cb34-2"><a></a>    <span class="kw">global</span> t</span>
<span id="cb34-3"><a></a>    t <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb34-4"><a></a>    <span class="cf">return</span> (<span class="dv">1</span> <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> t) <span class="op">**</span> (<span class="op">-</span><span class="fl">0.5</span>)</span>
<span id="cb34-5"><a></a></span>
<span id="cb34-6"><a></a>t <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb34-7"><a></a>lr <span class="op">=</span> polynomial_lr</span>
<span id="cb34-8"><a></a>d2l.show_trace_2d(f, d2l.train_2d(sgd, steps<span class="op">=</span><span class="dv">50</span>, f_grad<span class="op">=</span>f_grad))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 50, x1: -0.123380, x2: 0.013790</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/polynomial-lr-output-2.svg" id="polynomial-lr" class="r-stretch"></section>
<section id="stochastic-gradients-and-finite-samples" class="slide level2">
<h2>Stochastic Gradients and Finite Samples</h2>
<h3 id="sampling-strategies">Sampling Strategies</h3>
<ul>
<li>With replacement:
<ul>
<li>Probability of choosing element: <span class="math inline">\(1 - e^{-1} \approx 0.63\)</span></li>
<li>Increased variance</li>
<li>Decreased data efficiency</li>
</ul></li>
<li>Without replacement:
<ul>
<li>Better variance properties</li>
<li>More efficient data usage</li>
<li>Default choice in practice</li>
</ul></li>
</ul>
</section>
<section id="summary-3" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Key points:
<ul>
<li>SGD reduces computational cost to <span class="math inline">\(\mathcal{O}(1)\)</span></li>
<li>Learning rate scheduling is crucial</li>
<li>Convergence guarantees for convex problems</li>
<li>Sampling without replacement preferred</li>
</ul></li>
<li>Practical considerations:
<ul>
<li>Dynamic learning rates</li>
<li>Trade-offs in sampling strategies</li>
<li>Nonconvex optimization challenges</li>
</ul></li>
</ul>
</section>
<section id="exercises-2" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>Experiment with learning rate schedules</li>
<li>Analyze noise in gradient updates</li>
<li>Compare sampling strategies</li>
<li>Investigate gradient coordinate scaling</li>
<li>Study local minima in nonconvex functions</li>
</ol>
<!-- ---
title: ""
format: 
  revealjs:
    theme: custom.scss
    css: custom.css
    width: 1920
    height: 1080
    menu:
      side: right
      width: wide
    template-partials:
      - title-slide.html
    slide-number: c/t
    logo: "eclipse_logo_small.png"
    highlight-style: a11y
    incremental: false
    background-transition: fade
    footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy"
execute:
  eval: true
  echo: true
--- -->
</section></section>
<section>
<section id="minibatch-stochastic-gradient-descent" class="title-slide slide level1 center">
<h1>Minibatch Stochastic Gradient Descent</h1>
<ul>
<li>Two extremes in gradient-based learning:
<ul>
<li>Full dataset (gradient descent)</li>
<li>Single examples (stochastic gradient descent)</li>
</ul></li>
<li>Each approach has drawbacks:
<ul>
<li>Gradient descent: Not data efficient for similar data</li>
<li>SGD: Not computationally efficient (poor vectorization)</li>
</ul></li>
<li>Minibatch SGD offers a middle ground</li>
</ul>
</section>
<section id="vectorization-and-caches" class="slide level2">
<h2>Vectorization and Caches</h2>
<h3 id="hardware-considerations">Hardware Considerations</h3>
<ul>
<li>Multiple GPUs and servers require larger minibatches
<ul>
<li>8 GPUs × 16 servers = minimum batch size of 128</li>
</ul></li>
<li>Single GPU/CPU considerations:
<ul>
<li>Multiple memory types (registers, L1/L2/L3 cache)</li>
<li>Different bandwidth constraints</li>
<li>Memory access patterns matter</li>
</ul></li>
</ul>
<h3 id="performance-metrics">Performance Metrics</h3>
<ul>
<li>Modern CPU capabilities:
<ul>
<li>2GHz CPU with 16 cores and AVX-512</li>
<li>Can process up to 10¹² bytes/second</li>
</ul></li>
<li>GPU capabilities:
<ul>
<li>100× better than CPU</li>
</ul></li>
<li>Memory bandwidth limitations:
<ul>
<li>Midrange server: ~100 GB/s</li>
<li>Memory access width: 64-384 bit</li>
</ul></li>
</ul>
</section>
<section id="matrix-multiplication-strategies" class="slide level2">
<h2>Matrix Multiplication Strategies</h2>
<h3 id="different-approaches">Different Approaches</h3>
<ol type="1">
<li>Element-wise computation</li>
<li>Column-wise computation</li>
<li>Full matrix multiplication</li>
<li>Block-wise computation</li>
</ol>
</section>
<section class="slide level2">

<h3 id="performance-comparison">Performance Comparison</h3>
<div id="matrix-mult" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a></a><span class="im">import</span> d2l</span>
<span id="cb36-2"><a></a><span class="im">import</span> torch</span>
<span id="cb36-3"><a></a><span class="im">import</span> time</span>
<span id="cb36-4"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-5"><a></a></span>
<span id="cb36-6"><a></a><span class="kw">class</span> Timer:</span>
<span id="cb36-7"><a></a>    <span class="co">"""Record multiple running times."""</span></span>
<span id="cb36-8"><a></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb36-9"><a></a>        <span class="va">self</span>.times <span class="op">=</span> []</span>
<span id="cb36-10"><a></a>        <span class="va">self</span>.start()</span>
<span id="cb36-11"><a></a></span>
<span id="cb36-12"><a></a>    <span class="kw">def</span> start(<span class="va">self</span>):</span>
<span id="cb36-13"><a></a>        <span class="co">"""Start the timer."""</span></span>
<span id="cb36-14"><a></a>        <span class="va">self</span>.tik <span class="op">=</span> time.time()</span>
<span id="cb36-15"><a></a></span>
<span id="cb36-16"><a></a>    <span class="kw">def</span> stop(<span class="va">self</span>):</span>
<span id="cb36-17"><a></a>        <span class="co">"""Stop the timer and record the time in a list."""</span></span>
<span id="cb36-18"><a></a>        <span class="va">self</span>.times.append(time.time() <span class="op">-</span> <span class="va">self</span>.tik)</span>
<span id="cb36-19"><a></a>        <span class="cf">return</span> <span class="va">self</span>.times[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb36-20"><a></a></span>
<span id="cb36-21"><a></a>    <span class="kw">def</span> avg(<span class="va">self</span>):</span>
<span id="cb36-22"><a></a>        <span class="co">"""Return the average time."""</span></span>
<span id="cb36-23"><a></a>        <span class="cf">return</span> <span class="bu">sum</span>(<span class="va">self</span>.times) <span class="op">/</span> <span class="bu">len</span>(<span class="va">self</span>.times)</span>
<span id="cb36-24"><a></a></span>
<span id="cb36-25"><a></a>    <span class="kw">def</span> <span class="bu">sum</span>(<span class="va">self</span>):</span>
<span id="cb36-26"><a></a>        <span class="co">"""Return the sum of time."""</span></span>
<span id="cb36-27"><a></a>        <span class="cf">return</span> <span class="bu">sum</span>(<span class="va">self</span>.times)</span>
<span id="cb36-28"><a></a></span>
<span id="cb36-29"><a></a>    <span class="kw">def</span> cumsum(<span class="va">self</span>):</span>
<span id="cb36-30"><a></a>        <span class="co">"""Return the accumulated time."""</span></span>
<span id="cb36-31"><a></a>        <span class="cf">return</span> torch.tensor(<span class="va">self</span>.times).cumsum().tolist()</span>
<span id="cb36-32"><a></a></span>
<span id="cb36-33"><a></a><span class="co"># Initialize matrices</span></span>
<span id="cb36-34"><a></a>A <span class="op">=</span> torch.zeros(<span class="dv">256</span>, <span class="dv">256</span>)</span>
<span id="cb36-35"><a></a>B <span class="op">=</span> torch.randn(<span class="dv">256</span>, <span class="dv">256</span>)</span>
<span id="cb36-36"><a></a>C <span class="op">=</span> torch.randn(<span class="dv">256</span>, <span class="dv">256</span>)</span>
<span id="cb36-37"><a></a>timer <span class="op">=</span> Timer()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<h3 id="element-wise-computation">Element-wise Computation</h3>
<div id="cell-element-wise" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a></a><span class="co"># Compute A = BC one element at a time</span></span>
<span id="cb37-2"><a></a>timer.start()</span>
<span id="cb37-3"><a></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">256</span>):</span>
<span id="cb37-4"><a></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">256</span>):</span>
<span id="cb37-5"><a></a>        A[i, j] <span class="op">=</span> torch.dot(B[i, :], C[:, j])</span>
<span id="cb37-6"><a></a>timer.stop()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="element-wise" class="cell-output cell-output-display" data-execution_count="26">
<pre><code>2.2032790184020996</code></pre>
</div>
</div>
<h3 id="column-wise-computation">Column-wise Computation</h3>
<div id="cell-column-wise" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a></a><span class="co"># Compute A = BC one column at a time</span></span>
<span id="cb39-2"><a></a>timer.start()</span>
<span id="cb39-3"><a></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">256</span>):</span>
<span id="cb39-4"><a></a>    A[:, j] <span class="op">=</span> torch.mv(B, C[:, j])</span>
<span id="cb39-5"><a></a>timer.stop()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="column-wise" class="cell-output cell-output-display" data-execution_count="27">
<pre><code>0.013736724853515625</code></pre>
</div>
</div>
</section>
<section class="slide level2">

<h3 id="full-matrix-multiplication">Full Matrix Multiplication</h3>
<div id="full-matrix" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a></a><span class="co"># Compute A = BC in one go</span></span>
<span id="cb41-2"><a></a>timer.start()</span>
<span id="cb41-3"><a></a>A <span class="op">=</span> torch.mm(B, C)</span>
<span id="cb41-4"><a></a>timer.stop()</span>
<span id="cb41-5"><a></a></span>
<span id="cb41-6"><a></a>gigaflops <span class="op">=</span> [<span class="fl">0.03</span> <span class="op">/</span> i <span class="cf">for</span> i <span class="kw">in</span> timer.times]</span>
<span id="cb41-7"><a></a><span class="bu">print</span>(<span class="ss">f'performance in Gigaflops: element </span><span class="sc">{</span>gigaflops[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, '</span></span>
<span id="cb41-8"><a></a>      <span class="ss">f'column </span><span class="sc">{</span>gigaflops[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">, full </span><span class="sc">{</span>gigaflops[<span class="dv">2</span>]<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>performance in Gigaflops: element 0.014, column 2.184, full 36.462</code></pre>
</div>
</div>
</section>
<section id="minibatch-processing" class="slide level2">
<h2>Minibatch Processing</h2>
<h3 id="why-use-minibatches">Why Use Minibatches?</h3>
<ul>
<li>Computational efficiency</li>
<li>Statistical properties:
<ul>
<li>Maintains gradient expectation</li>
<li>Reduces variance by factor of <span class="math inline">\(b^{-\frac{1}{2}}\)</span></li>
<li><span class="math inline">\(b\)</span> = batch size</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="batch-size-trade-offs">Batch Size Trade-offs</h3>
<ul>
<li>Too small:
<ul>
<li>Poor computational efficiency</li>
<li>High variance</li>
</ul></li>
<li>Too large:
<ul>
<li>Diminishing returns in variance reduction</li>
<li>Memory constraints</li>
</ul></li>
<li>Optimal: Balance between:
<ul>
<li>Computational efficiency</li>
<li>Statistical efficiency</li>
<li>Available memory</li>
</ul></li>
</ul>
</section>
<section id="implementation-4" class="slide level2">
<h2>Implementation</h2>
<h3 id="data-loading">Data Loading</h3>
<div id="data-loading" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a></a><span class="co">#@save</span></span>
<span id="cb43-2"><a></a>d2l.DATA_HUB[<span class="st">'airfoil'</span>] <span class="op">=</span> (d2l.DATA_URL <span class="op">+</span> <span class="st">'airfoil_self_noise.dat'</span>,</span>
<span id="cb43-3"><a></a>                           <span class="st">'76e5be1548fd8222e5074cf0faae75edff8cf93f'</span>)</span>
<span id="cb43-4"><a></a></span>
<span id="cb43-5"><a></a><span class="co">#@save</span></span>
<span id="cb43-6"><a></a><span class="kw">def</span> get_data_ch11(batch_size<span class="op">=</span><span class="dv">10</span>, n<span class="op">=</span><span class="dv">1500</span>):</span>
<span id="cb43-7"><a></a>    data <span class="op">=</span> np.genfromtxt(d2l.download(<span class="st">'airfoil'</span>),</span>
<span id="cb43-8"><a></a>                         dtype<span class="op">=</span>np.float32, delimiter<span class="op">=</span><span class="st">'</span><span class="ch">\t</span><span class="st">'</span>)</span>
<span id="cb43-9"><a></a>    data <span class="op">=</span> torch.from_numpy((data <span class="op">-</span> data.mean(axis<span class="op">=</span><span class="dv">0</span>)) <span class="op">/</span> data.std(axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb43-10"><a></a>    data_iter <span class="op">=</span> d2l.load_array((data[:n, :<span class="op">-</span><span class="dv">1</span>], data[:n, <span class="op">-</span><span class="dv">1</span>]),</span>
<span id="cb43-11"><a></a>                               batch_size, is_train<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb43-12"><a></a>    <span class="cf">return</span> data_iter, data.shape[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<h3 id="training-function">Training Function</h3>
<div id="training-fn" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a></a><span class="co">#@save</span></span>
<span id="cb44-2"><a></a><span class="kw">def</span> sgd(params, states, hyperparams):</span>
<span id="cb44-3"><a></a>    <span class="cf">for</span> p <span class="kw">in</span> params:</span>
<span id="cb44-4"><a></a>        p.data.sub_(hyperparams[<span class="st">'lr'</span>] <span class="op">*</span> p.grad)</span>
<span id="cb44-5"><a></a>        p.grad.data.zero_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section class="slide level2">

<h3 id="training-function-1">Training Function</h3>
<div id="training-fn1" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a></a><span class="kw">def</span> train_ch11(trainer_fn, states, hyperparams, data_iter,</span>
<span id="cb45-2"><a></a>               feature_dim, num_epochs<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb45-3"><a></a>    <span class="co"># Initialization</span></span>
<span id="cb45-4"><a></a>    w <span class="op">=</span> torch.normal(mean<span class="op">=</span><span class="fl">0.0</span>, std<span class="op">=</span><span class="fl">0.01</span>, size<span class="op">=</span>(feature_dim, <span class="dv">1</span>),</span>
<span id="cb45-5"><a></a>                     requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-6"><a></a>    b <span class="op">=</span> torch.zeros((<span class="dv">1</span>), requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-7"><a></a>    net, loss <span class="op">=</span> <span class="kw">lambda</span> X: d2l.linreg(X, w, b), d2l.squared_loss</span>
<span id="cb45-8"><a></a>    <span class="co"># Train</span></span>
<span id="cb45-9"><a></a>    animator <span class="op">=</span> d2l.Animator(xlabel<span class="op">=</span><span class="st">'epoch'</span>, ylabel<span class="op">=</span><span class="st">'loss'</span>,</span>
<span id="cb45-10"><a></a>                            xlim<span class="op">=</span>[<span class="dv">0</span>, num_epochs], ylim<span class="op">=</span>[<span class="fl">0.22</span>, <span class="fl">0.35</span>])</span>
<span id="cb45-11"><a></a>    n, timer <span class="op">=</span> <span class="dv">0</span>, d2l.Timer()</span>
<span id="cb45-12"><a></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb45-13"><a></a>        <span class="cf">for</span> X, y <span class="kw">in</span> data_iter:</span>
<span id="cb45-14"><a></a>            l <span class="op">=</span> loss(net(X), y).mean()</span>
<span id="cb45-15"><a></a>            l.backward()</span>
<span id="cb45-16"><a></a>            trainer_fn([w, b], states, hyperparams)</span>
<span id="cb45-17"><a></a>            n <span class="op">+=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb45-18"><a></a>            <span class="cf">if</span> n <span class="op">%</span> <span class="dv">200</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb45-19"><a></a>                timer.stop()</span>
<span id="cb45-20"><a></a>                animator.add(n<span class="op">/</span>X.shape[<span class="dv">0</span>]<span class="op">/</span><span class="bu">len</span>(data_iter),</span>
<span id="cb45-21"><a></a>                             (d2l.evaluate_loss(net, data_iter, loss),))</span>
<span id="cb45-22"><a></a>                timer.start()</span>
<span id="cb45-23"><a></a>    <span class="bu">print</span>(<span class="ss">f'loss: </span><span class="sc">{</span>animator<span class="sc">.</span>Y[<span class="dv">0</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>timer<span class="sc">.</span><span class="bu">sum</span>()<span class="op">/</span>num_epochs<span class="sc">:.3f}</span><span class="ss"> sec/epoch'</span>)</span>
<span id="cb45-24"><a></a>    <span class="cf">return</span> timer.cumsum(), animator.Y[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="performance-comparison-1" class="slide level2">
<h2>Performance Comparison</h2>
<h3 id="different-batch-sizes">Different Batch Sizes</h3>
<div class="columns">
<div class="column" style="width:50%;">
<div id="batch-comparison1" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a></a><span class="kw">def</span> train_sgd(lr, batch_size, num_epochs<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb46-2"><a></a>    data_iter, feature_dim <span class="op">=</span> get_data_ch11(batch_size)</span>
<span id="cb46-3"><a></a>    <span class="cf">return</span> train_ch11(</span>
<span id="cb46-4"><a></a>        sgd, <span class="va">None</span>, {<span class="st">'lr'</span>: lr}, data_iter, feature_dim, num_epochs)</span>
<span id="cb46-5"><a></a></span>
<span id="cb46-6"><a></a><span class="co"># Compare different approaches</span></span>
<span id="cb46-7"><a></a>gd_res <span class="op">=</span> train_sgd(<span class="dv">1</span>, <span class="dv">1500</span>, <span class="dv">10</span>)  <span class="co"># Full batch</span></span>
<span id="cb46-8"><a></a>sgd_res <span class="op">=</span> train_sgd(<span class="fl">0.005</span>, <span class="dv">1</span>)    <span class="co"># Single example</span></span>
<span id="cb46-9"><a></a>d2l.set_figsize([<span class="dv">6</span>, <span class="dv">3</span>])</span>
<span id="cb46-10"><a></a>d2l.plot(<span class="op">*</span><span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">list</span>, <span class="bu">zip</span>(gd_res, sgd_res))),</span>
<span id="cb46-11"><a></a>         <span class="st">'time (sec)'</span>, <span class="st">'loss'</span>, xlim<span class="op">=</span>[<span class="fl">1e-2</span>, <span class="dv">10</span>],</span>
<span id="cb46-12"><a></a>         legend<span class="op">=</span>[<span class="st">'gd'</span>, <span class="st">'sgd'</span>, <span class="st">'batch size=100'</span>, <span class="st">'batch size=10'</span>])</span>
<span id="cb46-13"><a></a>d2l.plt.gca().set_xscale(<span class="st">'log'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>loss: 0.245, 0.522 sec/epoch</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="template_files/figure-revealjs/batch-comparison1-output-2.svg" id="batch-comparison1-1"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="template_files/figure-revealjs/batch-comparison1-output-3.svg" id="batch-comparison1-2"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div id="batch-comparison2" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a></a>mini1_res <span class="op">=</span> train_sgd(<span class="fl">.4</span>, <span class="dv">100</span>)   <span class="co"># Medium batch</span></span>
<span id="cb48-2"><a></a>mini2_res <span class="op">=</span> train_sgd(<span class="fl">.05</span>, <span class="dv">10</span>)   <span class="co"># Small batch</span></span>
<span id="cb48-3"><a></a></span>
<span id="cb48-4"><a></a><span class="co"># Plot results</span></span>
<span id="cb48-5"><a></a>d2l.set_figsize([<span class="dv">6</span>, <span class="dv">3</span>])</span>
<span id="cb48-6"><a></a>d2l.plot(<span class="op">*</span><span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">list</span>, <span class="bu">zip</span>( mini1_res, mini2_res))),</span>
<span id="cb48-7"><a></a>         <span class="st">'time (sec)'</span>, <span class="st">'loss'</span>, xlim<span class="op">=</span>[<span class="fl">1e-2</span>, <span class="dv">10</span>],</span>
<span id="cb48-8"><a></a>         legend<span class="op">=</span>[<span class="st">'gd'</span>, <span class="st">'sgd'</span>, <span class="st">'batch size=100'</span>, <span class="st">'batch size=10'</span>])</span>
<span id="cb48-9"><a></a>d2l.plt.gca().set_xscale(<span class="st">'log'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>loss: 0.244, 0.070 sec/epoch</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="template_files/figure-revealjs/batch-comparison2-output-2.svg" id="batch-comparison2-1"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="template_files/figure-revealjs/batch-comparison2-output-3.svg" id="batch-comparison2-2"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="summary-4" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Vectorization benefits:
<ul>
<li>Reduced framework overhead</li>
<li>Better memory locality</li>
<li>Improved caching</li>
</ul></li>
<li>Minibatch SGD advantages:
<ul>
<li>Computational efficiency</li>
<li>Statistical efficiency</li>
<li>Memory efficiency</li>
</ul></li>
<li>Key considerations:
<ul>
<li>Batch size selection</li>
<li>Learning rate decay</li>
<li>Hardware constraints</li>
</ul></li>
</ul>
</section>
<section id="exercises-3" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>Experiment with different batch sizes and learning rates</li>
<li>Implement learning rate decay</li>
<li>Compare with replacement sampling</li>
<li>Analyze behavior with duplicated data</li>
</ol>
<!-- ---
title: "Momentum in Optimization"
format: 
  revealjs:
    theme: custom.scss
    css: custom.css
    width: 1920
    height: 1080
    menu:
      side: right
      width: wide
    template-partials:
      - title-slide.html
    slide-number: c/t
    logo: "eclipse_logo_small.png"
    highlight-style: a11y
    incremental: false
    background-transition: fade
    footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy"
execute:
  eval: true
  echo: true
--- -->
</section></section>
<section>
<section id="momentum-in-optimization" class="title-slide slide level1 center">
<h1>Momentum in Optimization</h1>
<ul>
<li>Momentum is a key optimization technique in deep learning</li>
<li>Addresses challenges in stochastic gradient descent:
<ul>
<li>Learning rate sensitivity</li>
<li>Convergence issues</li>
<li>Noise handling</li>
</ul></li>
<li>Particularly effective for ill-conditioned problems</li>
</ul>
</section>
<section id="basics-of-momentum" class="slide level2">
<h2>Basics of Momentum</h2>
<h3 id="leaky-averages">Leaky Averages</h3>
<ul>
<li>Minibatch SGD averages gradients to reduce variance</li>
<li>Momentum extends this concept using “leaky averages”:
<ul>
<li>Accumulates past gradients</li>
<li>Weights recent gradients more heavily</li>
<li>Formula: <span class="math inline">\(\mathbf{v}_t = \beta \mathbf{v}_{t-1} + \mathbf{g}_{t, t-1}\)</span></li>
<li><span class="math inline">\(\beta \in (0, 1)\)</span> controls the “memory” of past gradients</li>
</ul></li>
</ul>
</section>
<section class="slide level2">

<h3 id="key-benefits">Key Benefits</h3>
<ul>
<li>Accelerates convergence</li>
<li>Particularly effective for:
<ul>
<li>Ill-conditioned problems</li>
<li>Narrow canyons in optimization landscape</li>
</ul></li>
<li>Provides more stable descent directions</li>
<li>Works well with both:
<ul>
<li>Noise-free convex problems</li>
<li>Stochastic gradient descent</li>
</ul></li>
</ul>
</section>
<section id="visualizing-the-problem" class="slide level2">
<h2>Visualizing the Problem</h2>
<p>Let’s examine an ill-conditioned problem:</p>
<div id="cell-setup" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a></a><span class="op">%</span>matplotlib inline</span>
<span id="cb50-2"><a></a><span class="im">import</span> d2l</span>
<span id="cb50-3"><a></a><span class="im">import</span> torch</span>
<span id="cb50-4"><a></a></span>
<span id="cb50-5"><a></a>eta <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb50-6"><a></a><span class="kw">def</span> f_2d(x1, x2):</span>
<span id="cb50-7"><a></a>    <span class="cf">return</span> <span class="fl">0.1</span> <span class="op">*</span> x1 <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> x2 <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb50-8"><a></a><span class="kw">def</span> gd_2d(x1, x2, s1, s2):</span>
<span id="cb50-9"><a></a>    <span class="cf">return</span> (x1 <span class="op">-</span> eta <span class="op">*</span> <span class="fl">0.2</span> <span class="op">*</span> x1, x2 <span class="op">-</span> eta <span class="op">*</span> <span class="dv">4</span> <span class="op">*</span> x2, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb50-10"><a></a></span>
<span id="cb50-11"><a></a>d2l.show_trace_2d(f_2d, d2l.train_2d(gd_2d))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 20, x1: -0.943467, x2: -0.000073</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/setup-output-2.svg" id="setup" class="r-stretch"></section>
<section id="the-challenge" class="slide level2">
<h2>The Challenge</h2>
<ul>
<li>Function <span class="math inline">\(f(\mathbf{x}) = 0.1 x_1^2 + 2 x_2^2\)</span> is very flat in <span class="math inline">\(x_1\)</span> direction</li>
<li>Gradient in <span class="math inline">\(x_2\)</span> direction:
<ul>
<li>Much higher</li>
<li>Changes more rapidly</li>
</ul></li>
<li>Trade-off in learning rate:
<ul>
<li>Small rate: Slow convergence in <span class="math inline">\(x_1\)</span></li>
<li>Large rate: Divergence in <span class="math inline">\(x_2\)</span></li>
</ul></li>
</ul>
</section>
<section id="momentum-method" class="slide level2">
<h2>Momentum Method</h2>
<h3 id="update-equations">Update Equations</h3>
<p><span class="math display">\[
\begin{aligned}
\mathbf{v}_t &amp;\leftarrow \beta \mathbf{v}_{t-1} + \mathbf{g}_{t, t-1}, \\
\mathbf{x}_t &amp;\leftarrow \mathbf{x}_{t-1} - \eta_t \mathbf{v}_t.
\end{aligned}
\]</span></p>
<h3 id="implementation-5">Implementation</h3>
<div id="cell-momentum-implementation" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a></a><span class="kw">def</span> momentum_2d(x1, x2, v1, v2):</span>
<span id="cb52-2"><a></a>    v1 <span class="op">=</span> beta <span class="op">*</span> v1 <span class="op">+</span> <span class="fl">0.2</span> <span class="op">*</span> x1</span>
<span id="cb52-3"><a></a>    v2 <span class="op">=</span> beta <span class="op">*</span> v2 <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> x2</span>
<span id="cb52-4"><a></a>    <span class="cf">return</span> x1 <span class="op">-</span> eta <span class="op">*</span> v1, x2 <span class="op">-</span> eta <span class="op">*</span> v2, v1, v2</span>
<span id="cb52-5"><a></a></span>
<span id="cb52-6"><a></a>eta, beta <span class="op">=</span> <span class="fl">0.6</span>, <span class="fl">0.5</span></span>
<span id="cb52-7"><a></a>d2l.show_trace_2d(f_2d, d2l.train_2d(momentum_2d))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 20, x1: 0.007188, x2: 0.002553</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/momentum-implementation-output-2.svg" id="momentum-implementation" class="r-stretch"></section>
<section id="effect-of-momentum-parameter" class="slide level2">
<h2>Effect of Momentum Parameter</h2>
<ul>
<li><span class="math inline">\(\beta = 0.5\)</span>: Good convergence</li>
<li><span class="math inline">\(\beta = 0.25\)</span>: Barely converges but better than no momentum</li>
<li><span class="math inline">\(\beta = 0\)</span>: Reduces to regular gradient descent</li>
</ul>
<div id="cell-momentum-beta" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a></a>eta, beta <span class="op">=</span> <span class="fl">0.6</span>, <span class="fl">0.25</span></span>
<span id="cb54-2"><a></a>d2l.show_trace_2d(f_2d, d2l.train_2d(momentum_2d))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>epoch 20, x1: -0.126340, x2: -0.186632</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/momentum-beta-output-2.svg" id="momentum-beta" class="r-stretch"></section>
<section id="effective-sample-weight" class="slide level2">
<h2>Effective Sample Weight</h2>
<ul>
<li>Sum of weights: <span class="math inline">\(\sum_{\tau=0}^\infty \beta^\tau = \frac{1}{1-\beta}\)</span></li>
<li>Step size effectively becomes <span class="math inline">\(\frac{\eta}{1-\beta}\)</span></li>
<li>Better behaved descent direction</li>
</ul>
<div id="cell-effective-weight" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a></a>d2l.set_figsize()</span>
<span id="cb56-2"><a></a>betas <span class="op">=</span> [<span class="fl">0.95</span>, <span class="fl">0.9</span>, <span class="fl">0.6</span>, <span class="dv">0</span>]</span>
<span id="cb56-3"><a></a><span class="cf">for</span> beta <span class="kw">in</span> betas:</span>
<span id="cb56-4"><a></a>    x <span class="op">=</span> d2l.numpy(d2l.arange(<span class="dv">40</span>))</span>
<span id="cb56-5"><a></a>    d2l.plt.plot(x, beta <span class="op">**</span> x, label<span class="op">=</span><span class="ss">f'beta = </span><span class="sc">{</span>beta<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb56-6"><a></a>d2l.plt.xlabel(<span class="st">'time'</span>)</span>
<span id="cb56-7"><a></a>d2l.plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="template_files/figure-revealjs/effective-weight-output-1.svg" id="effective-weight" class="r-stretch"></section>
<section id="practical-implementation" class="slide level2">
<h2>Practical Implementation</h2>
<h3 id="from-scratch">From Scratch</h3>
<div id="momentum-scratch" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a></a><span class="kw">def</span> init_momentum_states(feature_dim):</span>
<span id="cb57-2"><a></a>    v_w <span class="op">=</span> d2l.zeros((feature_dim, <span class="dv">1</span>))</span>
<span id="cb57-3"><a></a>    v_b <span class="op">=</span> d2l.zeros(<span class="dv">1</span>)</span>
<span id="cb57-4"><a></a>    <span class="cf">return</span> (v_w, v_b)</span>
<span id="cb57-5"><a></a></span>
<span id="cb57-6"><a></a><span class="kw">def</span> sgd_momentum(params, states, hyperparams):</span>
<span id="cb57-7"><a></a>    <span class="cf">for</span> p, v <span class="kw">in</span> <span class="bu">zip</span>(params, states):</span>
<span id="cb57-8"><a></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb57-9"><a></a>            v[:] <span class="op">=</span> hyperparams[<span class="st">'momentum'</span>] <span class="op">*</span> v <span class="op">+</span> p.grad</span>
<span id="cb57-10"><a></a>            p[:] <span class="op">-=</span> hyperparams[<span class="st">'lr'</span>] <span class="op">*</span> v</span>
<span id="cb57-11"><a></a>        p.grad.data.zero_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<h3 id="training-with-different-parameters">Training with Different Parameters</h3>
<div id="cell-momentum-training" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a></a><span class="kw">def</span> train_momentum(lr, momentum, num_epochs<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb58-2"><a></a>    d2l.train_ch11(sgd_momentum, init_momentum_states(feature_dim),</span>
<span id="cb58-3"><a></a>                   {<span class="st">'lr'</span>: lr, <span class="st">'momentum'</span>: momentum}, data_iter,</span>
<span id="cb58-4"><a></a>                   feature_dim, num_epochs)</span>
<span id="cb58-5"><a></a></span>
<span id="cb58-6"><a></a>data_iter, feature_dim <span class="op">=</span> d2l.get_data_ch11(batch_size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb58-7"><a></a>train_momentum(<span class="fl">0.02</span>, <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>loss: 0.243, 0.089 sec/epoch</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/momentum-training-output-2.svg" id="momentum-training" class="r-stretch"></section>
<section id="theoretical-analysis" class="slide level2">
<h2>Theoretical Analysis</h2>
<h3 id="quadratic-convex-functions">Quadratic Convex Functions</h3>
<ul>
<li>General form: <span class="math inline">\(h(\mathbf{x}) = \frac{1}{2} \mathbf{x}^\top \mathbf{Q} \mathbf{x} + \mathbf{x}^\top \mathbf{c} + b\)</span></li>
<li>For positive definite <span class="math inline">\(\mathbf{Q}\)</span>:
<ul>
<li>Minimizer at <span class="math inline">\(\mathbf{x}^* = -\mathbf{Q}^{-1} \mathbf{c}\)</span></li>
<li>Minimum value: <span class="math inline">\(b - \frac{1}{2} \mathbf{c}^\top \mathbf{Q}^{-1} \mathbf{c}\)</span></li>
</ul></li>
<li>Gradient: <span class="math inline">\(\partial_{\mathbf{x}} h(\mathbf{x}) = \mathbf{Q} (\mathbf{x} - \mathbf{Q}^{-1} \mathbf{c})\)</span></li>
</ul>
</section>
<section class="slide level2">

<h3 id="convergence-analysis">Convergence Analysis</h3>
<ul>
<li>For scalar function <span class="math inline">\(f(x) = \frac{\lambda}{2} x^2\)</span>:
<ul>
<li>Gradient descent: <span class="math inline">\(x_{t+1} = (1 - \eta \lambda) x_t\)</span></li>
<li>Convergence when <span class="math inline">\(|1 - \eta \lambda| &lt; 1\)</span></li>
<li>Exponential convergence rate</li>
</ul></li>
</ul>
<div id="cell-convergence-analysis" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a></a>lambdas <span class="op">=</span> [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">19</span>]</span>
<span id="cb60-2"><a></a>eta <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb60-3"><a></a>d2l.set_figsize((<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb60-4"><a></a><span class="cf">for</span> lam <span class="kw">in</span> lambdas:</span>
<span id="cb60-5"><a></a>    t <span class="op">=</span> d2l.numpy(d2l.arange(<span class="dv">20</span>))</span>
<span id="cb60-6"><a></a>    d2l.plt.plot(t, (<span class="dv">1</span> <span class="op">-</span> eta <span class="op">*</span> lam) <span class="op">**</span> t, label<span class="op">=</span><span class="ss">f'lambda = </span><span class="sc">{</span>lam<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb60-7"><a></a>d2l.plt.xlabel(<span class="st">'time'</span>)</span>
<span id="cb60-8"><a></a>d2l.plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="template_files/figure-revealjs/convergence-analysis-output-1.svg" id="convergence-analysis" class="r-stretch"></section>
<section id="summary-5" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Momentum replaces gradients with leaky averages</li>
<li>Key benefits:
<ul>
<li>Accelerates convergence</li>
<li>Works for both noise-free and noisy gradients</li>
<li>Prevents optimization stalling</li>
<li>Effective sample size: <span class="math inline">\(\frac{1}{1-\beta}\)</span></li>
</ul></li>
<li>Implementation requires:
<ul>
<li>Additional state vector (velocity)</li>
<li>Careful parameter tuning</li>
</ul></li>
</ul>
</section>
<section id="exercises-4" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>Experiment with different momentum and learning rate combinations</li>
<li>Analyze gradient descent and momentum for quadratic problems with multiple eigenvalues</li>
<li>Derive minimum value and minimizer for <span class="math inline">\(h(\mathbf{x}) = \frac{1}{2} \mathbf{x}^\top \mathbf{Q} \mathbf{x} + \mathbf{x}^\top \mathbf{c} + b\)</span></li>
<li>Investigate behavior with stochastic gradient descent and minibatch variants</li>
</ol>
<!-- ---
title: "Adam Optimization"
format: 
  revealjs:
    theme: custom.scss
    css: custom.css
    width: 1920
    height: 1080
    menu:
      side: right
      width: wide
    template-partials:
      - title-slide.html
    slide-number: c/t
    logo: "eclipse_logo_small.png"
    highlight-style: a11y
    incremental: false
    background-transition: fade
    footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy"
execute:
  eval: true
  echo: true
--- -->
</section></section>
<section>
<section id="adam-optimization" class="title-slide slide level1 center">
<h1>Adam Optimization</h1>
<ul>
<li>Adam combines multiple optimization techniques:
<ul>
<li>Stochastic Gradient Descent (SGD)</li>
<li>Minibatch processing</li>
<li>Momentum</li>
<li>Per-coordinate scaling (AdaGrad)</li>
<li>Learning rate adjustment (RMSProp)</li>
</ul></li>
<li>Popular in deep learning due to:
<ul>
<li>Robustness</li>
<li>Effectiveness</li>
<li>Computational efficiency</li>
</ul></li>
</ul>
</section>
<section id="previous-optimization-methods" class="slide level2">
<h2>Previous Optimization Methods</h2>
<ul>
<li>SGD: Efficient for redundant data</li>
<li>Minibatch SGD: Enables parallel processing</li>
<li>Momentum: Accelerates convergence</li>
<li>AdaGrad: Efficient preconditioning</li>
<li>RMSProp: Decoupled scaling</li>
</ul>
</section>
<section id="the-algorithm" class="slide level2">
<h2>The Algorithm</h2>
<h3 id="state-variables">State Variables</h3>
<ul>
<li>Uses exponential weighted moving averages</li>
<li>Momentum estimate: <span class="math display">\[\mathbf{v}_t \leftarrow \beta_1 \mathbf{v}_{t-1} + (1 - \beta_1) \mathbf{g}_t\]</span></li>
<li>Second moment estimate: <span class="math display">\[\mathbf{s}_t \leftarrow \beta_2 \mathbf{s}_{t-1} + (1 - \beta_2) \mathbf{g}_t^2\]</span></li>
<li>Typical values: <span class="math inline">\(\beta_1 = 0.9\)</span>, <span class="math inline">\(\beta_2 = 0.999\)</span></li>
</ul>
<h3 id="bias-correction">Bias Correction</h3>
<ul>
<li>Initial bias towards smaller values</li>
<li>Normalized state variables: <span class="math display">\[\hat{\mathbf{v}}_t = \frac{\mathbf{v}_t}{1 - \beta_1^t}\]</span> <span class="math display">\[\hat{\mathbf{s}}_t = \frac{\mathbf{s}_t}{1 - \beta_2^t}\]</span></li>
</ul>
</section>
<section class="slide level2">

<h3 id="update-rule">Update Rule</h3>
<ul>
<li>Rescaled gradient: <span class="math display">\[\mathbf{g}_t' = \frac{\eta \hat{\mathbf{v}}_t}{\sqrt{\hat{\mathbf{s}}_t} + \epsilon}\]</span></li>
<li>Parameter update: <span class="math display">\[\mathbf{x}_t \leftarrow \mathbf{x}_{t-1} - \mathbf{g}_t'\]</span></li>
<li>Typically <span class="math inline">\(\epsilon = 10^{-6}\)</span></li>
</ul>
</section>
<section id="implementation-6" class="slide level2">
<h2>Implementation</h2>
<h3 id="state-initialization">State Initialization</h3>
<div id="edf6c7fc" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a></a><span class="im">import</span> d2l</span>
<span id="cb61-2"><a></a><span class="im">import</span> torch</span>
<span id="cb61-3"><a></a><span class="co">#| label: init-states</span></span>
<span id="cb61-4"><a></a><span class="kw">def</span> init_adam_states(feature_dim):</span>
<span id="cb61-5"><a></a>    v_w, v_b <span class="op">=</span> d2l.zeros((feature_dim, <span class="dv">1</span>)), d2l.zeros(<span class="dv">1</span>)</span>
<span id="cb61-6"><a></a>    s_w, s_b <span class="op">=</span> d2l.zeros((feature_dim, <span class="dv">1</span>)), d2l.zeros(<span class="dv">1</span>)</span>
<span id="cb61-7"><a></a>    <span class="cf">return</span> ((v_w, s_w), (v_b, s_b))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<h3 id="adam-update">Adam Update</h3>
<div id="adam-update" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a></a><span class="kw">def</span> adam(params, states, hyperparams):</span>
<span id="cb62-2"><a></a>    beta1, beta2, eps <span class="op">=</span> <span class="fl">0.9</span>, <span class="fl">0.999</span>, <span class="fl">1e-6</span></span>
<span id="cb62-3"><a></a>    <span class="cf">for</span> p, (v, s) <span class="kw">in</span> <span class="bu">zip</span>(params, states):</span>
<span id="cb62-4"><a></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb62-5"><a></a>            <span class="co"># Update momentum</span></span>
<span id="cb62-6"><a></a>            v[:] <span class="op">=</span> beta1 <span class="op">*</span> v <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta1) <span class="op">*</span> p.grad</span>
<span id="cb62-7"><a></a>            <span class="co"># Update second moment</span></span>
<span id="cb62-8"><a></a>            s[:] <span class="op">=</span> beta2 <span class="op">*</span> s <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta2) <span class="op">*</span> torch.square(p.grad)</span>
<span id="cb62-9"><a></a>            <span class="co"># Bias correction</span></span>
<span id="cb62-10"><a></a>            v_bias_corr <span class="op">=</span> v <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> beta1 <span class="op">**</span> hyperparams[<span class="st">'t'</span>])</span>
<span id="cb62-11"><a></a>            s_bias_corr <span class="op">=</span> s <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> beta2 <span class="op">**</span> hyperparams[<span class="st">'t'</span>])</span>
<span id="cb62-12"><a></a>            <span class="co"># Parameter update</span></span>
<span id="cb62-13"><a></a>            p[:] <span class="op">-=</span> hyperparams[<span class="st">'lr'</span>] <span class="op">*</span> v_bias_corr <span class="op">/</span> (</span>
<span id="cb62-14"><a></a>                torch.sqrt(s_bias_corr) <span class="op">+</span> eps)</span>
<span id="cb62-15"><a></a>        p.grad.data.zero_()</span>
<span id="cb62-16"><a></a>    hyperparams[<span class="st">'t'</span>] <span class="op">+=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section class="slide level2">

<h3 id="training">Training</h3>
<div id="training" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a></a>data_iter, feature_dim <span class="op">=</span> d2l.get_data_ch11(batch_size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb63-2"><a></a>d2l.train_ch11(adam, init_adam_states(feature_dim),</span>
<span id="cb63-3"><a></a>               {<span class="st">'lr'</span>: <span class="fl">0.01</span>, <span class="st">'t'</span>: <span class="dv">1</span>}, data_iter, feature_dim)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>loss: 0.246, 0.117 sec/epoch</code></pre>
</div>
<div id="training-1" class="cell-output cell-output-display" data-execution_count="43">
<pre><code>([0.017148256301879883,
  0.03208518028259277,
  0.047471046447753906,
  0.06290531158447266,
  0.0791175365447998,
  0.09427881240844727,
  0.10961222648620605,
  0.12555718421936035,
  0.14097189903259277,
  0.15643548965454102,
  0.17159390449523926,
  0.18680453300476074,
  0.20263147354125977,
  0.21788454055786133,
  0.2335216999053955],
 [0.3833862506548564,
  0.31139746673901875,
  0.27013449573516846,
  0.25452979358037314,
  0.24769495431582134,
  0.24726733009020488,
  0.24354348778724672,
  0.24468712796767553,
  0.2462358455657959,
  0.2432505107720693,
  0.24375068044662476,
  0.24327284483114878,
  0.24355014717578888,
  0.24237807885805765,
  0.24601038785775503])</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/training-output-3.svg" id="training-2" class="r-stretch"></section>
<section class="slide level2">

<h3 id="concise-implementation">Concise Implementation</h3>
<div id="cell-concise-impl" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a></a>trainer <span class="op">=</span> torch.optim.Adam</span>
<span id="cb66-2"><a></a>d2l.train_concise_ch11(trainer, {<span class="st">'lr'</span>: <span class="fl">0.01</span>}, data_iter)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>loss: 0.242, 0.115 sec/epoch</code></pre>
</div>

</div>
<img data-src="template_files/figure-revealjs/concise-impl-output-2.svg" id="concise-impl" class="r-stretch"></section>
<section id="summary-6" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Adam combines multiple optimization techniques</li>
<li>Key features:
<ul>
<li>Momentum from RMSProp</li>
<li>Bias correction</li>
<li>Learning rate control</li>
</ul></li>
<li>Yogi variant:
<ul>
<li>Addresses convergence issues</li>
<li>Modified second moment update</li>
<li>Better variance control</li>
</ul></li>
</ul>
</section>
<section id="exercises-5" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>Experiment with learning rate adjustments</li>
<li>Rewrite momentum updates without bias correction</li>
<li>Analyze learning rate reduction during convergence</li>
<li>Construct divergence cases for Adam vs Yogi</li>
</ol>
</section></section>
<section>
<section id="sensor-fusion-as-a-regression-problem" class="title-slide slide level1 center">
<h1>Sensor Fusion as a Regression Problem</h1>
<ul>
<li>High-resolution chemical imaging in STEM is limited by inelastic scattering.</li>
<li>HAADF gives high SNR but lacks chemical specificity.</li>
<li>EDX/EELS gives chemistry but is noisy at low dose.</li>
<li>Goal: Fuse both signals for high-quality chemical maps.</li>
</ul>
</section>
<section id="data-fusion-as-inverse-problem" class="slide level2">
<h2>Data Fusion as Inverse Problem</h2>
<p><strong>Reconstruction goal:</strong> <span class="math display">\[
\hat{x} = \arg\min_{x \geq 0} \; \Psi_1(x) + \lambda_1 \Psi_2(x) + \lambda_2 \text{TV}(x)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\Psi_1\)</span>: HAADF model loss</li>
<li><span class="math inline">\(\Psi_2\)</span>: spectroscopic data fidelity</li>
<li><span class="math inline">\(\text{TV}(x)\)</span>: regularization term</li>
</ul>
</section>
<section id="first-term-haadf-consistency" class="slide level2">
<h2>First Term: HAADF Consistency</h2>
<p><strong>HAADF image model:</strong> <span class="math display">\[
\Psi_1(x) = \frac{1}{2} \| b_H - A x^\gamma \|_2^2
\]</span></p>
<ul>
<li><span class="math inline">\(b_H\)</span>: measured HAADF signal</li>
<li><span class="math inline">\(x^\gamma\)</span>: element-wise power (Z-contrast)</li>
<li><span class="math inline">\(\gamma \approx 1.7\)</span>: approximates Z-contrast</li>
</ul>
<p><strong>Interpretation:</strong> Ensure the fused chemical map explains HAADF contrast.</p>
</section>
<section id="second-term-spectroscopic-fidelity" class="slide level2">
<h2>Second Term: Spectroscopic Fidelity</h2>
<p><strong>Poisson noise model for EDX/EELS:</strong> <span class="math display">\[
\Psi_2(x) = \sum_i 1^T x_i - b_i^T \log(x_i + \varepsilon)
\]</span></p>
<ul>
<li><span class="math inline">\(x_i\)</span>: reconstructed map of element <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(b_i\)</span>: measured EDX/EELS signal for element <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\varepsilon\)</span>: small constant to avoid <span class="math inline">\(\log(0)\)</span></li>
</ul>
<p><strong>Interpretation:</strong> Match fused maps with noisy spectroscopic measurements.</p>
</section>
<section id="third-term-total-variation-tv" class="slide level2">
<h2>Third Term: Total Variation (TV)</h2>
<p><strong>Channel-wise total variation:</strong> <span class="math display">\[
\text{TV}(x) = \sum_i \|x_i\|_{TV}
\]</span></p>
<p><strong>Purpose:</strong> - Promote piecewise smooth maps - Reduce noise - Preserve edges</p>
<p><strong>Popular in:</strong> - Compressed sensing - Image denoising</p>
</section>
<section id="summary-of-loss-terms" class="slide level2">
<h2>Summary of Loss Terms</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Term</th>
<th>Meaning</th>
<th>Benefit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\Psi_1\)</span></td>
<td>HAADF consistency</td>
<td>Uses high SNR elastic signal</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\Psi_2\)</span></td>
<td>Spectroscopy fidelity</td>
<td>Honors noisy chemical data</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\text{TV}(x)\)</span></td>
<td>Regularization</td>
<td>Noise suppression and smoothness</td>
</tr>
</tbody>
</table>
<p>All terms are necessary for accurate low-dose chemical recovery.</p>
</section>
<section id="practical-results" class="slide level2">
<h2>Practical Results</h2>
<ul>
<li>Improves SNR by 300–500%.</li>
<li>Reduces required dose by &gt;10×.</li>
<li>Recovers stoichiometry with &lt;15% error.</li>
</ul>
</section>
<section id="takeaways" class="slide level2">
<h2>Takeaways</h2>
<ul>
<li>Multi-modal fusion = better signal, lower dose.</li>
<li>Expressed as interpretable optimization.</li>
<li>Each term plays a distinct role.</li>
</ul>
<p><strong>Future outlook:</strong> Combine with additional modalities (e.g., ABF, ptychography).</p>
</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
<ul>
<li>Tutorial on fusing EELS/X-EDS maps with HAADF for improved chemical resolution</li>
<li>Part 1 of 2: Atomic resolution HAADF and X-EDS dataset of DyScO<span class="math inline">\(_3\)</span></li>
<li>Python-based workflow with minimal user input (&lt;10 tunable lines)</li>
<li>Quick transformation of datasets into resolution-enhanced chemical maps</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Example Output</strong></p>
</div>
<div class="callout-content">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/Figure_3_Output.png" width="700"></p>
<figcaption>Raw vs Fused DyScO<span class="math inline">\(_3\)</span></figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="experimental-requirements" class="slide level2 callout-warning">
<h2>Experimental Requirements</h2>
<ul>
<li>Need both elastic (e.g., HAADF) and inelastic (e.g., EELS/X-EDS) maps</li>
<li>Elastic signal must provide Z-contrast</li>
<li>Inelastic signal must map all chemistries</li>
<li>All maps must have same dimensionality</li>
<li>Recommendation: Use simultaneously collected HAADF signal</li>
</ul>

<aside><div>
<p><span class="citation" data-cites="Schwartz_2022">Schwartz et al. (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span>, <span class="citation" data-cites="manassa2024fused">Manassa et al. (<a href="#/references" role="doc-biblioref" onclick="">2024</a>)</span></p>
</div></aside></section>
<section id="step-1-python-imports" class="slide level2">
<h2>Step 1: Python Imports</h2>
<div id="e5b9295c" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a></a><span class="im">import</span> data.fusion_utils <span class="im">as</span> utils</span>
<span id="cb68-2"><a></a><span class="im">from</span> scipy.sparse <span class="im">import</span> spdiags</span>
<span id="cb68-3"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb68-4"><a></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm </span>
<span id="cb68-5"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-2-data-loading" class="slide level2">
<h2>Step 2: Data Loading</h2>
<div id="4702b0ef" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a></a>data <span class="op">=</span> np.load(<span class="st">'data/PTO_Trilayer_dataset.npz'</span>)</span>
<span id="cb69-2"><a></a><span class="co"># Define element names and their atomic weights</span></span>
<span id="cb69-3"><a></a>elem_names<span class="op">=</span>[<span class="st">'Sc'</span>, <span class="st">'Dy'</span>, <span class="st">'O'</span>]</span>
<span id="cb69-4"><a></a>elem_weights<span class="op">=</span>[<span class="dv">21</span>,<span class="dv">66</span>,<span class="dv">8</span>]</span>
<span id="cb69-5"><a></a></span>
<span id="cb69-6"><a></a><span class="co"># Parse elastic HAADF data and inelastic chemical maps</span></span>
<span id="cb69-7"><a></a>HAADF <span class="op">=</span> data[<span class="st">'HAADF'</span>]</span>
<span id="cb69-8"><a></a>xx <span class="op">=</span> np.array([],dtype<span class="op">=</span>np.float32)</span>
<span id="cb69-9"><a></a><span class="cf">for</span> ee <span class="kw">in</span> elem_names:</span>
<span id="cb69-10"><a></a>    chemMap <span class="op">=</span> data[ee]</span>
<span id="cb69-11"><a></a>    <span class="cf">if</span> chemMap.shape <span class="op">!=</span> HAADF.shape:</span>
<span id="cb69-12"><a></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"The dimensions of </span><span class="sc">{</span>ee<span class="sc">}</span><span class="ss"> chemical map do not match HAADF dimensions."</span>)</span>
<span id="cb69-13"><a></a>    chemMap <span class="op">-=</span> np.<span class="bu">min</span>(chemMap)<span class="op">;</span> chemMap <span class="op">/=</span> np.<span class="bu">max</span>(chemMap)</span>
<span id="cb69-14"><a></a>    xx <span class="op">=</span> np.concatenate([xx,chemMap.flatten()])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!-- ::: {.callout-tip}
## Loading Alternative Formats
- For .dm3, .dm4, or .emd files: Use HyperSpy
- Documentation: [HyperSpy IO Guide](https://hyperspy.org/hyperspy-doc/v1.3/user_guide/io.html)
::: -->
</section>
<section id="step-3-data-reshaping" class="slide level2">
<h2>Step 3: Data Reshaping</h2>
<div id="33d67793" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a></a><span class="co"># Make Copy of Raw Measurements</span></span>
<span id="cb70-2"><a></a>xx0 <span class="op">=</span> xx.copy()</span>
<span id="cb70-3"><a></a></span>
<span id="cb70-4"><a></a><span class="co"># Parameters</span></span>
<span id="cb70-5"><a></a>gamma <span class="op">=</span> <span class="fl">1.6</span>  <span class="co"># Z-contrast scaling factor</span></span>
<span id="cb70-6"><a></a>(nx, ny) <span class="op">=</span> chemMap.shape<span class="op">;</span> nPix <span class="op">=</span> nx <span class="op">*</span> ny</span>
<span id="cb70-7"><a></a>nz <span class="op">=</span> <span class="bu">len</span>(elem_names)</span>
<span id="cb70-8"><a></a></span>
<span id="cb70-9"><a></a><span class="co"># Initialize TV Regularizers</span></span>
<span id="cb70-10"><a></a>reg <span class="op">=</span> utils.tvlib(nx,ny)</span>
<span id="cb70-11"><a></a></span>
<span id="cb70-12"><a></a><span class="co"># Normalize HAADF</span></span>
<span id="cb70-13"><a></a>HAADF <span class="op">-=</span> np.<span class="bu">min</span>(HAADF)<span class="op">;</span> HAADF <span class="op">/=</span> np.<span class="bu">max</span>(HAADF)</span>
<span id="cb70-14"><a></a>HAADF <span class="op">=</span> HAADF.flatten()</span>
<span id="cb70-15"><a></a></span>
<span id="cb70-16"><a></a><span class="co"># Create Measurement Matrix</span></span>
<span id="cb70-17"><a></a>A <span class="op">=</span> utils.create_weighted_measurement_matrix(nx,ny,nz,elem_weights,gamma,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-4-cost-function-parameters" class="slide level2">
<h2>Step 4: Cost Function Parameters</h2>
<div id="599c83e8" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a></a><span class="co"># Convergence Parameters</span></span>
<span id="cb71-2"><a></a>lambdaHAADF <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>nz <span class="co"># 1/nz (do not modify)</span></span>
<span id="cb71-3"><a></a>lambdaChem <span class="op">=</span> <span class="fl">0.08</span> <span class="co"># 0.05-0.3 (data consistency)</span></span>
<span id="cb71-4"><a></a>lambdaTV <span class="op">=</span> <span class="fl">0.15</span> <span class="co"># &lt;0.2  Total Variation denoising</span></span>
<span id="cb71-5"><a></a>nIter <span class="op">=</span> <span class="dv">30</span>      <span class="co"># typically converges in 10-15</span></span>
<span id="cb71-6"><a></a>bkg <span class="op">=</span> <span class="fl">2.4e-1</span>    <span class="co"># background subtraction</span></span>
<span id="cb71-7"><a></a></span>
<span id="cb71-8"><a></a><span class="co"># FGP TV Parameters</span></span>
<span id="cb71-9"><a></a>regularize <span class="op">=</span> <span class="va">True</span></span>
<span id="cb71-10"><a></a>nIter_TV <span class="op">=</span> <span class="dv">3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-5-algorithm-execution" class="slide level2">
<h2>Step 5: Algorithm Execution</h2>
<div id="cb8c07c2" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a></a><span class="co"># Initialize</span></span>
<span id="cb72-2"><a></a>xx <span class="op">=</span> xx0.copy()</span>
<span id="cb72-3"><a></a></span>
<span id="cb72-4"><a></a><span class="co"># Cost Functions</span></span>
<span id="cb72-5"><a></a>lsqFun <span class="op">=</span> <span class="kw">lambda</span> inData : <span class="fl">0.5</span> <span class="op">*</span> np.linalg.norm(A.dot(inData<span class="op">**</span>gamma) <span class="op">-</span> HAADF) <span class="op">**</span><span class="dv">2</span></span>
<span id="cb72-6"><a></a>poissonFun <span class="op">=</span> <span class="kw">lambda</span> inData : np.<span class="bu">sum</span>(xx0 <span class="op">*</span> np.log(inData <span class="op">+</span> <span class="fl">1e-8</span>) <span class="op">-</span> inData)</span>
<span id="cb72-7"><a></a></span>
<span id="cb72-8"><a></a><span class="co"># Initialize Cost Tracking</span></span>
<span id="cb72-9"><a></a>costHAADF <span class="op">=</span> np.zeros(nIter,dtype<span class="op">=</span>np.float32)</span>
<span id="cb72-10"><a></a>costChem <span class="op">=</span> np.zeros(nIter, dtype<span class="op">=</span>np.float32)</span>
<span id="cb72-11"><a></a>costTV <span class="op">=</span> np.zeros(nIter, dtype<span class="op">=</span>np.float32)</span>
<span id="cb72-12"><a></a></span>
<span id="cb72-13"><a></a><span class="co"># Main Loop</span></span>
<span id="cb72-14"><a></a><span class="cf">for</span> kk <span class="kw">in</span> tqdm(<span class="bu">range</span>(nIter)):</span>
<span id="cb72-15"><a></a>    <span class="co"># Optimization</span></span>
<span id="cb72-16"><a></a>    xx <span class="op">-=</span> gamma <span class="op">*</span> spdiags(xx<span class="op">**</span>(gamma <span class="op">-</span> <span class="dv">1</span>), [<span class="dv">0</span>], nz<span class="op">*</span>nx<span class="op">*</span>ny, nz<span class="op">*</span>nx<span class="op">*</span>ny) <span class="op">*</span> <span class="op">\</span></span>
<span id="cb72-17"><a></a>          lambdaHAADF <span class="op">*</span> A.transpose() <span class="op">*</span> (A.dot(xx<span class="op">**</span>gamma) <span class="op">-</span> HAADF) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb72-18"><a></a>          lambdaChem <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> xx0 <span class="op">/</span> (xx <span class="op">+</span> bkg))</span>
<span id="cb72-19"><a></a>    </span>
<span id="cb72-20"><a></a>    <span class="co"># Positivity Constraint</span></span>
<span id="cb72-21"><a></a>    xx[xx<span class="op">&lt;</span><span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb72-22"><a></a>    </span>
<span id="cb72-23"><a></a>    <span class="co"># TV Regularization</span></span>
<span id="cb72-24"><a></a>    <span class="cf">if</span> regularize:</span>
<span id="cb72-25"><a></a>        <span class="cf">for</span> zz <span class="kw">in</span> <span class="bu">range</span>(nz):</span>
<span id="cb72-26"><a></a>            xx[zz<span class="op">*</span>nPix:(zz<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>nPix] <span class="op">=</span> reg.fgp_tv(</span>
<span id="cb72-27"><a></a>                xx[zz<span class="op">*</span>nPix:(zz<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>nPix].reshape(nx,ny), </span>
<span id="cb72-28"><a></a>                lambdaTV, </span>
<span id="cb72-29"><a></a>                nIter_TV</span>
<span id="cb72-30"><a></a>            ).flatten()</span>
<span id="cb72-31"><a></a>            costTV[kk] <span class="op">+=</span> reg.tv(xx[zz<span class="op">*</span>nPix:(zz<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>nPix].reshape(nx,ny))</span>
<span id="cb72-32"><a></a>    </span>
<span id="cb72-33"><a></a>    <span class="co"># Track Costs</span></span>
<span id="cb72-34"><a></a>    costHAADF[kk] <span class="op">=</span> lsqFun(xx)</span>
<span id="cb72-35"><a></a>    costChem[kk] <span class="op">=</span> poissonFun(xx)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4604770d88ca40cdb77d59dd829f1da3","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
</section>
<section id="step-6-convergence-assessment" class="slide level2">
<h2>Step 6: Convergence Assessment</h2>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Convergence Criteria</strong></p>
</div>
<div class="callout-content">
<ul>
<li>All 3 cost functions should asymptotically approach low values</li>
<li>Look for:
<ul>
<li>Exponential decay</li>
<li>Brief overshooting (Lennard-Jones-like)</li>
<li>Avoid:
<ul>
<li>Incomplete convergence</li>
<li>Severe oscillations</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>

<img data-src="figs/Figure_4_Convergence.png" width="700" class="r-stretch quarto-figure-center"><p class="caption">Convergence Plot</p></section>
<section id="tv-weighting-effects" class="slide level2 callout-attention">
<h2>TV Weighting Effects</h2>

<img data-src="figs/Figure_5_TV.png" width="700" class="r-stretch quarto-figure-center"><p class="caption">TV Weighting Comparison</p><div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>TV Weighting Guidelines</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Under-weighting: Results in noisy reconstructions</li>
<li>Over-weighting: Causes blurring and feature loss</li>
<li>Best practice: Err on side of under-weighting
<ul>
<li>Noise is familiar to data</li>
<li>Oversmoothing creates unphysical artifacts</li>
</ul></li>
</ul>
</div>
</div>
</div>
</section>
<section id="results-visualization" class="slide level2">
<h2>Results Visualization</h2>
<div id="2c3ebd3e" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a></a><span class="co"># Display Cost Functions</span></span>
<span id="cb73-2"><a></a>utils.plot_convergence(costHAADF, lambdaHAADF, </span>
<span id="cb73-3"><a></a>                      costChem, lambdaChem, </span>
<span id="cb73-4"><a></a>                      costTV, lambdaTV)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="template_files/figure-revealjs/cell-51-output-1.svg" class="r-stretch"></section>
<section class="slide level2">

<div id="3f91c3b6" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a></a><span class="co"># Show Reconstructed Signal</span></span>
<span id="cb74-2"><a></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="bu">len</span>(elem_names)<span class="op">+</span><span class="dv">1</span>,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="fl">6.5</span>))</span>
<span id="cb74-3"><a></a>ax <span class="op">=</span> ax.flatten()</span>
<span id="cb74-4"><a></a>ax[<span class="dv">0</span>].imshow((A.dot(xx<span class="op">**</span>gamma)).reshape(nx,ny),cmap<span class="op">=</span><span class="st">'gray'</span>)<span class="op">;</span> ax[<span class="dv">0</span>].set_title(<span class="st">'HAADF'</span>)<span class="op">;</span> ax[<span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb74-5"><a></a>ax[<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(elem_names)].imshow((A.dot(xx<span class="op">**</span>gamma)).reshape(nx,ny)[<span class="dv">70</span>:<span class="dv">130</span>,<span class="dv">25</span>:<span class="dv">85</span>],cmap<span class="op">=</span><span class="st">'gray'</span>)<span class="op">;</span> ax[<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(elem_names)].set_title(<span class="st">'HAADF Cropped'</span>)<span class="op">;</span> ax[<span class="dv">1</span><span class="op">+</span><span class="bu">len</span>(elem_names)].axis(<span class="st">'off'</span>)</span>
<span id="cb74-6"><a></a></span>
<span id="cb74-7"><a></a><span class="cf">for</span> ii <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(elem_names)):</span>
<span id="cb74-8"><a></a>    ax[ii<span class="op">+</span><span class="dv">1</span>].imshow(xx[ii<span class="op">*</span>(nx<span class="op">*</span>ny):(ii<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>(nx<span class="op">*</span>ny)].reshape(nx,ny),cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb74-9"><a></a>    ax[ii<span class="op">+</span><span class="dv">2</span><span class="op">+</span><span class="bu">len</span>(elem_names)].imshow(xx[ii<span class="op">*</span>(nx<span class="op">*</span>ny):(ii<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>(nx<span class="op">*</span>ny)].reshape(nx,ny)[<span class="dv">70</span>:<span class="dv">130</span>,<span class="dv">25</span>:<span class="dv">85</span>],cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb74-10"><a></a>    </span>
<span id="cb74-11"><a></a>    ax[ii<span class="op">+</span><span class="dv">1</span>].set_title(elem_names[ii])</span>
<span id="cb74-12"><a></a>    ax[ii<span class="op">+</span><span class="dv">1</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb74-13"><a></a>    ax[ii<span class="op">+</span><span class="dv">2</span><span class="op">+</span><span class="bu">len</span>(elem_names)].set_title(elem_names[ii]<span class="op">+</span><span class="st">' Cropped'</span>)</span>
<span id="cb74-14"><a></a>    ax[ii<span class="op">+</span><span class="dv">2</span><span class="op">+</span><span class="bu">len</span>(elem_names)].axis(<span class="st">'off'</span>)</span>
<span id="cb74-15"><a></a></span>
<span id="cb74-16"><a></a>fig.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="template_files/figure-revealjs/cell-52-output-1.svg" class="r-stretch"></section>
<section class="slide level2">

<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Best Practices Summary</strong></p>
</div>
<div class="callout-content">
<ol type="1">
<li>Ensure proper data collection</li>
<li>Verify dimensional consistency</li>
<li>Start with recommended parameter ranges</li>
<li>Monitor convergence carefully</li>
<li>Validate results against physical expectations</li>
</ol>
</div>
</div>
</div>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-manassa2024fused" class="csl-entry" role="listitem">
Manassa, Jason, Miti Shah, Min Gee Cho, Zichao Wendy Di, Yi Jiang, Jeffrey A Fessler, Yu-Tsun Shao, Mary C Scott, Jonathan Schwartz, and Robert Hovden. 2024. <span>“Fused Multi-Modal Electron Microscopy.”</span> <em>Elemental Microscopy</em>. <a href="https://doi.org/10.69761/MXVR4353">https://doi.org/10.69761/MXVR4353</a>.
</div>
<div id="ref-Schwartz_2022" class="csl-entry" role="listitem">
Schwartz, Jonathan, Zichao Wendy Di, Yi Jiang, Alyssa J. Fielitz, Don-Hyung Ha, Sanjaya D. Perera, Ismail El Baggari, et al. 2022. <span>“Imaging Atomic-Scale Chemistry from Fused Multi-Modal Electron Microscopy.”</span> <em>Npj Computational Materials</em> 8 (11): 1–8. <a href="https://doi.org/10.1038/s41524-021-00692-5">https://doi.org/10.1038/s41524-021-00692-5</a>.
</div>
</div>
<script>
document.getElementById("marimo-frame").onload = function() {
    try {
        let iframeDoc = document.getElementById("marimo-frame").contentWindow.document;
        let marimoBadge = iframeDoc.querySelector("div.fixed.bottom-0.right-0.z-50");
        if (marimoBadge) {
            marimoBadge.style.display = "none";
            console.log("Marimo badge hidden successfully.");
        } else {
            console.log("Badge not found.");
        }
    } catch (error) {
        console.warn("Unable to modify iframe content due to CORS restrictions.");
    }
};
</script>
</section></section></div>

<div class="quarto-auto-generated-content" style="display: none;">
<p><img src="eclipse_logo_small.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy</p>
</div>
</div>

    </div>
  

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"right","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true,"width":"wide"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: false,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script type="application/vnd.jupyter.widget-state+json">
    {"state":{"4604770d88ca40cdb77d59dd829f1da3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_abdc592f94ee4e65ae0eaf26708e2b4f","IPY_MODEL_d2d797738343406dbec0af7722e01459","IPY_MODEL_edcd5fb801844699a619aa237de5f029"],"layout":"IPY_MODEL_55d5b6f89b804f14b14e724cb590c2eb","tabbable":null,"tooltip":null}},"4c30986b0762499fae34bcb819f50207":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d1ab44e7fd84dfeb949d8c982ba5341":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d5b6f89b804f14b14e724cb590c2eb":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75463792a3d64f858b22618725b8602a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abdc592f94ee4e65ae0eaf26708e2b4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_75463792a3d64f858b22618725b8602a","placeholder":"​","style":"IPY_MODEL_b195972c44ac41d78b4d09fd77c5a6eb","tabbable":null,"tooltip":null,"value":"100%"}},"b195972c44ac41d78b4d09fd77c5a6eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"cc6aecfc720b4dfb84a511920ff109ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d2d797738343406dbec0af7722e01459":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_4d1ab44e7fd84dfeb949d8c982ba5341","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f63cf5ed69054fcba82ab57455eb9111","tabbable":null,"tooltip":null,"value":30}},"edcd5fb801844699a619aa237de5f029":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_4c30986b0762499fae34bcb819f50207","placeholder":"​","style":"IPY_MODEL_cc6aecfc720b4dfb84a511920ff109ea","tabbable":null,"tooltip":null,"value":" 30/30 [00:01&lt;00:00, 20.31it/s]"}},"f63cf5ed69054fcba82ab57455eb9111":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/ECLIPSE-Lab\.github\.io\/public_presentations\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>