<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-927edb3cde42616945691bbf0360b549.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.30">

  <meta name="author" content="Prof.&nbsp;Dr.&nbsp;Philipp Pelz">
  <title>ECLIPSE Presentations – ML for Characterization and Processing  Lecture 6: Transfer Learning and Data Scarcity</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-6f2caa607f23f36d06aa80414e6ab815.css">
  <link rel="stylesheet" href="custom.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
    <h1 class="title"><p>ML for Characterization and Processing<br> Lecture 6: Transfer Learning and Data Scarcity</p></h1>
    
  <div class="quarto-title-authors">
    <div class="quarto-title-author">
  <div class="quarto-title-author-name">
  Prof.&nbsp;Dr.&nbsp;Philipp Pelz 
  </div>
                <p class="quarto-title-affiliation">
                FAU Erlangen-Nürnberg
              </p>
            <p class="quarto-title-affiliation">
                Institute of Micro- and Nanostructure Research
              </p>
          </div>
    </div>
  
    <!-- <div  class="footer-logos1"> -->
    <img src="logos/FAU.png" alt="FAU Logo" width="250px" style="position: absolute; bottom: 220px; left:550px;">
    <img src="logos/imn.png" alt="IMN Logo" width="270px" style="position: absolute; bottom: 220px; left: 900px;">
    <img src="logos/cenem.png" alt="CENEM Logo" width="320px" style="position: absolute; bottom: 220px; left: 1250px;">
    <img src="logos/erc.jpg" alt="ERC Logo" width="250px" style="position: absolute; bottom: 160px; left: 1650px;">
    <img src="logos/eclipse_logo.png" alt="Eclipse Logo" height="250px" style="position: absolute; bottom: 150px; left: -50px;">
  <!-- </div> -->
  </section>
<section id="welcome" class="slide level2">
<h2>Welcome</h2>
<h3 id="week-6-transfer-learning-data-scarcity-in-materials-characterization">Week 6 — Transfer Learning &amp; Data Scarcity in Materials Characterization</h3>
<p><strong>Goals for today:</strong></p>
<ul>
<li class="fragment">Understand why materials datasets are small<br>
</li>
<li class="fragment">Learn how transfer learning helps (and when it fails)<br>
</li>
<li class="fragment">Compare ImageNet vs modern foundation models<br>
</li>
<li class="fragment">Explore self-supervised learning for microstructures<br>
</li>
<li class="fragment">Learn how to train models with ~200 images</li>
</ul>
</section>
<section id="outline" class="slide level2">
<h2>Outline</h2>
<ol type="1">
<li class="fragment">The data scarcity problem<br>
</li>
<li class="fragment">Transfer learning basics<br>
</li>
<li class="fragment">ImageNet vs domain-specific pretraining<br>
</li>
<li class="fragment">Foundation models: SAM, ViTs, MAE, DINO<br>
</li>
<li class="fragment">Self-supervised pretraining for microstructures<br>
</li>
<li class="fragment">How to train with 200 images<br>
</li>
<li class="fragment">Summary</li>
</ol>
</section>
<section id="the-data-scarcity-problem" class="slide level2">
<h2>1. The Data Scarcity Problem</h2>
<p>Materials datasets are tiny:</p>
<ul>
<li class="fragment">SEM/TEM: 50–300 images<br>
</li>
<li class="fragment">EBSD: 10–40 maps<br>
</li>
<li class="fragment">AM melt pool videos: few sequences<br>
</li>
<li class="fragment">XRD: typically &lt;200 patterns</li>
</ul>
<p>Why?</p>
<ul>
<li class="fragment">Experiments cost time &amp; money<br>
</li>
<li class="fragment">Labeling requires expert knowledge<br>
</li>
<li class="fragment">High variability, limited reproducibility<br>
</li>
<li class="fragment">Proprietary/industrial constraints</li>
</ul>
<p><strong>Deep learning was designed for 1–10 million images.<br>
We have 100–500.</strong></p>
</section>
<section id="why-data-scarcity-breaks-vanilla-deep-learning" class="slide level2">
<h2>Why Data Scarcity Breaks Vanilla Deep Learning</h2>
<ul>
<li class="fragment">Overfitting<br>
</li>
<li class="fragment">Domain shift sensitivity<br>
</li>
<li class="fragment">Poor generalization across instruments/materials<br>
</li>
<li class="fragment">Lack of labeled examples</li>
</ul>
<p><strong>Solution:</strong><br>
Use transfer learning and self-supervised learning.</p>
</section>
<section id="transfer-learning-basics" class="slide level2">
<h2>2. Transfer Learning Basics</h2>
<p>Transfer learning = start from a pretrained model → adapt to your task.</p>
<p>Modes:</p>
<ul>
<li class="fragment"><strong>Feature extraction:</strong> freeze most layers<br>
</li>
<li class="fragment"><strong>Fine-tuning:</strong> allow deeper layers to adapt<br>
</li>
<li class="fragment"><strong>Full-domain adaptation:</strong> retrain backbone with small LR</li>
</ul>
<p>Benefits:</p>
<ul>
<li class="fragment">Reduces labeled data needs<br>
</li>
<li class="fragment">Stabilizes training<br>
</li>
<li class="fragment">Improves generalization<br>
</li>
<li class="fragment">Helps with noisy labels</li>
</ul>
</section>
<section id="why-transfer-learning-helps" class="slide level2">
<h2>Why Transfer Learning Helps</h2>
<p>Early CNN layers learn:</p>
<ul>
<li class="fragment">Edges<br>
</li>
<li class="fragment">Corners<br>
</li>
<li class="fragment">Local textures</li>
</ul>
<p>These are universal and useful for:</p>
<ul>
<li class="fragment">SEM<br>
</li>
<li class="fragment">Optical microscopy<br>
</li>
<li class="fragment">Fractography<br>
</li>
<li class="fragment">Corrosion patterns</li>
</ul>
<p>But not always suitable for:</p>
<ul>
<li class="fragment">TEM phase contrast<br>
</li>
<li class="fragment">EBSD patterns<br>
</li>
<li class="fragment">Periodic crystallographic contrast</li>
</ul>
</section>
<section id="imagenet-vs-domain-specific-pretraining" class="slide level2">
<h2>3. ImageNet vs Domain-Specific Pretraining</h2>
<p>ImageNet models know:</p>
<ul>
<li class="fragment">Dogs<br>
</li>
<li class="fragment">Trees<br>
</li>
<li class="fragment">Skies<br>
</li>
<li class="fragment">Human-made objects</li>
</ul>
<p>But they do <strong>not</strong> know:</p>
<ul>
<li class="fragment">Grains<br>
</li>
<li class="fragment">Precipitates<br>
</li>
<li class="fragment">Dislocation cells<br>
</li>
<li class="fragment">Kikuchi patterns<br>
</li>
<li class="fragment">AM melt pool textures</li>
</ul>
</section>
<section id="when-imagenet-transfer-works" class="slide level2">
<h2>When ImageNet Transfer Works</h2>
<ul>
<li class="fragment">SEM with strong edge contrast<br>
</li>
<li class="fragment">Optical microscopy<br>
</li>
<li class="fragment">Fracture surfaces<br>
</li>
<li class="fragment">Corrosion morphology<br>
</li>
<li class="fragment">Low-frequency textures</li>
</ul>
</section>
<section id="when-imagenet-transfer-fails" class="slide level2">
<h2>When ImageNet Transfer Fails</h2>
<ul>
<li class="fragment">TEM: contrast oscillations, phase contrast, thickness effects<br>
</li>
<li class="fragment">EBSD: crystallographic symmetry unseen in ImageNet<br>
</li>
<li class="fragment">High-frequency periodic microstructures<br>
</li>
<li class="fragment">Diffraction-like contrast</li>
</ul>
<p><strong>Conclusion:</strong><br>
ImageNet helps only if your data has natural-image statistics.</p>
</section>
<section id="foundation-models-for-vision" class="slide level2">
<h2>4. Foundation Models for Vision</h2>
<p>Foundation models = large pretrained models designed to generalize.</p>
<p>Examples:</p>
<ul>
<li class="fragment">Segment Anything Model (SAM)<br>
</li>
<li class="fragment">Vision Transformers (ViT)<br>
</li>
<li class="fragment">Masked Autoencoders (MAE)<br>
</li>
<li class="fragment">DINO / DINOv2<br>
</li>
<li class="fragment">CLIP</li>
</ul>
<p>These models learn broad visual priors independent of specific labels.</p>
</section>
<section id="segment-anything-model-sam" class="slide level2">
<h2>Segment Anything Model (SAM)</h2>
<p>Trained on 1B segmentation masks.</p>
<p>Strengths:</p>
<ul>
<li class="fragment">Great for interactive segmentation<br>
</li>
<li class="fragment">Very good boundary detection<br>
</li>
<li class="fragment">Useful for semi-automated labeling<br>
</li>
<li class="fragment">Zero-shot region proposals</li>
</ul>
<p>Weaknesses for materials:</p>
<ul>
<li class="fragment">Underperforms on TEM<br>
</li>
<li class="fragment">Weak on low-contrast SEM<br>
</li>
<li class="fragment">Misinterprets crystallographic boundaries<br>
</li>
<li class="fragment">Trained on natural imagery, not microstructures</li>
</ul>
<p><strong>SAM = Fantastic annotation tool, mediocre zero-shot microstructure segmenter.</strong></p>
</section>
<section id="sam-for-microscopy" class="slide level2">
<h2>SAM for Microscopy</h2>
<p>Adaptations exist:</p>
<ul>
<li class="fragment">Fine-tuned SAM for biological microscopy<br>
</li>
<li class="fragment">Experimental SAM variants for SEM/TEM</li>
</ul>
<p>Uses in materials:</p>
<ul>
<li class="fragment">Labeling precipitates with clicks<br>
</li>
<li class="fragment">Creating weak labels for grain boundaries<br>
</li>
<li class="fragment">Assisting segmentation of pores/defects</li>
</ul>
<p><strong>SAM accelerates annotation, not model performance.</strong></p>
</section>
<section id="vision-transformers-vit" class="slide level2">
<h2>Vision Transformers (ViT)</h2>
<p>ViTs treat images as patches (tokens).<br>
Excellent at: - Capturing long-range dependencies<br>
- Global texture representation<br>
- Morphology-level patterns</p>
<p>Weak points: - Need substantial pretraining<br>
- Overfit instantly with &lt;1000 images</p>
<p>ViTs + SSL = state-of-the-art representation learning for microstructures.</p>
</section>
<section id="masked-autoencoders-mae" class="slide level2">
<h2>Masked Autoencoders (MAE)</h2>
<p>MAE masks ~75% of the image → model reconstructs missing content.</p>
<p>Perfect for microstructures:</p>
<ul>
<li class="fragment">Learns grain texture prior<br>
</li>
<li class="fragment">Learns precipitate morphology<br>
</li>
<li class="fragment">Learns melt pool periodicity<br>
</li>
<li class="fragment">Learns EBSD-like orientation textures</li>
</ul>
<p>MAE pretraining works even with <strong>small unlabeled datasets</strong>.</p>
</section>
<section id="dino-dinov2" class="slide level2">
<h2>DINO / DINOv2</h2>
<p>Self-distillation for representation learning.</p>
<p>DINO strengths:</p>
<ul>
<li class="fragment">Exceptional clustering of microstructure types<br>
</li>
<li class="fragment">Good generalization across materials systems<br>
</li>
<li class="fragment">Strong for similarity search and embedding extraction</li>
</ul>
<p>DINOv2 is a strong foundation model for materials, but benefits from domain-adapted fine-tuning.</p>
</section>
<section id="foundation-model-summary" class="slide level2">
<h2>Foundation Model Summary</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Model</th>
<th>Usefulness for Materials</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ImageNet ResNet</td>
<td>★★☆☆☆</td>
<td>Helps for SEM/optical only</td>
</tr>
<tr class="even">
<td>SAM</td>
<td>★★★☆☆</td>
<td>Best annotation helper</td>
</tr>
<tr class="odd">
<td>ViT</td>
<td>★★★★☆</td>
<td>Needs pretraining; great for textures</td>
</tr>
<tr class="even">
<td>MAE</td>
<td>★★★★★</td>
<td>Best SSL for microstructure</td>
</tr>
<tr class="odd">
<td>DINO / DINOv2</td>
<td>★★★★★</td>
<td>Great embeddings and clustering</td>
</tr>
<tr class="even">
<td>CLIP</td>
<td>★★☆☆☆</td>
<td>Limited value without text modality</td>
</tr>
</tbody>
</table>
</section>
<section id="self-supervised-pretraining-for-microstructures" class="slide level2">
<h2>5. Self-Supervised Pretraining for Microstructures</h2>
<p>SSL learns from <em>unlabeled</em> micrographs, ideal for data-scarce fields.</p>
<p>Approaches:</p>
<ul>
<li class="fragment">Contrastive learning<br>
</li>
<li class="fragment">Masked image modeling (MAE)<br>
</li>
<li class="fragment">Rotation prediction<br>
</li>
<li class="fragment">Jigsaw tasks</li>
</ul>
</section>
<section id="why-ssl-is-a-game-changer" class="slide level2">
<h2>Why SSL is a Game-Changer</h2>
<p>SSL learns:</p>
<ul>
<li class="fragment">Grain boundary statistics<br>
</li>
<li class="fragment">Phase textures<br>
</li>
<li class="fragment">Precipitate morphology<br>
</li>
<li class="fragment">Melt pool periodicity<br>
</li>
<li class="fragment">Noise characteristics<br>
</li>
<li class="fragment">Crystallographic patterns (if present)</li>
</ul>
<p>No human labels required.</p>
</section>
<section id="contrastive-learning" class="slide level2">
<h2>Contrastive Learning</h2>
<p>Two augmented views → similar embedding.<br>
Different microstructures → distant embeddings.</p>
<p>Augmentations:</p>
<ul>
<li class="fragment">Rotation (if allowed by physics)<br>
</li>
<li class="fragment">Noise injection<br>
</li>
<li class="fragment">Blur<br>
</li>
<li class="fragment">Intensity remapping<br>
</li>
<li class="fragment">Cropping</li>
</ul>
<p><strong>PYTHONHERE</strong><br>
(Contrastive learning workflow)</p>
</section>
<section id="masked-microstructure-modeling-mae" class="slide level2">
<h2>Masked Microstructure Modeling (MAE)</h2>
<p>Mask most of the micrograph → reconstruct.</p>
<p>Why it excels:</p>
<ul>
<li class="fragment">SEM/TEM images have strong local redundancy<br>
</li>
<li class="fragment">Grain boundaries can be reconstructed from context<br>
</li>
<li class="fragment">AM cell patterns are periodic<br>
</li>
<li class="fragment">Precipitates have predictable shapes</li>
</ul>
<p>MAE = best current method for pretraining microstructure backbones.</p>
</section>
<section id="hybrid-ssl-supervised-fine-tuning" class="slide level2">
<h2>Hybrid SSL + Supervised Fine-Tuning</h2>
<p>Pipeline:</p>
<ol type="1">
<li class="fragment">Gather unlabeled micrographs<br>
</li>
<li class="fragment">SSL pretraining (MAE, DINO)<br>
</li>
<li class="fragment">Extract embeddings<br>
</li>
<li class="fragment">Fine-tune on 50–200 labeled images<br>
</li>
<li class="fragment">Validate on sample-level split</li>
</ol>
<p>SSL reduces labeled-data needs by 5–10×.</p>
</section>
<section id="how-to-train-with-only-200-images" class="slide level2">
<h2>6. How to Train with Only 200 Images</h2>
<h3 id="key-steps">Key steps:</h3>
<ol type="1">
<li class="fragment"><strong>Patch extraction</strong> (but split by specimen!)<br>
</li>
<li class="fragment"><strong>Strong augmentations</strong>: rotation, noise, blur, contrast<br>
</li>
<li class="fragment"><strong>Use SSL</strong> before supervised training<br>
</li>
<li class="fragment"><strong>Use small backbones</strong> (avoid huge models)<br>
</li>
<li class="fragment"><strong>Regularization</strong>: dropout, weight decay<br>
</li>
<li class="fragment"><strong>Low LR fine-tuning</strong><br>
</li>
<li class="fragment"><strong>Early stopping</strong><br>
</li>
<li class="fragment"><strong>Sample-level validation</strong></li>
</ol>
</section>
<section id="practical-pipeline" class="slide level2">
<h2>Practical Pipeline</h2>
<ol type="1">
<li class="fragment">Collect 100–200 micrographs<br>
</li>
<li class="fragment">Extract 10,000–30,000 patches<br>
</li>
<li class="fragment">Pretrain backbone with SSL<br>
</li>
<li class="fragment">Train downstream task (classification, segmentation)<br>
</li>
<li class="fragment">Evaluate on new specimens<br>
</li>
<li class="fragment">Visualize embeddings to ensure physical meaning</li>
</ol>
</section>
<section id="summary" class="slide level2">
<h2>7. Summary</h2>
<h3 id="key-insights">Key insights:</h3>
<ul>
<li class="fragment">Materials datasets are small → transfer learning is essential<br>
</li>
<li class="fragment">ImageNet helps, but only for SEM/optical<br>
</li>
<li class="fragment">Foundation models (SAM, ViTs, MAE, DINO) are promising but require adaptation<br>
</li>
<li class="fragment">Self-supervised learning (especially MAE/DINO) is ideal for microstructures<br>
</li>
<li class="fragment">With SSL + augmentation, you can train robust models with 200 images<br>
</li>
<li class="fragment">Microstructure ML is moving toward foundation-model-driven workflows</li>
</ul>
<p>Next week:<br>
<strong>Week 7 — Multi-Modal Fusion: Combining Images, Spectra &amp; Processing Data</strong></p>
</section>
<section id="questions" class="slide level2">
<h2>Questions?</h2>
<p>Use the chalkboard!</p>
<div>
<script>
document.getElementById("marimo-frame").onload = function() {
    try {
        let iframeDoc = document.getElementById("marimo-frame").contentWindow.document;
        let marimoBadge = iframeDoc.querySelector("div.fixed.bottom-0.right-0.z-50");
        if (marimoBadge) {
            marimoBadge.style.display = "none";
            console.log("Marimo badge hidden successfully.");
        } else {
            console.log("Badge not found.");
        }
    } catch (error) {
        console.warn("Unable to modify iframe content due to CORS restrictions.");
    }
};
</script>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="eclipse_logo_small.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>©Philipp Pelz - FAU Erlangen-Nürnberg - ML for Characterization and Processing</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"right","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true,"width":"wide"},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: false,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>