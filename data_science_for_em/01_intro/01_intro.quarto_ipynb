{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: |\n",
        "  Data Science for Electron Microscopy<br>\n",
        "  Lecture 1: Introduction\n",
        "bibliography: ref.bib\n",
        "# csl: custom.csl\n",
        "author:\n",
        "  - name: Prof. Dr. Philipp Pelz\n",
        "    affiliation: \n",
        "      - FAU Erlangen-Nürnberg\n",
        "      - Institute of Micro- and Nanostructure Research\n",
        "\n",
        "execute: \n",
        "  eval: true\n",
        "  echo: true\n",
        "format:\n",
        "    revealjs: \n",
        "        scroll-view:\n",
        "            activate: true\n",
        "            snap: mandatory\n",
        "            layout: full\n",
        "        width: 1920\n",
        "        height: 1080\n",
        "        menu:\n",
        "            side: right\n",
        "            width: wide\n",
        "        template-partials:\n",
        "            - title-slide.html\n",
        "        css: custom.css\n",
        "        theme: custom.scss\n",
        "        slide-number: c/t    \n",
        "        logo: \"eclipse_logo_small.png\" \n",
        "        highlight-style: a11y\n",
        "        incremental: false \n",
        "        background-transition: fade\n",
        "        footer: \"©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy\"\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Outline\n",
        "\n",
        "::: {.outline-container}\n",
        "\n",
        "::: {.outline-box .fragment}\n",
        "### Formalities\n",
        "![](02_imaging.png)\n",
        ":::\n",
        "\n",
        "::: {.outline-box .fragment}\n",
        "### Introduction <br>to<br> Electron<br> Microscopy<br> Data\n",
        "![](02_imaging.png)\n",
        ":::\n",
        "\n",
        "::: {.outline-box .fragment}\n",
        "### Basic Pytorch<br> Knowledge\n",
        "![](./images/pytorch.png)\n",
        ":::\n",
        "\n",
        "::: {.outline-box .fragment}\n",
        "### .\n",
        "![](./images/autograd.png)\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Formalities\n",
        "\n",
        "- [Course Website](https://pelzlab.science/DataScienceForElectronMicroscopy/)\n",
        "- 8-9 lectures\n",
        "- 1 graded miniproject (40% of the final grade)\n",
        "  - use of AI tools is allowed: \n",
        "    - e.g. [Github Copilot](https://github.com/features/copilot) [(free for students)](https://docs.github.com/en/education/about-github-education/github-education-for-students/apply-to-github-education-as-a-student)\n",
        "    - e.g. [Cursor](https://www.cursor.com/) (paid)\n",
        "    \n",
        "- 1 graded exam (60% of the final grade)\n",
        "\n",
        "## Book that covers many topics of the course\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "::: {layout=\"[[1]]\"}\n",
        "![[https://d2l.ai/](https://d2l.ai/)](./images/d2l.jpg){fig-align=\"center\" width=\"80%\"}\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "- Interactive deep learning book with code, math, and discussions\n",
        "- Implemented with PyTorch, NumPy/MXNet, JAX, and TensorFlow\n",
        "- Adopted at 500 universities from 70 countries\n",
        "\n",
        "- We will use the pytorch framework for our coding\n",
        "\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "## STEM capabilities\n",
        "\n",
        "- Imaging (Z–contrast, light-element, phase-contrast)  \n",
        "- 4D-STEM diffraction & orientation mapping  \n",
        "- Spectroscopies (EELS/XEDS, plasmonics)  \n",
        "- Tomography down to every atom  \n",
        "- Simulation & data-science backbone  \n",
        "\n",
        "---\n",
        "\n",
        "## STEM operating modes  \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"70%\"}\n",
        "![Figure 1a – STEM measurement families](./images/fig1a_imaging.png)\n",
        ":::\n",
        "::: {.column width=\"30%\"}\n",
        "- A modern microscope can switch **on the fly** between  \n",
        "  - incoherent imaging,  \n",
        "  - diffraction/4D-STEM,  \n",
        "  - EELS / XEDS spectroscopy, and  \n",
        "  - tilt-series tomography   \n",
        "- “A synchrotron in a microscope”: one tool covers Å-to-µm length-scales and meV-to-keV energy-scales.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## 4DSTEM - Diffraction from a crystalline sample\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"70%\"}\n",
        "\n",
        "{{< video ./images/crystal_diffraction2.mp4 width=\"900\" data-autoplay>}}\n",
        "\n",
        ":::\n",
        "::: {.column width=\"30%\"}\n",
        "- Ideally, the diffracted signal is simply a 2D Fourier transform of the projected potential, multiplied by the probe intensity.\n",
        "- Thus the position and intensity of Bragg disks of each diffraction pattern acts as a fingerprint for the local structure and orientation of the (crystal) sample.\n",
        "- Interpretation is complicated by multiple / dynamical scattering (thickness effects), overlapping grains, background signals.\n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "video courtesy of C. Ophus, Stanford University\n",
        ":::\n",
        "\n",
        "## 4DSTEM - Diffraction from a amorphous sample\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"70%\"}\n",
        "\n",
        "{{< video ./images/amorphous_diffraction2.mp4 width=\"900\" data-autoplay>}}\n",
        "\n",
        ":::\n",
        "::: {.column width=\"30%\"}\n",
        "- Ideally, the diffracted signal is simply a 2D Fourier transform of the projected potential, multiplied by the probe intensity.\n",
        "- The position and shape of amorphous halos of each diffraction pattern acts as a fingerprint for the local structure factor, given by the mean atomic arrangement.\n",
        "- Interpretation is complicated by multiple / dynamical scattering (thickness effects), overlapping grains, more than crystal diffraction.\n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "video courtesy of C. Ophus, Stanford University\n",
        ":::\n",
        "\n",
        "## 4DSTEM - Design of experiments\n",
        "\n",
        "::: {layout=\"[[1]]\"}\n",
        "![](./images/experiment_design.png){fig-align=\"center\" width=\"100%\"}\n",
        ":::\n",
        "\n",
        "## Single-atom Z-contrast  \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"60%\"}\n",
        "![Au atoms in Si](./images/fig3a_single_atom.png)\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "- **HAADF** collects high-angle incoherent scattering → intensity ∝ Z^1.6 – Z^1.9 \n",
        "- Detects & counts **individual heavy atoms**, even inside a nanowire.  \n",
        "- Sub-picometre column-position metrology enables strain & segregation studies.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "---\n",
        "\n",
        "\n",
        "## Calibrated composition imaging \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"60%\"}\n",
        "![AlGaN/GaN multilayer](./images/fig3b_quant_HAADF.png)\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "- Absolute detector-response calibration converts HAADF signal to **atomic areal density** .  \n",
        "- Enables **nm-scale composition profiles** (here Al₀.₂Ga₀.₈N) & local thickness determination to ≈1 nm.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Seeing light elements – ABF/BF \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"60%\"}\n",
        "![ABF of YH₂, H columns visible](./images/fig4c_ABF_H.png)\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "- **Annular Bright-Field (ABF)** records low-angle transmitted beam: simultaneously heavy & **very light atoms (H, Li, O)**  .  \n",
        "- Quantitative contrast modelling (multislice + frozen phonon) allows **thickness & defocus refinement**.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "---\n",
        "\n",
        "\n",
        "## Mapping internal fields – DPC  \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"60%\"}\n",
        "![DPC of Σ13 GB in SrTiO₃](./images/fig5a_DPC_GB.png)\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "- Segmented / pixelated detectors yield **differential phase-contrast (DPC)** images.  \n",
        "- Linear to projected **electric-field**; with sample flip or advanced analysis → **magnetic induction** too .  \n",
        "- Here: TiO₆ octahedra rotations and GB polarity resolved at the picometre level.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## 4D-STEM diffraction & orientation mapping  \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"60%\"}\n",
        "![4D-STEM of organic crystals](./images/fig6c4dstem.png){fig-align=\"center\" width=\"40%\"}\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "- Pixelated cameras record a **CBED pattern at every probe position** → 4D data cube.  \n",
        "- From disks, extract local strain, orientation, thickness, even (via ptychography) phases beyond the probe NA.  \n",
        "- Matching experiment to simulation (thermal + inelastic) achieves **quantitative thickness/chemistry**  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "---\n",
        "\n",
        "\n",
        "## Spectroscopy – EELS/XEDS  \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"60%\"}\n",
        "![Plasmonic resonances in Ag nanowire](./images/fig2e_plasmon_EELS.png)\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "- **STEM-EELS** resolves plasmons (few eV), phonons (meV) & core-loss fine structure (bonding, oxidation).  \n",
        "- Combined with modelling (BEM, DFT, multiplet) for **nanophotonic mode mapping** .  \n",
        "- Parallel XEDS gives simultaneous **3-D elemental maps**.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Atomic electron tomography  \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"60%\"}\n",
        "![AET of Au nanorod](./images/fig10a_AET.png)\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "- Tilt-series HAADF/ptychography + iterative reconstruction → **3-D coordinates of every atom** in ≤20 nm objects .  \n",
        "- Enables full **strain tensors**, defect cores, compositional ordering.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "---\n",
        "\n",
        "\n",
        "## Simulation accelerators – PRISM  \n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"60%\"}\n",
        "![PRISM algorithm](./images/fig2b_PRISM.png){fig-align=\"center\" width=\"40%\"}\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "- Quantitative STEM hinges on **ab-initio accurate multislice simulations**.  \n",
        "- **PRISM** re-uses plane-wave slices → orders-of-magnitude faster with <1 % error .  \n",
        "- Powers real-time experiment steering & big-data 4D-STEM analysis.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@ophus2023quantitative\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Take-aways\n",
        "\n",
        "- Modern aberration-corrected STEM delivers **Å-resolution imaging, diffraction, spectroscopy & tomography** within one instrument.  \n",
        "- **Quantification** (composition, fields, 3-D structure) now matches the resolution.  \n",
        "- Open-source **simulation & Python toolchains** are key enablers for truly **quantitative materials science**.  \n",
        "\n",
        "## The data-driven TEM framework (*Figure 1*)\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "![Fig 1 – three-layer framework](./images/fig1_framework.png)\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "- Three nested layers turn unknown samples → **quantifiable descriptors**  \n",
        "  1. **Experiment design**  \n",
        "  2. **Feature extraction**  \n",
        "  3. **Knowledge discovery**  \n",
        "- Open, interoperable control + AI links all layers into a virtuous cycle.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@Spurgeon_2020\n",
        ":::\n",
        "---\n",
        "\n",
        "\n",
        "## ① Experiment design (*Fig 1 top*)\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"48%\"}\n",
        "![Fig 1a – design grid](./images/fig1_framework.png)\n",
        ":::\n",
        "::: {.column width=\"52%\"}\n",
        "- GPU-accelerated simulations predict **detection limits & dose budgets** before the first electron hits the sample.  \n",
        "- ML mines prior-work databases (future) to recommend **optimal imaging / spectroscopy modes** in real time.  \n",
        "- Outcome: fewer trial-and-error sessions; **cost & time savings**.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@Spurgeon_2020\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## ② Feature extraction (*Fig 1 middle*)\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"48%\"}\n",
        "![Fig 1b – feature layer](./images/fig1_framework.png)\n",
        ":::\n",
        "::: {.column width=\"52%\"}\n",
        "- Records complete data streams (e.g. **4D-STEM diffraction cubes**) for flexible post-processing  \n",
        "- Combines complementary modalities to overcome projection & damage artefacts.  \n",
        "- Requires **automation** and low-level access for batch surveys & *in-situ* studies.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@Spurgeon_2020\n",
        ":::\n",
        "---\n",
        "\n",
        "\n",
        "## ③ Knowledge discovery (*Fig 1 bottom*)\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"48%\"}\n",
        "![Fig 1c – knowledge layer](./images/fig1_framework.png)\n",
        ":::\n",
        "::: {.column width=\"52%\"}\n",
        "- AI/ML trained on physical models classifies **multidimensional signals** → structure, bonding, dynamics.  \n",
        "- FAIR data standards and open repositories enable **meta-analysis & reproducibility**.  \n",
        "- Vision: adaptive microscopy where data choose the next experiment step on-the-fly.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@Spurgeon_2020\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Detectors drive the data deluge (*Figure 2 a*)\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"48%\"}\n",
        "![Fig 2a – data-rate timeline](./images/fig2a_datarate.png)\n",
        ":::\n",
        "::: {.column width=\"52%\"}\n",
        "- From film (1 GB h⁻¹) to **4D pixelated cameras (200 TB h⁻¹)** – a 10⁸× leap in two decades.  \n",
        "- Computing & storage must scale in lock-step; edge processing at the microscope becomes essential.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@Spurgeon_2020\n",
        ":::\n",
        "---\n",
        "\n",
        "\n",
        "## Workflow evolution (*Figure 2 b*)\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"48%\"}\n",
        "![Fig 2b – manual → augmented](./images/fig2b_workflow.png)\n",
        ":::\n",
        "::: {.column width=\"52%\"}\n",
        "- **Manual**: choose features “by eye”, serial data, iterative models.  \n",
        "- **Augmented**: collect **many data streams**, ML finds features, simulation-based model extraction.  \n",
        "- Integrated experiment control enables **closed-loop, crowd-sourced** materials discovery.  \n",
        ":::\n",
        ":::\n",
        "::: aside\n",
        "@Spurgeon_2020\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Take-aways\n",
        "\n",
        "- Modern STEM now spans **Å-scale resolution & petabyte-scale data**.  \n",
        "- A three-layer, open architecture (design → extraction → discovery) lets AI and simulation turn data into insight.  \n",
        "- Detector advances + FAIR data infrastructure set the stage for **truly adaptive, autonomous microscopy**.  \n",
        "\n",
        "## Course outline\n",
        "\n",
        "- Intro (13.05.2025)\n",
        "- Regression and Sensor Fusion (20.05.2025)\n",
        "- CNNs (27.05.2025)\n",
        "- Classification, Segmentation, AutoEncoders (03.06.2025)\n",
        "- Miniproject (3.6. - 24.6.2025) concurrent to lectures\n",
        "- Project Presentations, GANs (24.06.2025)\n",
        "- Gaussian Processes Introduction (01.07.2025)\n",
        "- Gaussian Processes Applications (08.07.2025)\n",
        "- Advanced Forward Models for Imaging: Tomography, Diffractive Imaging (15.07.2025)\n",
        "- Repetition (29.07.2025)\n",
        "\n",
        "## Miniproject\n",
        "\n",
        "- In the miniproject, you will test multiple deep neural network architectures on one of four microscopy-related tasks.\n",
        "- You should summarize your results in a short presentation (5 minutes + 2 minutes discussion) and deliver a Jupyter Notebook with your code and results.\n",
        "- The miniproject will be graded and will count as 40% towards your final grade.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Data Manipulation\n",
        "\n",
        "- Data handling requires two main tasks:\n",
        "  * Data acquisition\n",
        "  * Data processing\n",
        "\n",
        "- Key concepts for data manipulation:\n",
        "  * $n$-dimensional arrays (tensors) are fundamental\n",
        "  * Modern deep learning frameworks use tensor classes:\n",
        "    - `ndarray` in MXNet\n",
        "    - `Tensor` in PyTorch and TensorFlow\n",
        "    - Similar to NumPy's `ndarray` with additional features\n",
        "  * Key advantages of tensor classes:\n",
        "    - Support automatic differentiation\n",
        "    - GPU acceleration for numerical computation\n",
        "    - NumPy only runs on CPUs\n",
        "\n",
        "## Getting Started 1\n",
        "\n",
        "- Import PyTorch:"
      ],
      "id": "513e6a02"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch"
      ],
      "id": "198ac598",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Tensor basics:\n",
        "  * Vector: tensor with one axis\n",
        "  * Matrix: tensor with two axes\n",
        "  * $k^\\mathrm{th}$ order tensor: tensor with $k > 2$ axes\n",
        "\n",
        "- Tensor creation:\n",
        "  * Use `arange(n)` for evenly spaced values (0 to n-1)\n",
        "  * Default storage: main memory\n",
        "  * Default computation: CPU-based\n",
        "\n",
        "## Getting Started 2"
      ],
      "id": "e8036e9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = torch.arange(12, dtype=torch.float32)\n",
        "x"
      ],
      "id": "ee82ed36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Tensor elements:\n",
        "  * Each value is an element\n",
        "  * Use `numel()` to get total element count\n",
        "  * Use `shape` attribute to get dimensions"
      ],
      "id": "4b216466"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x.numel()\n",
        "x.shape"
      ],
      "id": "a0b0e546",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Reshaping tensors:\n",
        "  * Use `reshape` to change shape without changing values\n",
        "  * Example: vector (12,) → matrix (3, 4)\n",
        "  * Elements maintain order (row-major)"
      ],
      "id": "d2946319"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = x.reshape(3, 4)\n",
        "X"
      ],
      "id": "0cb54a17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting Started 3\n",
        "\n",
        "- Shape inference:\n",
        "  * Use `-1` to automatically infer one dimension\n",
        "  * Example: `x.reshape(-1, 4)` or `x.reshape(3, -1)`\n",
        "  * Given size $n$ and shape ($h$, $w$), $w = n/h$\n",
        "\n",
        "- Common tensor initializations:\n",
        "  * Zeros: `torch.zeros((2, 3, 4))`\n",
        "  * Ones: `torch.ones((2, 3, 4))`\n",
        "  * Random (Gaussian): `torch.randn(3, 4)`\n",
        "  * Custom values: `torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])`\n",
        "\n",
        "## Indexing and Slicing 1\n",
        "\n",
        "- Access methods:\n",
        "  * Indexing (0-based)\n",
        "  * Negative indexing (from end)\n",
        "  * Slicing (`start:stop`)\n",
        "  * Single index/slice applies to axis 0"
      ],
      "id": "997733e2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X[-1], X[1:3]"
      ],
      "id": "8d1ce403",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Element modification:\n",
        "  * Use indexing for assignment\n",
        "  * Example: `X[1, 2] = 17`\n",
        "\n",
        "## Indexing and Slicing 2\n",
        "\n",
        "- Multiple element assignment:\n",
        "  * Use indexing on left side of assignment\n",
        "  * `:` selects all elements along an axis\n",
        "  * Works for vectors and higher-dimensional tensors"
      ],
      "id": "ab728e93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X[:2, :] = 12\n",
        "X"
      ],
      "id": "1733f855",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Operations 1\n",
        "\n",
        "- Elementwise operations:\n",
        "  * Apply scalar operations to each element\n",
        "  * Work with corresponding element pairs\n",
        "  * Support unary operators (e.g., $e^x$)\n",
        "  * Signature: $f: \\mathbb{R} \\rightarrow \\mathbb{R}$"
      ],
      "id": "0851c766"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "torch.exp(x)"
      ],
      "id": "4a7566a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Operations 2\n",
        "\n",
        "- Binary operations:\n",
        "  * Work on pairs of real numbers\n",
        "  * Signature: $f: \\mathbb{R}, \\mathbb{R} \\rightarrow \\mathbb{R}$\n",
        "  * Common operators:\n",
        "    - Addition (`+`)\n",
        "    - Subtraction (`-`)\n",
        "    - Multiplication (`*`)\n",
        "    - Division (`/`)\n",
        "    - Exponentiation (`**`)"
      ],
      "id": "4a7f96f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = torch.tensor([1.0, 2, 4, 8])\n",
        "y = torch.tensor([2, 2, 2, 2])\n",
        "x + y, x - y, x * y, x / y, x ** y"
      ],
      "id": "6e6f5f3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Operations 3\n",
        "\n",
        "- Tensor concatenation:\n",
        "  * Use `torch.cat` with list of tensors\n",
        "  * Specify axis for concatenation\n",
        "  * Shape changes:\n",
        "    - Axis 0: sum of input axis-0 lengths\n",
        "    - Axis 1: sum of input axis-1 lengths"
      ],
      "id": "3d1b6abe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
        "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
      ],
      "id": "25f2cfcf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Operations 4\n",
        "\n",
        "- Logical operations:\n",
        "  * Create binary tensors via logical statements\n",
        "  * Example: `X == Y` creates tensor of 1s and 0s\n",
        "  * Sum operation: `X.sum()` reduces to single element"
      ],
      "id": "2b9ea699"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X == Y\n",
        "X.sum()"
      ],
      "id": "8597af32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Broadcasting\n",
        "\n",
        "- Mechanism for elementwise operations with different shapes:\n",
        "  * Step 1: Expand arrays along length-1 axes\n",
        "  * Step 2: Perform elementwise operation"
      ],
      "id": "83a3f6c7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "a = torch.arange(3).reshape((3, 1))\n",
        "b = torch.arange(2).reshape((1, 2))\n",
        "a + b"
      ],
      "id": "60b0a2f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Memory 1\n",
        "\n",
        "- Memory allocation issues:\n",
        "  * Operations create new memory allocations\n",
        "  * Example: `Y = X + Y` creates new memory\n",
        "  * Check with `id()` function\n",
        "  * Undesirable for:\n",
        "    - Frequent parameter updates\n",
        "    - Multiple variable references\n",
        "\n",
        "## Saving Memory 2\n",
        "\n",
        "- In-place operations:\n",
        "  * Use slice notation: `Y[:] = <expression>`\n",
        "  * Use `zeros_like` for initialization\n",
        "  * Use `X[:] = X + Y` or `X += Y` for efficiency"
      ],
      "id": "6a6c8c0a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Z = torch.zeros_like(Y)\n",
        "Z[:] = X + Y\n",
        "X += Y"
      ],
      "id": "1b1ccecd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion to Other Python Objects\n",
        "\n",
        "- NumPy conversion:\n",
        "  * `X.numpy()`: Tensor → NumPy array\n",
        "  * `torch.from_numpy(A)`: NumPy array → Tensor\n",
        "  * Shared memory between conversions\n",
        "\n",
        "- Scalar conversion:\n",
        "  * Use `item()` or built-in functions\n",
        "  * Example: `float(a)`, `int(a)`\n",
        "\n",
        "## Summary\n",
        "\n",
        "- Tensor class features:\n",
        "  * Data storage and manipulation\n",
        "  * Construction routines\n",
        "  * Indexing and slicing\n",
        "  * Basic mathematics\n",
        "  * Broadcasting\n",
        "  * Memory-efficient operations\n",
        "  * Python object conversion\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Experiment with different conditional statements:\n",
        "   * Try `X < Y` and `X > Y`\n",
        "   * Observe resulting tensor types\n",
        "\n",
        "2. Test broadcasting with 3D tensors:\n",
        "   * Try different shapes\n",
        "   * Verify results match expectations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Automatic Differentiation\n",
        "\n",
        "- Key points about derivatives in deep learning:\n",
        "  * Essential for optimization algorithms\n",
        "  * Used in training deep networks\n",
        "  * Manual calculation is:\n",
        "    - Tedious\n",
        "    - Error-prone\n",
        "    - More difficult with complex models\n",
        "\n",
        "- Modern deep learning frameworks provide:\n",
        "  * Automatic differentiation (autograd)\n",
        "  * Computational graph tracking\n",
        "  * Backpropagation implementation\n",
        "    - Works backwards through graph\n",
        "    - Applies chain rule\n",
        "    - Efficient gradient computation"
      ],
      "id": "33907f0d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch"
      ],
      "id": "e447a525",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A Simple Function\n",
        "\n",
        "- Goal: Differentiate $y = 2\\mathbf{x}^{\\top}\\mathbf{x}$ with respect to $\\mathbf{x}$\n",
        "- Initial setup:"
      ],
      "id": "fa861072"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = torch.arange(4.0)\n",
        "x"
      ],
      "id": "379a13bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Gradient storage considerations:\n",
        "  * Need space to store gradients\n",
        "  * Avoid new memory allocation for each derivative\n",
        "  * Important because:\n",
        "    - Deep learning requires many derivative computations\n",
        "    - Same parameters used repeatedly\n",
        "    - Memory efficiency crucial\n",
        "  * Gradient shape matches input vector shape"
      ],
      "id": "c601da2a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x.requires_grad_(True)\n",
        "x.grad  # The gradient is None by default"
      ],
      "id": "af0a07cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "\n",
        "- Function calculation:"
      ],
      "id": "850a6b11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y"
      ],
      "id": "2c96df87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Gradient computation:\n",
        "  * Use `backward()` method\n",
        "  * Access via `grad` attribute\n",
        "  * Expected result: $4\\mathbf{x}$"
      ],
      "id": "2e0711a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y.backward()\n",
        "x.grad\n",
        "x.grad == 4 * x"
      ],
      "id": "51146bfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Important note about gradient accumulation:\n",
        "  * PyTorch adds new gradients to existing ones\n",
        "  * Useful for optimizing sum of multiple objectives\n",
        "  * Reset with `x.grad.zero_()`"
      ],
      "id": "61220c32"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x.grad.zero_()  # Reset the gradient\n",
        "y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ],
      "id": "47d5f66a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backward for Non-Scalar Variables\n",
        "\n",
        "- Vector derivatives:\n",
        "  * Natural interpretation: Jacobian matrix\n",
        "  * Contains partial derivatives of each component\n",
        "  * Higher-order tensors for higher-order inputs\n",
        "\n",
        "- Common use case:\n",
        "  * Sum gradients of each component\n",
        "  * Often needed for batch processing\n",
        "  * Results in vector matching input shape\n",
        "\n",
        "- PyTorch implementation:\n",
        "  * Requires explicit reduction to scalar\n",
        "  * Uses vector $\\mathbf{v}$ for computation\n",
        "  * Computes $\\mathbf{v}^\\top \\partial_{\\mathbf{x}} \\mathbf{y}$\n",
        "  * Argument named `gradient` for historical reasons"
      ],
      "id": "f8be14ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "y.backward(gradient=torch.ones(len(y)))  # Faster: y.sum().backward()\n",
        "x.grad"
      ],
      "id": "b3e013ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detaching Computation\n",
        "\n",
        "- Purpose: Move calculations outside computational graph\n",
        "- Use cases:\n",
        "  * Create auxiliary terms without gradients\n",
        "  * Focus on direct influence of variables\n",
        "  * Control gradient flow\n",
        "\n",
        "- Example scenario:\n",
        "  * `z = x * y` and `y = x * x`\n",
        "  * Want direct influence of `x` on `z`\n",
        "  * Solution: Detach `y` to create `u`\n",
        "  * Results in:\n",
        "    - Same value as `y`\n",
        "    - No gradient flow through `u`\n",
        "    - Direct computation of `z = x * u`"
      ],
      "id": "6298c015"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach()\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ],
      "id": "3af69c9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Important notes:\n",
        "  * Detaches ancestors from graph\n",
        "  * Original graph for `y` persists\n",
        "  * Can still compute gradients for `y`"
      ],
      "id": "f1d29c3f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x.grad.zero_()\n",
        "y.sum().backward()\n",
        "x.grad == 2 * x"
      ],
      "id": "35c8c60b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradients and Python Control Flow\n",
        "\n",
        "- Key feature: Works with dynamic computation paths\n",
        "- Supports:\n",
        "  * Conditional statements\n",
        "  * Loops\n",
        "  * Arbitrary function calls\n",
        "  * Variable-dependent control flow\n",
        "\n",
        "- Example function:"
      ],
      "id": "ed6d23e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c"
      ],
      "id": "87aeddec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "- Implementation details:\n",
        "  * Graph built during execution\n",
        "  * Specific path for each input\n",
        "  * Supports backward pass after execution\n",
        "  * Works with linear functions and piecewise definitions"
      ],
      "id": "9be9297d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()\n",
        "a.grad == d / a"
      ],
      "id": "287bffc3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Real-world applications:\n",
        "  * Text processing with variable lengths\n",
        "  * Dynamic model architectures\n",
        "  * Statistical modeling\n",
        "  * Impossible to compute gradients a priori\n",
        "\n",
        "## Discussion\n",
        "\n",
        "- Impact of automatic differentiation:\n",
        "  * Massive productivity boost\n",
        "  * Enables complex model design\n",
        "  * Frees practitioners for higher-level tasks\n",
        "\n",
        "- Technical aspects:\n",
        "  * Optimization of autograd libraries\n",
        "  * Compiler and graph manipulation tools\n",
        "  * Memory efficiency\n",
        "  * Computational efficiency\n",
        "\n",
        "- Basic workflow:\n",
        "  1. Attach gradients to target variables\n",
        "  2. Record target value computation\n",
        "  3. Execute backpropagation\n",
        "  4. Access resulting gradient\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Backpropagation behavior:\n",
        "   * Run function twice\n",
        "   * Observe and explain results\n",
        "\n",
        "2. Control flow analysis:\n",
        "   * Change `a` to vector/matrix\n",
        "   * Analyze non-scalar results\n",
        "   * Explain computation changes\n",
        "\n",
        "3. Automatic differentiation practice:\n",
        "   * Plot $f(x) = \\sin(x)$\n",
        "   * Plot derivative using autograd\n",
        "   * Avoid using known derivative formula\n",
        "\n",
        "---\n",
        "\n",
        "4. Chain rule exercise:\n",
        "   * Function: $f(x) = ((\\log x^2) \\cdot \\sin x) + x^{-1}$\n",
        "   * Create dependency graph\n",
        "   * Compute derivative using chain rule\n",
        "   * Map terms to dependency graph\n",
        "\n",
        "5. Let $f(x) = ((\\log x^2) \\cdot \\sin x) + x^{-1}$. Write out a dependency graph tracing results from $x$ to $f(x)$. \n",
        "\n",
        "---\n",
        "\n",
        "6. Use the chain rule to compute the derivative $\\frac{df}{dx}$ of the aforementioned function, placing each term on the dependency graph that you constructed previously. \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## References\n",
        "::: {#refs}\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<script>\n",
        "document.getElementById(\"marimo-frame\").onload = function() {\n",
        "    try {\n",
        "        let iframeDoc = document.getElementById(\"marimo-frame\").contentWindow.document;\n",
        "        let marimoBadge = iframeDoc.querySelector(\"div.fixed.bottom-0.right-0.z-50\");\n",
        "        if (marimoBadge) {\n",
        "            marimoBadge.style.display = \"none\";\n",
        "            console.log(\"Marimo badge hidden successfully.\");\n",
        "        } else {\n",
        "            console.log(\"Badge not found.\");\n",
        "        }\n",
        "    } catch (error) {\n",
        "        console.warn(\"Unable to modify iframe content due to CORS restrictions.\");\n",
        "    }\n",
        "};\n",
        "</script>\n",
        "</div>"
      ],
      "id": "ca4c1874"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}