<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d9ea220ee908cb7322d1b5aeb522d8d4.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="../../site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.36">

  <meta name="author" content="Prof.&nbsp;Dr.&nbsp;Philipp Pelz">
  <title>ECLIPSE Presentations – Data Science for Electron Microscopy  Lecture 1: Introduction</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #97947a;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #97947a;  padding-left: 4px; }
    div.sourceCode
      { color: #f8f8f2; background-color: #2b2b2b; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #f8f8f2; } /* Normal */
    code span.al { color: #dcc6e0; } /* Alert */
    code span.an { color: #d4d0ab; } /* Annotation */
    code span.at { color: #ffd700; } /* Attribute */
    code span.bn { color: #dcc6e0; } /* BaseN */
    code span.bu { color: #f5ab35; } /* BuiltIn */
    code span.cf { color: #ffa07a; } /* ControlFlow */
    code span.ch { color: #abe338; } /* Char */
    code span.cn { color: #ffa07a; } /* Constant */
    code span.co { color: #d4d0ab; } /* Comment */
    code span.cv { color: #d4d0ab; font-style: italic; } /* CommentVar */
    code span.do { color: #d4d0ab; font-style: italic; } /* Documentation */
    code span.dt { color: #dcc6e0; } /* DataType */
    code span.dv { color: #dcc6e0; } /* DecVal */
    code span.er { color: #dcc6e0; } /* Error */
    code span.ex { color: #ffd700; } /* Extension */
    code span.fl { color: #f5ab35; } /* Float */
    code span.fu { color: #ffd700; } /* Function */
    code span.im { color: #f8f8f2; } /* Import */
    code span.in { color: #d4d0ab; } /* Information */
    code span.kw { color: #ffa07a; } /* Keyword */
    code span.op { color: #00e0e0; } /* Operator */
    code span.ot { color: #ffa07a; } /* Other */
    code span.pp { color: #dcc6e0; } /* Preprocessor */
    code span.sc { color: #00e0e0; } /* SpecialChar */
    code span.ss { color: #abe338; } /* SpecialString */
    code span.st { color: #abe338; } /* String */
    code span.va { color: #f5ab35; } /* Variable */
    code span.vs { color: #abe338; } /* VerbatimString */
    code span.wa { color: #d4d0ab; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-dc974aec7c6e41d67b96b1eadf3565d9.css">
  <link rel="stylesheet" href="custom.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
    <h1 class="title"><p>Data Science for Electron Microscopy<br> Lecture 1: Introduction</p></h1>
    
  <div class="quarto-title-authors">
    <div class="quarto-title-author">
  <div class="quarto-title-author-name">
  Prof.&nbsp;Dr.&nbsp;Philipp Pelz 
  </div>
                <p class="quarto-title-affiliation">
                FAU Erlangen-Nürnberg
              </p>
            <p class="quarto-title-affiliation">
                Institute of Micro- and Nanostructure Research
              </p>
          </div>
    </div>
  
    <div class="footer-logos1">
    <img src="logos/FAU.png" alt="FAU Logo" width="20%">
    <img src="logos/imn.png" alt="IMN Logo" width="20%">
    <img src="logos/cenem.png" alt="CENEM Logo" width="20%">
    <img src="logos/erc.jpg" alt="Elettra Logo" width="20%">
  </div>
  </section>
<section id="outline" class="slide level2">
<h2>Outline</h2>
<div class="outline-container">
<div class="outline-box fragment">
<h3 id="formalities">Formalities</h3>
<p><img data-src="02_imaging.png"></p>
</div>
<div class="outline-box fragment">
<h3 id="introduction-to-electron-microscopy-data">Introduction <br>to<br> Electron<br> Microscopy<br> Data</h3>
<p><img data-src="02_imaging.png"></p>
</div>
<div class="outline-box fragment">
<h3 id="basic-pytorch-knowledge">Basic Pytorch<br> Knowledge</h3>
<p><img data-src="./images/pytorch.png"></p>
</div>
<div class="outline-box fragment">
<h3 id="section">.</h3>
<p><img data-src="./images/autograd.png"></p>
</div>
</div>
</section>
<section id="formalities-1" class="slide level2">
<h2>Formalities</h2>
<ul>
<li><a href="https://pelzlab.science/DataScienceForElectronMicroscopy/">Course Website</a></li>
<li>8-9 lectures</li>
<li>1 graded miniproject (40% of the final grade)
<ul>
<li>use of AI tools is allowed:
<ul>
<li>e.g.&nbsp;<a href="https://github.com/features/copilot">Github Copilot</a> <a href="https://docs.github.com/en/education/about-github-education/github-education-for-students/apply-to-github-education-as-a-student">(free for students)</a></li>
<li>e.g.&nbsp;<a href="https://www.cursor.com/">Cursor</a> (paid)</li>
</ul></li>
</ul></li>
<li>1 graded exam (60% of the final grade)</li>
</ul>
</section>
<section id="book-that-covers-many-topics-of-the-course" class="slide level2">
<h2>Book that covers many topics of the course</h2>
<div class="columns">
<div class="column" style="width:40%;">
<div>

</div>
<div class="quarto-layout-panel" data-layout="[[1]]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/d2l.jpg" style="width:80.0%"></p>
<figcaption><a href="https://d2l.ai/">https://d2l.ai/</a></figcaption>
</figure>
</div>
</div>
</div>
</div>
</div><div class="column" style="width:60%;">
<ul>
<li><p>Interactive deep learning book with code, math, and discussions</p></li>
<li><p>Implemented with PyTorch, NumPy/MXNet, JAX, and TensorFlow</p></li>
<li><p>Adopted at 500 universities from 70 countries</p></li>
<li><p>We will use the pytorch framework for our coding</p></li>
</ul>
</div></div>
</section>
<section id="stem-capabilities" class="slide level2">
<h2>STEM capabilities</h2>
<ul>
<li>Imaging (Z–contrast, light-element, phase-contrast)<br>
</li>
<li>4D-STEM diffraction &amp; orientation mapping<br>
</li>
<li>Spectroscopies (EELS/XEDS, plasmonics)<br>
</li>
<li>Tomography down to every atom<br>
</li>
<li>Simulation &amp; data-science backbone</li>
</ul>
</section>
<section id="stem-operating-modes" class="slide level2">
<h2>STEM operating modes</h2>
<div class="columns">
<div class="column" style="width:70%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig1a_imaging.png"></p>
<figcaption>Figure 1a – STEM measurement families</figcaption>
</figure>
</div>
</div><div class="column" style="width:30%;">
<ul>
<li>A modern microscope can switch <strong>on the fly</strong> between
<ul>
<li>incoherent imaging,<br>
</li>
<li>diffraction/4D-STEM,<br>
</li>
<li>EELS / XEDS spectroscopy, and<br>
</li>
<li>tilt-series tomography<br>
</li>
</ul></li>
<li>“A synchrotron in a microscope”: one tool covers Å-to-µm length-scales and meV-to-keV energy-scales.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="dstem---diffraction-from-a-crystalline-sample" class="slide level2">
<h2>4DSTEM - Diffraction from a crystalline sample</h2>
<div class="columns">
<div class="column" style="width:70%;">
<video id="video_shortcode_videojs_video1" width="900" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="./images/crystal_diffraction2.mp4"></video>
</div><div class="column" style="width:30%;">
<ul>
<li>Ideally, the diffracted signal is simply a 2D Fourier transform of the projected potential, multiplied by the probe intensity.</li>
<li>Thus the position and intensity of Bragg disks of each diffraction pattern acts as a fingerprint for the local structure and orientation of the (crystal) sample.</li>
<li>Interpretation is complicated by multiple / dynamical scattering (thickness effects), overlapping grains, background signals.</li>
</ul>
</div></div>

<aside><div>
<p>video courtesy of C. Ophus, Stanford University</p>
</div></aside></section>
<section id="dstem---diffraction-from-a-amorphous-sample" class="slide level2">
<h2>4DSTEM - Diffraction from a amorphous sample</h2>
<div class="columns">
<div class="column" style="width:70%;">
<video id="video_shortcode_videojs_video2" width="900" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="./images/amorphous_diffraction2.mp4"></video>
</div><div class="column" style="width:30%;">
<ul>
<li>Ideally, the diffracted signal is simply a 2D Fourier transform of the projected potential, multiplied by the probe intensity.</li>
<li>The position and shape of amorphous halos of each diffraction pattern acts as a fingerprint for the local structure factor, given by the mean atomic arrangement.</li>
<li>Interpretation is complicated by multiple / dynamical scattering (thickness effects), overlapping grains, more than crystal diffraction.</li>
</ul>
</div></div>

<aside><div>
<p>video courtesy of C. Ophus, Stanford University</p>
</div></aside></section>
<section id="dstem---design-of-experiments" class="slide level2">
<h2>4DSTEM - Design of experiments</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[[1]]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/experiment_design.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="single-atom-z-contrast" class="slide level2">
<h2>Single-atom Z-contrast</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig3a_single_atom.png"></p>
<figcaption>Au atoms in Si</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<ul>
<li><strong>HAADF</strong> collects high-angle incoherent scattering → intensity ∝ Z^1.6 – Z^1.9</li>
<li>Detects &amp; counts <strong>individual heavy atoms</strong>, even inside a nanowire.<br>
</li>
<li>Sub-picometre column-position metrology enables strain &amp; segregation studies.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="calibrated-composition-imaging" class="slide level2">
<h2>Calibrated composition imaging</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig3b_quant_HAADF.png"></p>
<figcaption>AlGaN/GaN multilayer</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<ul>
<li>Absolute detector-response calibration converts HAADF signal to <strong>atomic areal density</strong> .<br>
</li>
<li>Enables <strong>nm-scale composition profiles</strong> (here Al₀.₂Ga₀.₈N) &amp; local thickness determination to ≈1 nm.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="seeing-light-elements-abfbf" class="slide level2">
<h2>Seeing light elements – ABF/BF</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig4c_ABF_H.png"></p>
<figcaption>ABF of YH₂, H columns visible</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<ul>
<li><strong>Annular Bright-Field (ABF)</strong> records low-angle transmitted beam: simultaneously heavy &amp; <strong>very light atoms (H, Li, O)</strong> .<br>
</li>
<li>Quantitative contrast modelling (multislice + frozen phonon) allows <strong>thickness &amp; defocus refinement</strong>.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="mapping-internal-fields-dpc" class="slide level2">
<h2>Mapping internal fields – DPC</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig5a_DPC_GB.png"></p>
<figcaption>DPC of Σ13 GB in SrTiO₃</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<ul>
<li>Segmented / pixelated detectors yield <strong>differential phase-contrast (DPC)</strong> images.<br>
</li>
<li>Linear to projected <strong>electric-field</strong>; with sample flip or advanced analysis → <strong>magnetic induction</strong> too .<br>
</li>
<li>Here: TiO₆ octahedra rotations and GB polarity resolved at the picometre level.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="d-stem-diffraction-orientation-mapping" class="slide level2">
<h2>4D-STEM diffraction &amp; orientation mapping</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig6c4dstem.png" style="width:40.0%"></p>
<figcaption>4D-STEM of organic crystals</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<ul>
<li>Pixelated cameras record a <strong>CBED pattern at every probe position</strong> → 4D data cube.<br>
</li>
<li>From disks, extract local strain, orientation, thickness, even (via ptychography) phases beyond the probe NA.<br>
</li>
<li>Matching experiment to simulation (thermal + inelastic) achieves <strong>quantitative thickness/chemistry</strong><br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="spectroscopy-eelsxeds" class="slide level2">
<h2>Spectroscopy – EELS/XEDS</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig2e_plasmon_EELS.png"></p>
<figcaption>Plasmonic resonances in Ag nanowire</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<ul>
<li><strong>STEM-EELS</strong> resolves plasmons (few eV), phonons (meV) &amp; core-loss fine structure (bonding, oxidation).<br>
</li>
<li>Combined with modelling (BEM, DFT, multiplet) for <strong>nanophotonic mode mapping</strong> .<br>
</li>
<li>Parallel XEDS gives simultaneous <strong>3-D elemental maps</strong>.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="atomic-electron-tomography" class="slide level2">
<h2>Atomic electron tomography</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig10a_AET.png"></p>
<figcaption>AET of Au nanorod</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<ul>
<li>Tilt-series HAADF/ptychography + iterative reconstruction → <strong>3-D coordinates of every atom</strong> in ≤20 nm objects .<br>
</li>
<li>Enables full <strong>strain tensors</strong>, defect cores, compositional ordering.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="simulation-accelerators-prism" class="slide level2">
<h2>Simulation accelerators – PRISM</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig2b_PRISM.png" style="width:40.0%"></p>
<figcaption>PRISM algorithm</figcaption>
</figure>
</div>
</div><div class="column" style="width:40%;">
<ul>
<li>Quantitative STEM hinges on <strong>ab-initio accurate multislice simulations</strong>.<br>
</li>
<li><strong>PRISM</strong> re-uses plane-wave slices → orders-of-magnitude faster with &lt;1 % error .<br>
</li>
<li>Powers real-time experiment steering &amp; big-data 4D-STEM analysis.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="ophus2023quantitative">Ophus (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span></p>
</div></aside></section>
<section id="take-aways" class="slide level2">
<h2>Take-aways</h2>
<ul>
<li>Modern aberration-corrected STEM delivers <strong>Å-resolution imaging, diffraction, spectroscopy &amp; tomography</strong> within one instrument.<br>
</li>
<li><strong>Quantification</strong> (composition, fields, 3-D structure) now matches the resolution.<br>
</li>
<li>Open-source <strong>simulation &amp; Python toolchains</strong> are key enablers for truly <strong>quantitative materials science</strong>.</li>
</ul>
</section>
<section id="the-data-driven-tem-framework-figure-1" class="slide level2">
<h2>The data-driven TEM framework (<em>Figure 1</em>)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig1_framework.png"></p>
<figcaption>Fig 1 – three-layer framework</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<ul>
<li>Three nested layers turn unknown samples → <strong>quantifiable descriptors</strong>
<ol type="1">
<li><strong>Experiment design</strong><br>
</li>
<li><strong>Feature extraction</strong><br>
</li>
<li><strong>Knowledge discovery</strong><br>
</li>
</ol></li>
<li>Open, interoperable control + AI links all layers into a virtuous cycle.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="Spurgeon_2020">Spurgeon et al. (<a href="#/references" role="doc-biblioref" onclick="">2020</a>)</span></p>
</div></aside></section>
<section id="experiment-design-fig-1-top" class="slide level2">
<h2>① Experiment design (<em>Fig 1 top</em>)</h2>
<div class="columns">
<div class="column" style="width:48%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig1_framework.png"></p>
<figcaption>Fig 1a – design grid</figcaption>
</figure>
</div>
</div><div class="column" style="width:52%;">
<ul>
<li>GPU-accelerated simulations predict <strong>detection limits &amp; dose budgets</strong> before the first electron hits the sample.<br>
</li>
<li>ML mines prior-work databases (future) to recommend <strong>optimal imaging / spectroscopy modes</strong> in real time.<br>
</li>
<li>Outcome: fewer trial-and-error sessions; <strong>cost &amp; time savings</strong>.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="Spurgeon_2020">Spurgeon et al. (<a href="#/references" role="doc-biblioref" onclick="">2020</a>)</span></p>
</div></aside></section>
<section id="feature-extraction-fig-1-middle" class="slide level2">
<h2>② Feature extraction (<em>Fig 1 middle</em>)</h2>
<div class="columns">
<div class="column" style="width:48%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig1_framework.png"></p>
<figcaption>Fig 1b – feature layer</figcaption>
</figure>
</div>
</div><div class="column" style="width:52%;">
<ul>
<li>Records complete data streams (e.g.&nbsp;<strong>4D-STEM diffraction cubes</strong>) for flexible post-processing<br>
</li>
<li>Combines complementary modalities to overcome projection &amp; damage artefacts.<br>
</li>
<li>Requires <strong>automation</strong> and low-level access for batch surveys &amp; <em>in-situ</em> studies.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="Spurgeon_2020">Spurgeon et al. (<a href="#/references" role="doc-biblioref" onclick="">2020</a>)</span></p>
</div></aside></section>
<section id="knowledge-discovery-fig-1-bottom" class="slide level2">
<h2>③ Knowledge discovery (<em>Fig 1 bottom</em>)</h2>
<div class="columns">
<div class="column" style="width:48%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig1_framework.png"></p>
<figcaption>Fig 1c – knowledge layer</figcaption>
</figure>
</div>
</div><div class="column" style="width:52%;">
<ul>
<li>AI/ML trained on physical models classifies <strong>multidimensional signals</strong> → structure, bonding, dynamics.<br>
</li>
<li>FAIR data standards and open repositories enable <strong>meta-analysis &amp; reproducibility</strong>.<br>
</li>
<li>Vision: adaptive microscopy where data choose the next experiment step on-the-fly.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="Spurgeon_2020">Spurgeon et al. (<a href="#/references" role="doc-biblioref" onclick="">2020</a>)</span></p>
</div></aside></section>
<section id="detectors-drive-the-data-deluge-figure-2-a" class="slide level2">
<h2>Detectors drive the data deluge (<em>Figure 2 a</em>)</h2>
<div class="columns">
<div class="column" style="width:48%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig2a_datarate.png"></p>
<figcaption>Fig 2a – data-rate timeline</figcaption>
</figure>
</div>
</div><div class="column" style="width:52%;">
<ul>
<li>From film (1 GB h⁻¹) to <strong>4D pixelated cameras (200 TB h⁻¹)</strong> – a 10⁸× leap in two decades.<br>
</li>
<li>Computing &amp; storage must scale in lock-step; edge processing at the microscope becomes essential.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="Spurgeon_2020">Spurgeon et al. (<a href="#/references" role="doc-biblioref" onclick="">2020</a>)</span></p>
</div></aside></section>
<section id="workflow-evolution-figure-2-b" class="slide level2">
<h2>Workflow evolution (<em>Figure 2 b</em>)</h2>
<div class="columns">
<div class="column" style="width:48%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./images/fig2b_workflow.png"></p>
<figcaption>Fig 2b – manual → augmented</figcaption>
</figure>
</div>
</div><div class="column" style="width:52%;">
<ul>
<li><strong>Manual</strong>: choose features “by eye”, serial data, iterative models.<br>
</li>
<li><strong>Augmented</strong>: collect <strong>many data streams</strong>, ML finds features, simulation-based model extraction.<br>
</li>
<li>Integrated experiment control enables <strong>closed-loop, crowd-sourced</strong> materials discovery.<br>
</li>
</ul>
</div></div>

<aside><div>
<p><span class="citation" data-cites="Spurgeon_2020">Spurgeon et al. (<a href="#/references" role="doc-biblioref" onclick="">2020</a>)</span></p>
</div></aside></section>
<section id="take-aways-1" class="slide level2">
<h2>Take-aways</h2>
<ul>
<li>Modern STEM now spans <strong>Å-scale resolution &amp; petabyte-scale data</strong>.<br>
</li>
<li>A three-layer, open architecture (design → extraction → discovery) lets AI and simulation turn data into insight.<br>
</li>
<li>Detector advances + FAIR data infrastructure set the stage for <strong>truly adaptive, autonomous microscopy</strong>.</li>
</ul>
</section>
<section id="course-outline" class="slide level2">
<h2>Course outline</h2>
<ul>
<li>Intro (13.05.2025)</li>
<li>Regression and Sensor Fusion (20.05.2025)</li>
<li>CNNs (27.05.2025)</li>
<li>Classification, Segmentation, AutoEncoders (03.06.2025)</li>
<li>Miniproject (3.6. - 24.6.2025) concurrent to lectures</li>
<li>Project Presentations, GANs (24.06.2025)</li>
<li>Gaussian Processes Introduction (01.07.2025)</li>
<li>Gaussian Processes Applications (08.07.2025)</li>
<li>Advanced Forward Models for Imaging: Tomography, Diffractive Imaging (15.07.2025)</li>
<li>Repetition (29.07.2025)</li>
</ul>
</section>
<section id="miniproject" class="slide level2">
<h2>Miniproject</h2>
<ul>
<li>In the miniproject, you will test multiple deep neural network architectures on one of four microscopy-related tasks.</li>
<li>You should summarize your results in a short presentation (5 minutes + 2 minutes discussion) and deliver a Jupyter Notebook with your code and results.</li>
<li>The miniproject will be graded and will count as 40% towards your final grade.</li>
</ul>
</section>
<section id="data-manipulation" class="slide level2">
<h2>Data Manipulation</h2>
<ul>
<li>Data handling requires two main tasks:
<ul>
<li>Data acquisition</li>
<li>Data processing</li>
</ul></li>
<li>Key concepts for data manipulation:
<ul>
<li><span class="math inline">\(n\)</span>-dimensional arrays (tensors) are fundamental</li>
<li>Modern deep learning frameworks use tensor classes:
<ul>
<li><code>ndarray</code> in MXNet</li>
<li><code>Tensor</code> in PyTorch and TensorFlow</li>
<li>Similar to NumPy’s <code>ndarray</code> with additional features</li>
</ul></li>
<li>Key advantages of tensor classes:
<ul>
<li>Support automatic differentiation</li>
<li>GPU acceleration for numerical computation</li>
<li>NumPy only runs on CPUs</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="getting-started-1" class="slide level2">
<h2>Getting Started 1</h2>
<ul>
<li>Import PyTorch:</li>
</ul>
<div id="27f26c55" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Tensor basics:
<ul>
<li>Vector: tensor with one axis</li>
<li>Matrix: tensor with two axes</li>
<li><span class="math inline">\(k^\mathrm{th}\)</span> order tensor: tensor with <span class="math inline">\(k &gt; 2\)</span> axes</li>
</ul></li>
<li>Tensor creation:
<ul>
<li>Use <code>arange(n)</code> for evenly spaced values (0 to n-1)</li>
<li>Default storage: main memory</li>
<li>Default computation: CPU-based</li>
</ul></li>
</ul>
</section>
<section id="getting-started-2" class="slide level2">
<h2>Getting Started 2</h2>
<div id="4bddfb10" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb2-2"><a></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])</code></pre>
</div>
</div>
<ul>
<li>Tensor elements:
<ul>
<li>Each value is an element</li>
<li>Use <code>numel()</code> to get total element count</li>
<li>Use <code>shape</code> attribute to get dimensions</li>
</ul></li>
</ul>
<div id="4df63770" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>x.numel()</span>
<span id="cb4-2"><a></a>x.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>torch.Size([12])</code></pre>
</div>
</div>
<ul>
<li>Reshaping tensors:
<ul>
<li>Use <code>reshape</code> to change shape without changing values</li>
<li>Example: vector (12,) → matrix (3, 4)</li>
<li>Elements maintain order (row-major)</li>
</ul></li>
</ul>
<div id="52400ce9" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a>X <span class="op">=</span> x.reshape(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-2"><a></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.]])</code></pre>
</div>
</div>
</section>
<section id="getting-started-3" class="slide level2">
<h2>Getting Started 3</h2>
<ul>
<li>Shape inference:
<ul>
<li>Use <code>-1</code> to automatically infer one dimension</li>
<li>Example: <code>x.reshape(-1, 4)</code> or <code>x.reshape(3, -1)</code></li>
<li>Given size <span class="math inline">\(n\)</span> and shape (<span class="math inline">\(h\)</span>, <span class="math inline">\(w\)</span>), <span class="math inline">\(w = n/h\)</span></li>
</ul></li>
<li>Common tensor initializations:
<ul>
<li>Zeros: <code>torch.zeros((2, 3, 4))</code></li>
<li>Ones: <code>torch.ones((2, 3, 4))</code></li>
<li>Random (Gaussian): <code>torch.randn(3, 4)</code></li>
<li>Custom values: <code>torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])</code></li>
</ul></li>
</ul>
</section>
<section id="indexing-and-slicing-1" class="slide level2">
<h2>Indexing and Slicing 1</h2>
<ul>
<li>Access methods:
<ul>
<li>Indexing (0-based)</li>
<li>Negative indexing (from end)</li>
<li>Slicing (<code>start:stop</code>)</li>
<li>Single index/slice applies to axis 0</li>
</ul></li>
</ul>
<div id="fa0cd159" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>X[<span class="op">-</span><span class="dv">1</span>], X[<span class="dv">1</span>:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(tensor([ 8.,  9., 10., 11.]),
 tensor([[ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.]]))</code></pre>
</div>
</div>
<ul>
<li>Element modification:
<ul>
<li>Use indexing for assignment</li>
<li>Example: <code>X[1, 2] = 17</code></li>
</ul></li>
</ul>
</section>
<section id="indexing-and-slicing-2" class="slide level2">
<h2>Indexing and Slicing 2</h2>
<ul>
<li>Multiple element assignment:
<ul>
<li>Use indexing on left side of assignment</li>
<li><code>:</code> selects all elements along an axis</li>
<li>Works for vectors and higher-dimensional tensors</li>
</ul></li>
</ul>
<div id="00b3b42e" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>X[:<span class="dv">2</span>, :] <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb10-2"><a></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[12., 12., 12., 12.],
        [12., 12., 12., 12.],
        [ 8.,  9., 10., 11.]])</code></pre>
</div>
</div>
</section>
<section id="operations-1" class="slide level2">
<h2>Operations 1</h2>
<ul>
<li>Elementwise operations:
<ul>
<li>Apply scalar operations to each element</li>
<li>Work with corresponding element pairs</li>
<li>Support unary operators (e.g., <span class="math inline">\(e^x\)</span>)</li>
<li>Signature: <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span></li>
</ul></li>
</ul>
<div id="4c30fecb" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a>torch.exp(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969, 162754.7969,
        162754.7969, 162754.7969, 162754.7969,   2980.9580,   8103.0840,
         22026.4648,  59874.1406])</code></pre>
</div>
</div>
</section>
<section id="operations-2" class="slide level2">
<h2>Operations 2</h2>
<ul>
<li>Binary operations:
<ul>
<li>Work on pairs of real numbers</li>
<li>Signature: <span class="math inline">\(f: \mathbb{R}, \mathbb{R} \rightarrow \mathbb{R}\)</span></li>
<li>Common operators:
<ul>
<li>Addition (<code>+</code>)</li>
<li>Subtraction (<code>-</code>)</li>
<li>Multiplication (<code>*</code>)</li>
<li>Division (<code>/</code>)</li>
<li>Exponentiation (<code>**</code>)</li>
</ul></li>
</ul></li>
</ul>
<div id="8ff64107" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>])</span>
<span id="cb14-2"><a></a>y <span class="op">=</span> torch.tensor([<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb14-3"><a></a>x <span class="op">+</span> y, x <span class="op">-</span> y, x <span class="op">*</span> y, x <span class="op">/</span> y, x <span class="op">**</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(tensor([ 3.,  4.,  6., 10.]),
 tensor([-1.,  0.,  2.,  6.]),
 tensor([ 2.,  4.,  8., 16.]),
 tensor([0.5000, 1.0000, 2.0000, 4.0000]),
 tensor([ 1.,  4., 16., 64.]))</code></pre>
</div>
</div>
</section>
<section id="operations-3" class="slide level2">
<h2>Operations 3</h2>
<ul>
<li>Tensor concatenation:
<ul>
<li>Use <code>torch.cat</code> with list of tensors</li>
<li>Specify axis for concatenation</li>
<li>Shape changes:
<ul>
<li>Axis 0: sum of input axis-0 lengths</li>
<li>Axis 1: sum of input axis-1 lengths</li>
</ul></li>
</ul></li>
</ul>
<div id="81a418ef" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a>X <span class="op">=</span> torch.arange(<span class="dv">12</span>, dtype<span class="op">=</span>torch.float32).reshape((<span class="dv">3</span>,<span class="dv">4</span>))</span>
<span id="cb16-2"><a></a>Y <span class="op">=</span> torch.tensor([[<span class="fl">2.0</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">3</span>], [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>]])</span>
<span id="cb16-3"><a></a>torch.cat((X, Y), dim<span class="op">=</span><span class="dv">0</span>), torch.cat((X, Y), dim<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         [ 2.,  1.,  4.,  3.],
         [ 1.,  2.,  3.,  4.],
         [ 4.,  3.,  2.,  1.]]),
 tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))</code></pre>
</div>
</div>
</section>
<section id="operations-4" class="slide level2">
<h2>Operations 4</h2>
<ul>
<li>Logical operations:
<ul>
<li>Create binary tensors via logical statements</li>
<li>Example: <code>X == Y</code> creates tensor of 1s and 0s</li>
<li>Sum operation: <code>X.sum()</code> reduces to single element</li>
</ul></li>
</ul>
<div id="201885c5" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a>X <span class="op">==</span> Y</span>
<span id="cb18-2"><a></a>X.<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor(66.)</code></pre>
</div>
</div>
</section>
<section id="broadcasting" class="slide level2">
<h2>Broadcasting</h2>
<ul>
<li>Mechanism for elementwise operations with different shapes:
<ul>
<li>Step 1: Expand arrays along length-1 axes</li>
<li>Step 2: Perform elementwise operation</li>
</ul></li>
</ul>
<div id="356c7a83" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a></a>a <span class="op">=</span> torch.arange(<span class="dv">3</span>).reshape((<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb20-2"><a></a>b <span class="op">=</span> torch.arange(<span class="dv">2</span>).reshape((<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb20-3"><a></a>a <span class="op">+</span> b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([[0, 1],
        [1, 2],
        [2, 3]])</code></pre>
</div>
</div>
</section>
<section id="saving-memory-1" class="slide level2">
<h2>Saving Memory 1</h2>
<ul>
<li>Memory allocation issues:
<ul>
<li>Operations create new memory allocations</li>
<li>Example: <code>Y = X + Y</code> creates new memory</li>
<li>Check with <code>id()</code> function</li>
<li>Undesirable for:
<ul>
<li>Frequent parameter updates</li>
<li>Multiple variable references</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="saving-memory-2" class="slide level2">
<h2>Saving Memory 2</h2>
<ul>
<li>In-place operations:
<ul>
<li>Use slice notation: <code>Y[:] = &lt;expression&gt;</code></li>
<li>Use <code>zeros_like</code> for initialization</li>
<li>Use <code>X[:] = X + Y</code> or <code>X += Y</code> for efficiency</li>
</ul></li>
</ul>
<div id="6e41348a" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a>Z <span class="op">=</span> torch.zeros_like(Y)</span>
<span id="cb22-2"><a></a>Z[:] <span class="op">=</span> X <span class="op">+</span> Y</span>
<span id="cb22-3"><a></a>X <span class="op">+=</span> Y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="conversion-to-other-python-objects" class="slide level2">
<h2>Conversion to Other Python Objects</h2>
<ul>
<li>NumPy conversion:
<ul>
<li><code>X.numpy()</code>: Tensor → NumPy array</li>
<li><code>torch.from_numpy(A)</code>: NumPy array → Tensor</li>
<li>Shared memory between conversions</li>
</ul></li>
<li>Scalar conversion:
<ul>
<li>Use <code>item()</code> or built-in functions</li>
<li>Example: <code>float(a)</code>, <code>int(a)</code></li>
</ul></li>
</ul>
</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Tensor class features:
<ul>
<li>Data storage and manipulation</li>
<li>Construction routines</li>
<li>Indexing and slicing</li>
<li>Basic mathematics</li>
<li>Broadcasting</li>
<li>Memory-efficient operations</li>
<li>Python object conversion</li>
</ul></li>
</ul>
</section>
<section id="exercises" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>Experiment with different conditional statements:
<ul>
<li>Try <code>X &lt; Y</code> and <code>X &gt; Y</code></li>
<li>Observe resulting tensor types</li>
</ul></li>
<li>Test broadcasting with 3D tensors:
<ul>
<li>Try different shapes</li>
<li>Verify results match expectations</li>
</ul></li>
</ol>
</section>
<section id="automatic-differentiation" class="slide level2">
<h2>Automatic Differentiation</h2>
<ul>
<li>Key points about derivatives in deep learning:
<ul>
<li>Essential for optimization algorithms</li>
<li>Used in training deep networks</li>
<li>Manual calculation is:
<ul>
<li>Tedious</li>
<li>Error-prone</li>
<li>More difficult with complex models</li>
</ul></li>
</ul></li>
<li>Modern deep learning frameworks provide:
<ul>
<li>Automatic differentiation (autograd)</li>
<li>Computational graph tracking</li>
<li>Backpropagation implementation
<ul>
<li>Works backwards through graph</li>
<li>Applies chain rule</li>
<li>Efficient gradient computation</li>
</ul></li>
</ul></li>
</ul>
<div id="15f645e5" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a></a><span class="im">import</span> torch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="a-simple-function" class="slide level2">
<h2>A Simple Function</h2>
<ul>
<li>Goal: Differentiate <span class="math inline">\(y = 2\mathbf{x}^{\top}\mathbf{x}\)</span> with respect to <span class="math inline">\(\mathbf{x}\)</span></li>
<li>Initial setup:</li>
</ul>
<div id="79b5643b" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a>x <span class="op">=</span> torch.arange(<span class="fl">4.0</span>)</span>
<span id="cb24-2"><a></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([0., 1., 2., 3.])</code></pre>
</div>
</div>
<ul>
<li>Gradient storage considerations:
<ul>
<li>Need space to store gradients</li>
<li>Avoid new memory allocation for each derivative</li>
<li>Important because:
<ul>
<li>Deep learning requires many derivative computations</li>
<li>Same parameters used repeatedly</li>
<li>Memory efficiency crucial</li>
</ul></li>
<li>Gradient shape matches input vector shape</li>
</ul></li>
</ul>
<div id="47b3bd04" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a></a>x.requires_grad_(<span class="va">True</span>)</span>
<span id="cb26-2"><a></a>x.grad  <span class="co"># The gradient is None by default</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section class="slide level2">

<ul>
<li>Function calculation:</li>
</ul>
<div id="85183abc" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a></a>y <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> torch.dot(x, x)</span>
<span id="cb27-2"><a></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor(28., grad_fn=&lt;MulBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li>Gradient computation:
<ul>
<li>Use <code>backward()</code> method</li>
<li>Access via <code>grad</code> attribute</li>
<li>Expected result: <span class="math inline">\(4\mathbf{x}\)</span></li>
</ul></li>
</ul>
<div id="2bcdbec1" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a></a>y.backward()</span>
<span id="cb29-2"><a></a>x.grad</span>
<span id="cb29-3"><a></a>x.grad <span class="op">==</span> <span class="dv">4</span> <span class="op">*</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([True, True, True, True])</code></pre>
</div>
</div>
<ul>
<li>Important note about gradient accumulation:
<ul>
<li>PyTorch adds new gradients to existing ones</li>
<li>Useful for optimizing sum of multiple objectives</li>
<li>Reset with <code>x.grad.zero_()</code></li>
</ul></li>
</ul>
<div id="77085963" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a></a>x.grad.zero_()  <span class="co"># Reset the gradient</span></span>
<span id="cb31-2"><a></a>y <span class="op">=</span> x.<span class="bu">sum</span>()</span>
<span id="cb31-3"><a></a>y.backward()</span>
<span id="cb31-4"><a></a>x.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor([1., 1., 1., 1.])</code></pre>
</div>
</div>
</section>
<section id="backward-for-non-scalar-variables" class="slide level2">
<h2>Backward for Non-Scalar Variables</h2>
<ul>
<li>Vector derivatives:
<ul>
<li>Natural interpretation: Jacobian matrix</li>
<li>Contains partial derivatives of each component</li>
<li>Higher-order tensors for higher-order inputs</li>
</ul></li>
<li>Common use case:
<ul>
<li>Sum gradients of each component</li>
<li>Often needed for batch processing</li>
<li>Results in vector matching input shape</li>
</ul></li>
<li>PyTorch implementation:
<ul>
<li>Requires explicit reduction to scalar</li>
<li>Uses vector <span class="math inline">\(\mathbf{v}\)</span> for computation</li>
<li>Computes <span class="math inline">\(\mathbf{v}^\top \partial_{\mathbf{x}} \mathbf{y}\)</span></li>
<li>Argument named <code>gradient</code> for historical reasons</li>
</ul></li>
</ul>
<div id="3a40834c" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a></a>x.grad.zero_()</span>
<span id="cb33-2"><a></a>y <span class="op">=</span> x <span class="op">*</span> x</span>
<span id="cb33-3"><a></a>y.backward(gradient<span class="op">=</span>torch.ones(<span class="bu">len</span>(y)))  <span class="co"># Faster: y.sum().backward()</span></span>
<span id="cb33-4"><a></a>x.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([0., 2., 4., 6.])</code></pre>
</div>
</div>
</section>
<section id="detaching-computation" class="slide level2">
<h2>Detaching Computation</h2>
<ul>
<li>Purpose: Move calculations outside computational graph</li>
<li>Use cases:
<ul>
<li>Create auxiliary terms without gradients</li>
<li>Focus on direct influence of variables</li>
<li>Control gradient flow</li>
</ul></li>
<li>Example scenario:
<ul>
<li><code>z = x * y</code> and <code>y = x * x</code></li>
<li>Want direct influence of <code>x</code> on <code>z</code></li>
<li>Solution: Detach <code>y</code> to create <code>u</code></li>
<li>Results in:
<ul>
<li>Same value as <code>y</code></li>
<li>No gradient flow through <code>u</code></li>
<li>Direct computation of <code>z = x * u</code></li>
</ul></li>
</ul></li>
</ul>
<div id="7b98c3e7" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a></a>x.grad.zero_()</span>
<span id="cb35-2"><a></a>y <span class="op">=</span> x <span class="op">*</span> x</span>
<span id="cb35-3"><a></a>u <span class="op">=</span> y.detach()</span>
<span id="cb35-4"><a></a>z <span class="op">=</span> u <span class="op">*</span> x</span>
<span id="cb35-5"><a></a></span>
<span id="cb35-6"><a></a>z.<span class="bu">sum</span>().backward()</span>
<span id="cb35-7"><a></a>x.grad <span class="op">==</span> u</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([True, True, True, True])</code></pre>
</div>
</div>
<ul>
<li>Important notes:
<ul>
<li>Detaches ancestors from graph</li>
<li>Original graph for <code>y</code> persists</li>
<li>Can still compute gradients for <code>y</code></li>
</ul></li>
</ul>
<div id="fb6afa45" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a></a>x.grad.zero_()</span>
<span id="cb37-2"><a></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb37-3"><a></a>x.grad <span class="op">==</span> <span class="dv">2</span> <span class="op">*</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([True, True, True, True])</code></pre>
</div>
</div>
</section>
<section id="gradients-and-python-control-flow" class="slide level2">
<h2>Gradients and Python Control Flow</h2>
<ul>
<li>Key feature: Works with dynamic computation paths</li>
<li>Supports:
<ul>
<li>Conditional statements</li>
<li>Loops</li>
<li>Arbitrary function calls</li>
<li>Variable-dependent control flow</li>
</ul></li>
<li>Example function:</li>
</ul>
<div id="e5e4e9c2" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a></a><span class="kw">def</span> f(a):</span>
<span id="cb39-2"><a></a>    b <span class="op">=</span> a <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb39-3"><a></a>    <span class="cf">while</span> b.norm() <span class="op">&lt;</span> <span class="dv">1000</span>:</span>
<span id="cb39-4"><a></a>        b <span class="op">=</span> b <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb39-5"><a></a>    <span class="cf">if</span> b.<span class="bu">sum</span>() <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb39-6"><a></a>        c <span class="op">=</span> b</span>
<span id="cb39-7"><a></a>    <span class="cf">else</span>:</span>
<span id="cb39-8"><a></a>        c <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> b</span>
<span id="cb39-9"><a></a>    <span class="cf">return</span> c</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section class="slide level2">

<ul>
<li>Implementation details:
<ul>
<li>Graph built during execution</li>
<li>Specific path for each input</li>
<li>Supports backward pass after execution</li>
<li>Works with linear functions and piecewise definitions</li>
</ul></li>
</ul>
<div id="b01dfeb8" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a></a>a <span class="op">=</span> torch.randn(size<span class="op">=</span>(), requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-2"><a></a>d <span class="op">=</span> f(a)</span>
<span id="cb40-3"><a></a>d.backward()</span>
<span id="cb40-4"><a></a>a.grad <span class="op">==</span> d <span class="op">/</span> a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor(True)</code></pre>
</div>
</div>
<ul>
<li>Real-world applications:
<ul>
<li>Text processing with variable lengths</li>
<li>Dynamic model architectures</li>
<li>Statistical modeling</li>
<li>Impossible to compute gradients a priori</li>
</ul></li>
</ul>
</section>
<section id="discussion" class="slide level2">
<h2>Discussion</h2>
<ul>
<li>Impact of automatic differentiation:
<ul>
<li>Massive productivity boost</li>
<li>Enables complex model design</li>
<li>Frees practitioners for higher-level tasks</li>
</ul></li>
<li>Technical aspects:
<ul>
<li>Optimization of autograd libraries</li>
<li>Compiler and graph manipulation tools</li>
<li>Memory efficiency</li>
<li>Computational efficiency</li>
</ul></li>
<li>Basic workflow:
<ol type="1">
<li>Attach gradients to target variables</li>
<li>Record target value computation</li>
<li>Execute backpropagation</li>
<li>Access resulting gradient</li>
</ol></li>
</ul>
</section>
<section id="exercises-1" class="slide level2">
<h2>Exercises</h2>
<ol type="1">
<li>Backpropagation behavior:
<ul>
<li>Run function twice</li>
<li>Observe and explain results</li>
</ul></li>
<li>Control flow analysis:
<ul>
<li>Change <code>a</code> to vector/matrix</li>
<li>Analyze non-scalar results</li>
<li>Explain computation changes</li>
</ul></li>
<li>Automatic differentiation practice:
<ul>
<li>Plot <span class="math inline">\(f(x) = \sin(x)\)</span></li>
<li>Plot derivative using autograd</li>
<li>Avoid using known derivative formula</li>
</ul></li>
</ol>
</section>
<section class="slide level2">

<ol start="4" type="1">
<li>Chain rule exercise:
<ul>
<li>Function: <span class="math inline">\(f(x) = ((\log x^2) \cdot \sin x) + x^{-1}\)</span></li>
<li>Create dependency graph</li>
<li>Compute derivative using chain rule</li>
<li>Map terms to dependency graph</li>
</ul></li>
<li>Let <span class="math inline">\(f(x) = ((\log x^2) \cdot \sin x) + x^{-1}\)</span>. Write out a dependency graph tracing results from <span class="math inline">\(x\)</span> to <span class="math inline">\(f(x)\)</span>.</li>
</ol>
</section>
<section class="slide level2">

<ol start="6" type="1">
<li>Use the chain rule to compute the derivative <span class="math inline">\(\frac{df}{dx}\)</span> of the aforementioned function, placing each term on the dependency graph that you constructed previously.</li>
</ol>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-ophus2023quantitative" class="csl-entry" role="listitem">
Ophus, Colin. 2023. <span>“Quantitative Scanning Transmission Electron Microscopy for Materials Science: Imaging, Diffraction, Spectroscopy, and Tomography.”</span> <em>Annual Review of Materials Research</em> 53 (1): 105–41.
</div>
<div id="ref-Spurgeon_2020" class="csl-entry" role="listitem">
Spurgeon, Steven R., Colin Ophus, Lewys Jones, Amanda Petford-Long, Sergei V. Kalinin, Matthew J. Olszta, Rafal E. Dunin-Borkowski, et al. 2020. <span>“Towards Data-Driven Next-Generation Transmission Electron Microscopy.”</span> <em>Nature Materials</em>, October, 1–6. <a href="https://doi.org/10/ghhtjq">https://doi.org/10/ghhtjq</a>.
</div>
</div>
<script>
document.getElementById("marimo-frame").onload = function() {
    try {
        let iframeDoc = document.getElementById("marimo-frame").contentWindow.document;
        let marimoBadge = iframeDoc.querySelector("div.fixed.bottom-0.right-0.z-50");
        if (marimoBadge) {
            marimoBadge.style.display = "none";
            console.log("Marimo badge hidden successfully.");
        } else {
            console.log("Badge not found.");
        }
    } catch (error) {
        console.warn("Unable to modify iframe content due to CORS restrictions.");
    }
};
</script>
</section></div>

<div class="quarto-auto-generated-content" style="display: none;">
<p><img src="eclipse_logo_small.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy</p>
</div>
</div>

    </div>
  

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'view': "scroll",
'scrollSnap': "mandatory",
'scrollLayout': "full",
'menu': {"side":"right","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true,"width":"wide"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: false,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/ECLIPSE-Lab\.github\.io\/public_presentations\/");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script>videojs(video_shortcode_videojs_video1);</script>
    <script>videojs(video_shortcode_videojs_video2);</script>
    

</body></html>