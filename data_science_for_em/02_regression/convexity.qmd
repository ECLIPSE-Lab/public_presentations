<!-- ---
title: "Convexity"
format: 
  revealjs:
    theme: custom.scss
    css: custom.css
    width: 1920
    height: 1080
    menu:
      side: right
      width: wide
    template-partials:
      - title-slide.html
    slide-number: c/t
    logo: "eclipse_logo_small.png"
    highlight-style: a11y
    incremental: false
    background-transition: fade
    footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Data Science for Electron Microscopy"
execute:
  eval: true
  echo: true
--- -->

# Convexity

- Convexity is crucial for optimization algorithm design
- Benefits:
  - Easier algorithm analysis and testing
  - Better understanding of deep learning optimization
  - Properties near local minima often resemble convex functions
- Even nonconvex problems can benefit from convex analysis
```{python}
#| label: setup1
#| code-fold: true
%matplotlib inline
import d2l
import numpy as np
from mpl_toolkits import mplot3d
import torch
```

## Definitions

### Convex Sets

- A set $\mathcal{X}$ is convex if:
  - For any $a, b \in \mathcal{X}$
  - Line segment connecting $a$ and $b$ is in $\mathcal{X}$
- Mathematical definition:
  $$\lambda a + (1-\lambda) b \in \mathcal{X} \textrm{ whenever } a, b \in \mathcal{X}$$
  for all $\lambda \in [0, 1]$

### Visual Examples

![The first set is nonconvex and the other two are convex.](./img/pacman.svg)

--- 

### Set Operations

- Intersections of convex sets are convex
- Unions of convex sets need not be convex
- Example: $\mathbb{R}^d$ is convex
- Bounded sets (e.g., balls) are often convex

![The intersection between two convex sets is convex.](./img/convex-intersect.svg)

![The union of two convex sets need not be convex.](./img/nonconvex.svg)

## Convex Functions

### Definition

- Function $f: \mathcal{X} \to \mathbb{R}$ is convex if:
  - For all $x, x' \in \mathcal{X}$
  - For all $\lambda \in [0, 1]$
  - Satisfies: $\lambda f(x) + (1-\lambda) f(x') \geq f(\lambda x + (1-\lambda) x')$

### Examples

```{python}
#| label: function-examples
#| code-fold: true
f = lambda x: 0.5 * x**2  # Convex
g = lambda x: d2l.cos(np.pi * x)  # Nonconvex
h = lambda x: d2l.exp(0.5 * x)  # Convex

x, segment = d2l.arange(-2, 2, 0.01), d2l.tensor([-1.5, 1])
d2l.use_svg_display()
_, axes = d2l.plt.subplots(1, 3, figsize=(9, 3))
for ax, func in zip(axes, [f, g, h]):
    d2l.plot([x, segment], [func(x), func(segment)], axes=ax)
```

## Jensen's Inequality

### Definition

- Generalization of convexity
- For convex function $f$:
  $$\sum_i \alpha_i f(x_i) \geq f\left(\sum_i \alpha_i x_i\right)$$
  $$E_X[f(X)] \geq f\left(E_X[X]\right)$$
- Where $\alpha_i \geq 0$ and $\sum_i \alpha_i = 1$

### Applications

- Bounding complex expressions
- Log-likelihood of partially observed variables
- Variational methods
- Clustering algorithms

## Properties

### Local vs Global Minima

- Local minima of convex functions are global minima
- Proof by contradiction
- Example: $f(x) = (x-1)^2$

```{python}
#| label: local-global-minima
#| code-fold: true
f = lambda x: (x - 1) ** 2
d2l.set_figsize((8,8))
d2l.plot([x, segment], [f(x), f(segment)], 'x', 'f(x)')
```

--- 

### Below Sets

- Given convex function $f$ on convex set $\mathcal{X}$
- Below set $\mathcal{S}_b = \{x | x \in \mathcal{X} \textrm{ and } f(x) \leq b\}$ is convex
- Proof uses definition of convexity

### Second Derivatives

- For twice-differentiable $f: \mathbb{R}^n \rightarrow \mathbb{R}$
- Convex if and only if Hessian is positive semidefinite
- One-dimensional case: $f'' \geq 0$
- Multidimensional case: $\nabla^2f \succeq 0$

## Constraints

### Constrained Optimization

- Form: 
  $$\begin{aligned} \mathop{\textrm{minimize~}}_{\mathbf{x}} & f(\mathbf{x}) \\
    \textrm{ subject to } & c_i(\mathbf{x}) \leq 0 \textrm{ for all } i \in \{1, \ldots, n\}\end{aligned}$$
- Examples:
  - Unit ball constraint: $c_1(\mathbf{x}) = \|\mathbf{x}\|_2 - 1$
  - Half-space constraint: $c_2(\mathbf{x}) = \mathbf{v}^\top \mathbf{x} + b$

### Lagrangian

- Combines objective and constraints
- Form: $L(\mathbf{x}, \alpha_1, \ldots, \alpha_n) = f(\mathbf{x}) + \sum_{i=1}^n \alpha_i c_i(\mathbf{x})$
- Lagrange multipliers $\alpha_i \geq 0$
- Saddle point optimization

---

### Penalties

- Alternative to exact constraint satisfaction
- Add $\alpha_i c_i(\mathbf{x})$ to objective
- Example: weight decay
- More robust than exact satisfaction
- Works well for nonconvex problems

---

### Projections

- Projection on convex set $\mathcal{X}$:
  $$\textrm{Proj}_\mathcal{X}(\mathbf{x}) = \mathop{\mathrm{argmin}}_{\mathbf{x}' \in \mathcal{X}} \|\mathbf{x} - \mathbf{x}'\|$$
- Example: gradient clipping
- Applications:
  - Sparse weight vectors
  - $\ell_1$ ball projections

![Convex Projections.](./img/projections.svg)

## Summary

- Key properties:
  - Intersections of convex sets are convex
  - Jensen's inequality for expectations
  - Hessian positive semidefinite for convex functions
  - Local minima are global minima
- Constraint handling:
  - Lagrangian approach
  - Penalty methods
  - Projections
- Applications in deep learning:
  - Algorithm motivation
  - Understanding optimization
  - Gradient descent analysis

