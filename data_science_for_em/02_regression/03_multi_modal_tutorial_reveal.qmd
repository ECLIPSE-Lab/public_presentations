 

 

## Overview

- Tutorial on fusing EELS/X-EDS maps with HAADF for improved chemical resolution
- Part 1 of 2: Atomic resolution HAADF and X-EDS dataset of DyScO$_3$
- Python-based workflow with minimal user input (<10 tunable lines)
- Quick transformation of datasets into resolution-enhanced chemical maps

::: {.callout-note}
## Example Output
![Raw vs Fused DyScO$_3$](figs/Figure_3_Output.png){width="700px"}
:::

## Experimental Requirements {.callout-warning}

- Need both elastic (e.g., HAADF) and inelastic (e.g., EELS/X-EDS) maps
- Elastic signal must provide Z-contrast
- Inelastic signal must map all chemistries
- All maps must have same dimensionality
- Recommendation: Use simultaneously collected HAADF signal

::: aside
@Schwartz_2022, @manassa2024fused
:::

## Step 1: Python Imports

```{python}
import data.fusion_utils as utils
from scipy.sparse import spdiags
import matplotlib.pyplot as plt
from tqdm.notebook import tqdm 
import numpy as np

```

## Step 2: Data Loading

```{python}
data = np.load('data/PTO_Trilayer_dataset.npz')
# Define element names and their atomic weights
elem_names=['Sc', 'Dy', 'O']
elem_weights=[21,66,8]

# Parse elastic HAADF data and inelastic chemical maps
HAADF = data['HAADF']
xx = np.array([],dtype=np.float32)
for ee in elem_names:
    chemMap = data[ee]
    if chemMap.shape != HAADF.shape:
        raise ValueError(f"The dimensions of {ee} chemical map do not match HAADF dimensions.")
    chemMap -= np.min(chemMap); chemMap /= np.max(chemMap)
    xx = np.concatenate([xx,chemMap.flatten()])
```

<!-- ::: {.callout-tip}
## Loading Alternative Formats
- For .dm3, .dm4, or .emd files: Use HyperSpy
- Documentation: [HyperSpy IO Guide](https://hyperspy.org/hyperspy-doc/v1.3/user_guide/io.html)
::: -->

## Step 3: Data Reshaping

```{python}
# Make Copy of Raw Measurements
xx0 = xx.copy()

# Parameters
gamma = 1.6  # Z-contrast scaling factor
(nx, ny) = chemMap.shape; nPix = nx * ny
nz = len(elem_names)

# Initialize TV Regularizers
reg = utils.tvlib(nx,ny)

# Normalize HAADF
HAADF -= np.min(HAADF); HAADF /= np.max(HAADF)
HAADF = HAADF.flatten()

# Create Measurement Matrix
A = utils.create_weighted_measurement_matrix(nx,ny,nz,elem_weights,gamma,1)
```

## Step 4: Cost Function Parameters

  
```{python}
# Convergence Parameters
lambdaHAADF = 1/nz # 1/nz (do not modify)
lambdaChem = 0.08 # 0.05-0.3 (data consistency)
lambdaTV = 0.15 # <0.2  Total Variation denoising
nIter = 30      # typically converges in 10-15
bkg = 2.4e-1    # background subtraction

# FGP TV Parameters
regularize = True
nIter_TV = 3
```

## Step 5: Algorithm Execution

```{python}
# Initialize
xx = xx0.copy()

# Cost Functions
lsqFun = lambda inData : 0.5 * np.linalg.norm(A.dot(inData**gamma) - HAADF) **2
poissonFun = lambda inData : np.sum(xx0 * np.log(inData + 1e-8) - inData)

# Initialize Cost Tracking
costHAADF = np.zeros(nIter,dtype=np.float32)
costChem = np.zeros(nIter, dtype=np.float32)
costTV = np.zeros(nIter, dtype=np.float32)

# Main Loop
for kk in tqdm(range(nIter)):
    # Optimization
    xx -= gamma * spdiags(xx**(gamma - 1), [0], nz*nx*ny, nz*nx*ny) * \
          lambdaHAADF * A.transpose() * (A.dot(xx**gamma) - HAADF) + \
          lambdaChem * (1 - xx0 / (xx + bkg))
    
    # Positivity Constraint
    xx[xx<0] = 0
    
    # TV Regularization
    if regularize:
        for zz in range(nz):
            xx[zz*nPix:(zz+1)*nPix] = reg.fgp_tv(
                xx[zz*nPix:(zz+1)*nPix].reshape(nx,ny), 
                lambdaTV, 
                nIter_TV
            ).flatten()
            costTV[kk] += reg.tv(xx[zz*nPix:(zz+1)*nPix].reshape(nx,ny))
    
    # Track Costs
    costHAADF[kk] = lsqFun(xx)
    costChem[kk] = poissonFun(xx)
```

## Step 6: Convergence Assessment

::: {.callout-important}
## Convergence Criteria
- All 3 cost functions should asymptotically approach low values
- Look for:
  - Exponential decay
  - Brief overshooting (Lennard-Jones-like)
  - Avoid:
    - Incomplete convergence
    - Severe oscillations
:::

![Convergence Plot](figs/Figure_4_Convergence.png){width="700px"}

## TV Weighting Effects {.callout-attention}

![TV Weighting Comparison](figs/Figure_5_TV.png){width="700px"}

::: {.callout-warning}
## TV Weighting Guidelines
- Under-weighting: Results in noisy reconstructions
- Over-weighting: Causes blurring and feature loss
- Best practice: Err on side of under-weighting
  - Noise is familiar to data
  - Oversmoothing creates unphysical artifacts
:::

## Results Visualization

```{python}
# Display Cost Functions
utils.plot_convergence(costHAADF, lambdaHAADF, 
                      costChem, lambdaChem, 
                      costTV, lambdaTV)
```

---

```{python}
# Show Reconstructed Signal
fig, ax = plt.subplots(2,len(elem_names)+1,figsize=(12,6.5))
ax = ax.flatten()
ax[0].imshow((A.dot(xx**gamma)).reshape(nx,ny),cmap='gray'); ax[0].set_title('HAADF'); ax[0].axis('off')
ax[1+len(elem_names)].imshow((A.dot(xx**gamma)).reshape(nx,ny)[70:130,25:85],cmap='gray'); ax[1+len(elem_names)].set_title('HAADF Cropped'); ax[1+len(elem_names)].axis('off')

for ii in range(len(elem_names)):
    ax[ii+1].imshow(xx[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx,ny),cmap='gray')
    ax[ii+2+len(elem_names)].imshow(xx[ii*(nx*ny):(ii+1)*(nx*ny)].reshape(nx,ny)[70:130,25:85],cmap='gray')
    
    ax[ii+1].set_title(elem_names[ii])
    ax[ii+1].axis('off')
    ax[ii+2+len(elem_names)].set_title(elem_names[ii]+' Cropped')
    ax[ii+2+len(elem_names)].axis('off')

fig.tight_layout()
```

---

::: {.callout-warning}
## Best Practices Summary
1. Ensure proper data collection
2. Verify dimensional consistency
3. Start with recommended parameter ranges
4. Monitor convergence carefully
5. Validate results against physical expectations
::: 