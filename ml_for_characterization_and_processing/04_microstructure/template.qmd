---
title: |
  ML for Characterization and Processing<br>
  Lecture 4: Classical Microstructure Quantification & Its ML Extension
bibliography: ref.bib
# csl: custom.csl
author:
  - name: Prof. Dr. Philipp Pelz
    affiliation: 
      - FAU Erlangen-Nürnberg
      - Institute of Micro- and Nanostructure Research
   
execute: 
  eval: true
  echo: true
format: 
    revealjs: 
        chalkboard: true
        mermaid:
            theme: forest
        # mermaid-format: png
        # scroll-view:
        #     activate: true
        #     snap: mandatory
        #     layout: full 
        width: 1920
        height: 1080
        menu:
            side: right
            width: wide 
        template-partials:
            - title-slide.html
        css: custom.css
        theme: custom.scss
        slide-number: c/t    
        logo: "eclipse_logo_small.png"          
        highlight-style: a11y
        incremental: true 
        background-transition: fade
        footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - ML for Characterization and Processing"
---
 


## Welcome

### Week 4 — Classical Microstructure Quantification & Its ML Extension

**Goals for today:**
- Understand classical microstructure metrics  
- Learn how they become ML features  
- See how CNNs extend classical quantification  
- Understand the leap from hand-crafted → learned representations

---

## Outline

1. Why quantify microstructure?  
2. Classical metrics (grain size, phases, orientation, intercepts)  
3. From metrics → feature engineering  
4. From engineered → learned representations  
5. Summary & lab preview  

---

## 1. Why Quantify Microstructure?

Images are continuous fields.  
Models need **numbers**, not pictures.

Classical quantification turns images into:

- Grain sizes  
- Phase fractions  
- Orientation descriptors  
- Morphological statistics  

Machine learning continues this tradition — but at scale.

---

## Microstructure controls properties

- Grain size → strength (Hall–Petch)  
- Phase fractions → hardness, ductility  
- Texture → anisotropy, fatigue  
- Precipitates → creep, aging  

Quantification = link between structure and property.

---

## 2. Classical Microstructure Metrics

We review:

- Grain size  
- Phase fractions  
- Orientation maps (EBSD)  
- Lineal intercepts & spatial correlations  

These form the **foundation of ML features**.

---

## Grain Size

### ASTM grain size number:
\[
G = 1 + \log_2 N
\]

### Intercept method:
\[
\bar{L} = \frac{1}{M} \cdot \frac{1}{P_L}
\]

Key ideas:
- Use test lines across micrographs  
- Count grain boundary crossings  
- Robust, easy to automate  

ML relevance:
- Grain size = a fundamental feature for property prediction.

---

## Stereology Basics

### Delesse principle:
\[
V_V = A_A = P_P
\]

Volume fraction = area fraction = point fraction  
(for random sampling)

This underpins:

- Phase fraction estimation  
- Porosity quantification  
- Precipitate fractions  

---

## Phase Fractions

Methods:

- Thresholding segmentation  
- Color segmentation (optical)  
- Multi-channel segmentation (EDS maps)  

Challenges:

- Overlapping phases  
- Variable etching  
- Contrast drift  
- Noise

ML relevance:
- Phase fractions become regression targets or input features.

---

## Orientation Maps (EBSD)

EBSD outputs:

- Euler angles / quaternions  
- Inverse pole figure colors  
- Misorientation angles  
- Grain boundary character distribution (GBCD)  
- Kernel average misorientation (KAM)

Orientation → texture → anisotropy.

---

## EBSD Derived Metrics

### Misorientation:
\[
\Delta g = g_1 g_2^{-1}
\]

### Grain boundary character distribution:
Measures special boundaries (Σ3, Σ9, …)

### KAM:
Local disorder → indicator of plastic strain

ML relevance:

- Orientation is **non-Euclidean**  
- Requires specialized embeddings or graph models

---

## Lineal Intercept Metrics

Measures:

- Mean free path  
- Spacing  
- Directional anisotropy  
- Precipitate spacing  
- Porosity spacing  

Under the hood:
- These are **spatial correlation statistics**

---

## Two-Point Correlation Function

\[
S_2(r) = \langle I(x) I(x+r) \rangle
\]

Interprets:

- Periodicity  
- Texture  
- Cluster sizes  

ML relevance:

- Equivalent to convolution with shifted fields  
- CNN filters rediscover these patterns

---

## Summary of Classical Metrics

| Metric | Purpose | ML Link |
|--------|---------|---------|
| Grain size | Strength, hardness | Scalar feature |
| Phase fractions | State of material | Regression target/feature |
| Orientation | Texture | High-dimensional feature |
| Lineal intercepts | Spacing, anisotropy | Convolution analog |
| S2(r) | Periodicity | Frequency content |

---

## 3. From Classical Metrics → Feature Engineering

Hand-crafted features = human-designed descriptors.

These include:

- Grain size distribution  
- Shape descriptors  
- Texture metrics  
- Haralick texture features (GLCM)  
- LBP (local binary patterns)  
- Fourier features  
- Wavelet energies  

---

## What Feature Engineering Tries to Capture

- Edges  
- Patterns  
- Frequencies  
- Repetition  
- Shape  
- Orientation  
- Contrast changes  

But:

- Usually brittle  
- Requires domain expertise  
- Not generalizable  
- Omits subtle interactions  

---

## Feature Vector View

Microstructure → Feature vector:

\[
\mathbf{x} = [d_{\text{grain}}, f_{\text{phase}}, S_2(r), \text{GLCM}, \text{LBP}, …]
\]

Traditional ML (RF, SVM, GPR) works on these representations.

---

## Strengths & Weaknesses of Feature Engineering

### Strengths:

- Interpretability  
- Low data requirement  
- Easy to compute  

### Weaknesses:

- Limited scalability  
- Misses complex patterns  
- Sensitive to noise & preparation  
- Requires expert-designed heuristics  

---

## 4. Learned Representations

Deep learning extends classical quantification.

CNNs learn:

- Edges (grain boundaries)  
- Blobs (precipitates)  
- Textures (orientation regions)  
- Morphology (martensite, AM cells)  

---

## CNN Filters Mirror Metallography

### First layers:
Edges → grain boundaries

### Middle layers:
Blobs → precipitates, pores

### Deep layers:
Persistent motifs → lath martensite, banding, melt pool textures

CNN hierarchy mimics how metallurgists describe images.

---

## Why Learned Features Work Better

- Data-driven (no heuristics)
- Capture multi-scale structure
- Generalize across materials systems
- Encode subtle correlations
- Produce embeddings for clustering, regression, similarity search

---

## Microstructure Embeddings

A CNN's latent vector becomes a digital fingerprint of a microstructure.

**Applications:**

- Clustering materials
- Discovering new microstructure classes
- Property prediction
- Detecting anomalies
- Transfer learning across related alloys

---

## Hybrid Approaches

**Combine:**

- Classical descriptors
- Deep embeddings

**Benefits:**

- Better interpretability
- Stronger predictive power
- Physics + data-driven synergy

---

## When Deep Representations Fail

- Severe domain shift
- Small datasets (without augmentation)
- Poor labeling quality
- Out-of-distribution microstructures
- Missing physical priors

We will address these issues later in the course.

---

## 5. Summary & Lab Preview

**Key takeaways:**

- Classical microstructure quantification = foundation of ML
- Feature engineering is a bridge between classical and deep learning
- CNNs rediscover hierarchical features used in metallography
- Deep embeddings act as powerful microstructure descriptors
- Hybrid approaches are best in practice

**Next week's lab:**

- Compute classical descriptors (GLCM, LBP)
- Train a small CNN on microstructure patches
- Compare performance & embeddings
- Visualize CNN filters and latent space

<div>
<script>
document.getElementById("marimo-frame").onload = function() {
    try {
        let iframeDoc = document.getElementById("marimo-frame").contentWindow.document;
        let marimoBadge = iframeDoc.querySelector("div.fixed.bottom-0.right-0.z-50");
        if (marimoBadge) {
            marimoBadge.style.display = "none";
            console.log("Marimo badge hidden successfully.");
        } else {
            console.log("Badge not found.");
        }
    } catch (error) {
        console.warn("Unable to modify iframe content due to CORS restrictions.");
    }
};
</script>
</div>