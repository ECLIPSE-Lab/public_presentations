---
title: |
  ML for Characterization and Processing<br>
  Lecture 7: Process Monitoring & Time-Series ML
bibliography: ref.bib
# csl: custom.csl
author:
  - name: Prof. Dr. Philipp Pelz
    affiliation: 
      - FAU Erlangen-Nürnberg
      - Institute of Micro- and Nanostructure Research
   
execute: 
  eval: true
  echo: true
format: 
    revealjs: 
        chalkboard: true
        mermaid:
            theme: forest
        # mermaid-format: png
        # scroll-view:
        #     activate: true
        #     snap: mandatory
        #     layout: full 
        width: 1920
        height: 1080
        menu:
            side: right
            width: wide 
        template-partials:
            - title-slide.html
        css: custom.css
        theme: custom.scss
        slide-number: c/t    
        logo: "eclipse_logo_small.png"          
        highlight-style: a11y
        incremental: true 
        background-transition: fade
        footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - ML for Characterization and Processing"
---
 
 

## Welcome

### Week 7 — Process Monitoring & Time-Series Machine Learning

**Goals for today:**

- Understand why materials processing produces time-series  
- Explore process monitoring modalities  
- Learn classical time-series models (ARIMA, HMMs)  
- Introduce ML models for sequences (RF, RNNs)  
- Connect theory to AM, SPS, rolling & heat treatment  

---

## Outline

1. Why time-series matter  
2. Process monitoring data types  
3. Classical time-series models  
4. ML approaches (RF, RNNs)  
5. Applications in real processes  
6. Summary  

---

## 1. Why Time-Series Matter

Materials processing is **dynamic**:

- Heat flows  
- Phase transformations  
- Stress accumulation  
- Melt pool instabilities  
- Solidification fronts  
- SPS current & displacement profiles  

Snapshots can’t describe:

- Kinetics  
- Transitions  
- Regime shifts  
- Time-dependent defects  

**Time carries hidden state information.**

---

## Processing as a Dynamical System

Examples:

- Heat-treatment ramps  
- AM melt pool stability  
- Aging/tempering curves  
- Rolling load vs time  
- SPS densification cycles  

ML must handle:

- Trends  
- Cycles  
- Abrupt changes  
- Long-term dependencies  

---

## 2. Process Monitoring Data Types

### Temperature Cycles

During:

- Heat treatment  
- Tempering  
- Aging  
- Austenitization  

Sensors record:

- Temperature  
- Ramp rate  
- Soak durations  
- Cool-down rate  

Encoding:

- Transformation kinetics  
- Grain growth behavior  

---

### AM Melt Pool Monitoring

Sensors:

- Photodiodes  
- Near-IR cameras  
- High-speed imaging  
- Layer-wise snapshots  

Observables:

- Melt pool intensity  
- Width & depth  
- Spatter  
- Keyhole onset  

These are **rich time-series**.

---

### SPS (Spark Plasma Sintering)

Logs include:

- Temperature  
- Pressure  
- Punch displacement  
- Current & voltage  
- Heating rate  

Patterns reveal:

- Densification onset  
- Abnormal heating  
- Mechanical instability  

---

### Rolling, Forging, Forming

Sensors:

- Force  
- Torque  
- Vibrations  
- Spindle speed  
- Thickness logs  

Uses:

- Defect detection  
- Load prediction  
- Process stability analysis  

---

## 3. Classical Time-Series Models

### ARIMA (Autoregressive Integrated Moving Average)

Captures:

- Trends  
- Autocorrelation  
- Seasonal patterns  
- Noise  

Good for:

- Furnace temperature control  
- SPS heating curves  
- Rolling load forecasting  

Intuition:

AR = depends on past  
I = removes trend  
MA = depends on past noise  

---

### Hidden Markov Models (HMMs)

Model:

- Observed signals  
- Hidden process states  
- Probabilities of transitions  

States might be:

- “Stable melt pool”  
- “Keyholing”  
- “Porosity risk”  
- “Steady densification”  

HMMs infer hidden regimes from noisy sensor data.

---

## 4. ML Approaches for Time-Series

### Random Forests for Sliding Windows

Steps:

1. Extract short windows  
2. Compute summary stats (mean, slope, variance)  
3. Optionally include FFT features  
4. Train RF regressor/classifier  

Strengths:

- Works with small datasets  
- Interpretable  
- Robust to outliers  

---

### Introduction to RNNs (Recurrent Neural Networks)

RNN intuition:

- Model “remembers” the past  
- Captures sequence dynamics  
- Ideal for complex temporal signals  

Variants:

- LSTM  
- GRU  

Explain conceptually only:
RNN state evolves as new timesteps arrive, enabling long-term dependency modeling.

---

### When to Use Which Model

**ARIMA:** smooth trends, furnace cycles  
**HMM:** regime changes, melt pool states  
**Random Forest:** small datasets, engineering features  
**RNNs:** complex, noisy processes with long dependencies  

---

## Example Workflows

### AM Melt Pool
Inputs:

- Melt pool width  
- Laser power  
- Intensity profile  

Outputs:

- Defect prediction  
- Keyhole detection  
- Instability alerts  

---

### SPS Densification
Inputs:

- Pressure  
- Displacement  
- Temperature  

Outputs:

- Density prediction  
- Cycle optimization  
- Anomaly detection  

---

### Heat Treatment
Inputs:

- Time–temperature curve  

Outputs:

- Hardness  
- Grain size  
- Detection of incorrect ramps  

---

## Mini Demo (Conceptual)

How you might process a time-series in Python:

**PYTHONHERE**

(e.g., windowing a sequence, feature extraction, running through RF or RNN)

---

## 5. Applications in Real Processes

### Additive Manufacturing (AM)

- Real-time defect detection  
- Predicting porosity formation  
- Stability monitoring  

### SPS

- Detecting abnormal densification  
- Predicting final density  

### Heat Treatment

- Predicting mechanical properties  
- Detecting furnace deviations  

### Rolling / Forging

- Predicting rolling force  
- Vibration anomaly detection  

---

## 6. Summary

### Key insights:

- Processing is temporal → ML must model sequences  
- Temperature cycles, melt pool data, SPS logs are prime ML targets  
- ARIMA and HMMs are still extremely valuable  
- Random forests handle low-data regimes well  
- RNNs model complex, long-range temporal patterns  
- Time-series ML enables prediction, optimization, and anomaly detection  

Next week:  
**Week 8 — Multi-Modal Fusion: Images + Spectra + Processing Data**

---

## Questions?

Use the chalkboard!


<div>
<script>
document.getElementById("marimo-frame").onload = function() {
    try {
        let iframeDoc = document.getElementById("marimo-frame").contentWindow.document;
        let marimoBadge = iframeDoc.querySelector("div.fixed.bottom-0.right-0.z-50");
        if (marimoBadge) {
            marimoBadge.style.display = "none";
            console.log("Marimo badge hidden successfully.");
        } else {
            console.log("Badge not found.");
        }
    } catch (error) {
        console.warn("Unable to modify iframe content due to CORS restrictions.");
    }
};
</script>
</div>