---
title: |
  Materials Genomics<br>
  Lecture 10: Regression on Crystal Data
bibliography: ref.bib
# csl: custom.csl
author:
  - name: Prof. Dr. Philipp Pelz
    affiliation: 
      - FAU Erlangen-Nürnberg
      - Institute of Micro- and Nanostructure Research
   
execute: 
  eval: true
  echo: true
format: 
    revealjs: 
        chalkboard: true
        mermaid:
            theme: forest
        # mermaid-format: png
        # scroll-view:
        #     activate: true
        #     snap: mandatory
        #     layout: full 
        width: 1920
        height: 1080
        menu:
            side: right
            width: wide 
        template-partials:
            - title-slide.html
        css: custom.css
        theme: custom.scss
        slide-number: c/t    
        logo: "eclipse_logo_small.png"          
        highlight-style: a11y
        incremental: true 
        background-transition: fade
        footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Materials Genomics"
---
 

## Welcome

### Week 10 — Regression on Crystal Data

**Goals for today:**

- Understand regression tasks on crystal structures (band gaps, hardness, elastic moduli)  
- See how different structure representations affect model performance  
- Compare classical descriptors, local environment descriptors, and graph-based models  
- Conceptually benchmark Random Forest, Gaussian Process Regression, and CGCNN on a small dataset  

---

## Outline

1. Property prediction tasks on crystal data  
2. Input representations (feature families)  
3. Models: RF, GPR, CGCNN  
4. Benchmarking strategy  
5. Exercise: small benchmark on crystal data  
6. Summary  

---

## 1. Property Prediction Tasks

We focus on **regression tasks**:

- Predicting **band gaps**  
- Predicting **hardness** (e.g. Vickers hardness, bulk/shear moduli)  
- Predicting **elastic properties** (bulk modulus, shear modulus, Young’s modulus)  

Why these?

- They are central design targets in materials science  
- Data exists in DFT databases and experimental compilations  
- They span:
  - Electronic properties  
  - Mechanical properties  

---

## Input → Output

Given a crystal structure:

- Lattice + atomic positions + elements  

Goal:

- Map structure → property  

Examples:

- \(E_g(\text{structure})\) for band gap  
- \(K, G, E\) for elastic moduli  
- Hardness \(H_V\) from composition + structure  

We will vary:

- How we represent the input  
- What ML model we use  

---

## 2. Representation Families

We compare three broad families:

1. **Classical descriptors**  
   - Magpie-style compositional + simple structural features  

2. **Local environment / SOAP-type descriptors**  
   - SOAP vectors + pooling to global representation  

3. **Graph-based representations**  
   - Crystal graphs (CGCNN-style)  

Each trades off:

- Complexity  
- Data requirements  
- Interpretability  

---

## 2.1 Classical Descriptors

Input:  

- Composition (formula) + optional simple structure features  

Features:

- Stoichiometric features (number of elements, composition entropy…)  
- Elemental property stats (mean/variance of electronegativity, radius…)  
- Structural scalars (volume per atom, density, packing fraction)  

Pros:

- Fast to compute  
- Low-dimensional  
- Works with small datasets  
- Highly interpretable  

Cons:

- Ignores detailed geometry  
- Limited sensitivity to subtle structural variations  

---

## 2.2 Local Environment / SOAP-Type Global Descriptors

Idea:

- For each atom:
  - Compute a local descriptor (SOAP, symmetry functions, etc.)  
- Pool over atoms:
  - Mean / sum / histogram of local descriptors  

Global representation:

- Captures distribution of local environments  
- More geometry-aware than pure composition features  

Pros:

- Encodes local bonding & symmetry  
- Good for mechanical/energetic properties  

Cons:

- More expensive  
- Higher-dimensional descriptors  
- Somewhat less intuitive  

---

## 2.3 Graph-Based Representations (CGCNN-Style)

Crystal graph:

- **Nodes**: atoms (with elemental features)  
- **Edges**: neighbor relationships (distance-based, with PBC)  

Graph Neural Network:

- Message-passing updates node embeddings  
- Global pooling yields crystal embedding  

Pros:

- Very flexible, end-to-end learned features  
- Strong performance on many properties  
- Naturally handles complicated structures  

Cons:

- More complex models  
- Requires more data and care with training  
- Less transparent feature interpretation  

---

## Representation Trade-offs

| Representation     | Pros                           | Cons                         |
|--------------------|--------------------------------|------------------------------|
| Classical          | Simple, fast, interpretable    | Limited structural detail    |
| Local env / SOAP   | Rich local geometry            | High dimensional, more costly|
| Graph-based (GNNs) | End-to-end, very expressive    | Needs more data & tuning     |

We’ll now pair each representation with an appropriate regression model.

---

## 3. Models: RF, GPR, CGCNN

We’ll conceptually benchmark three models:

1. **Random Forest (RF)**  
2. **Gaussian Process Regression (GPR)**  
3. **CGCNN** (graph neural network)  

Each lives in a different corner of the model complexity universe.

---

## 3.1 Random Forest Regression

Random Forest:

- Ensemble of decision trees  
- Each tree trained on a bootstrap sample of data  
- Final prediction = average of trees  

Pros:

- Handles nonlinear relationships  
- Robust, relatively low-tuning  
- Works well with mixed-scale features  
- Good baseline for classical descriptors  

Cons:

- Not inherently uncertainty-aware (without extra tricks)  
- Harder to extrapolate outside training domain  
- Trees do not exploit structure beyond provided features  

Best suited for:

- Classical compositional + structural descriptors  
- Medium-sized datasets  

---

## 3.2 Gaussian Process Regression (GPR)

Gaussian Process:

- Probabilistic regression model  
- Defines a prior over functions  
- Predictions come with mean and variance (uncertainty)  

Pros:

- Built-in uncertainty quantification  
- Can work very well on small datasets  
- Good for active learning and Bayesian optimization  

Cons:

- Scales poorly with very large datasets (O(N³))  
- Requires specifying kernel (distance measure in feature space)  
- High dimensional features can be challenging  

Best suited for:

- Moderate-size datasets  
- Handcrafted feature spaces (e.g. SOAP, Magpie)  
- Tasks where uncertainty matters  

---

## 3.3 CGCNN (Graph Neural Network)

Crystal Graph Convolutional Neural Network:

- Input: crystal graph (nodes, edges, PBC)  
- Several graph convolution (message-passing) layers  
- Global pooling to obtain crystal embedding  
- MLP head for property prediction  

Pros:

- Learns its own structural features  
- Strong performance on many benchmarks (e.g., formation energy, band gap)  
- Naturally incorporates geometric information  

Cons:

- Requires more data and training time  
- Many hyperparameters  
- Harder to interpret  

Best suited for:

- Larger datasets  
- When structure matters strongly  
- When we want an end-to-end differentiable model  

---

## 4. Benchmarking Strategy

We want to compare:

- RF with classical descriptors  
- GPR with a richer descriptor (e.g. SOAP or Magpie)  
- CGCNN with graph representation  

on the same **dataset** and **train/test split**.

---

## Step 1 — Choose a Property & Dataset

Examples:

- Band gap (DFT or experimental)  
- Bulk modulus (from DFT elastic data)  
- Shear modulus  
- Possibly Vickers hardness (from experimental compilation)  

Data source:

- Materials Project (via API)  
- Or a curated teaching dataset  

**PYTHONHERE**

Conceptual data:

- `structure` or `formula`  
- `target_property`  

---

## Step 2 — Create Representations

### For RF:
- Compute classical descriptors (Magpie + structural scalar features)  

### For GPR:
- Either:
  - Use the same classical descriptors  
  - Or use local/ SOAP-based global descriptors  

### For CGCNN:
- Build crystal graphs:
  - Node features (element embeddings)  
  - Edge features (distance basis)  
  - Neighbor lists with PBC  

**PYTHONHERE**

---

## Step 3 — Define Consistent Splits

Avoid data leakage:

- Use the same train/validation/test splits across models  
- Typical split:
  - 70% train  
  - 15% validation  
  - 15% test  

Optionally:

- Compositional split (train and test on different chemical systems)  
- To test generalization across chemistry  

---

## Step 4 — Train & Evaluate Models

### Random Forest:

- Train on classical descriptors  
- Evaluate on test set  
- Metrics:
  - MAE, RMSE, R²  

### GPR:

- Train on chosen features  
- Compare predictive performance  
- Also inspect predicted uncertainty  

### CGCNN:

- Train on graphs  
- Tune hyperparameters (layers, hidden units, learning rate)  
- Evaluate on test set  

**PYTHONHERE**

(Conceptual training/evaluation codes.)

---

## Step 5 — Compare Results

Compare:

- MAE, RMSE, R² for each model  
- Computational cost:
  - Feature computation time  
  - Training time  
  - 
- Data efficiency:
  - How performance degrades when using fewer training samples  

Ask:

- Does CGCNN outperform classical RF?  
- Does GPR perform best on small data?  
- Which representation/model provides the best accuracy vs cost trade-off?  

---

## 5. Exercise: Benchmark RF, GPR, CGCNN on a Small Dataset

Students won’t code everything live, but they should understand the pipeline.

---

### Exercise Outline

1. Provide a small dataset (e.g., 200–500 materials) with:
   - Crystal structures  
   - Band gap or bulk modulus as target  

2. Precomputed:
   - Classical descriptors  
   - SOAP descriptors (optional)  
   - Graphs (for CGCNN)  

3. Students (individually or in groups) will:
   - Train RF on classical descriptors  
   - Train GPR on same features (or SOAP)  
   - Train CGCNN using provided template  

**PYTHONHERE**

---

### Analysis Tasks

Students should:

- Plot predicted vs actual values for each model  
- Report MAE, RMSE for the test set  
- Discuss:
  - Underfitting vs overfitting  
  - Which representation seems to capture structure best  
  - Which model is most robust on small data  

Optional:

- Investigate feature importance for RF  
- Inspect GPR uncertainties (do high-uncertainty predictions have larger errors?)  

---

## 6. Summary

**Today you learned:**

- How to frame regression tasks on crystal structures (band gaps, hardness, elastic moduli)  
- Different representation families:
  - Classical (Magpie/structural)  
  - Local environment (SOAP-style)  
  - Graph-based (CGCNN)  
- How RF, GPR, and CGCNN occupy different niches in the model landscape  
- How to benchmark multiple models fairly on the same dataset  

Next week:  
**Week 11 — Uncertainty & Reliability in Materials ML**  
(Calibration, confidence intervals, and using uncertainty for screening.)

---

## Questions?

Use the chalkboard!

<div>
<script>
document.getElementById("marimo-frame").onload = function() {
    try {
        let iframeDoc = document.getElementById("marimo-frame").contentWindow.document;
        let marimoBadge = iframeDoc.querySelector("div.fixed.bottom-0.right-0.z-50");
        if (marimoBadge) {
            marimoBadge.style.display = "none";
            console.log("Marimo badge hidden successfully.");
        } else {
            console.log("Badge not found.");
        }
    } catch (error) {
        console.warn("Unable to modify iframe content due to CORS restrictions.");
    }
};
</script>
</div>