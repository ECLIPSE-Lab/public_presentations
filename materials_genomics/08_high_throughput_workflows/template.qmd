---
title: |
  Materials Genomics<br>
  Lecture 8: High-Throughput Workflows
bibliography: ref.bib
# csl: custom.csl
author:
  - name: Prof. Dr. Philipp Pelz
    affiliation: 
      - FAU Erlangen-Nürnberg
      - Institute of Micro- and Nanostructure Research
   
execute: 
  eval: true
  echo: true
format: 
    revealjs: 
        chalkboard: true
        mermaid:
            theme: forest
        # mermaid-format: png
        # scroll-view:
        #     activate: true
        #     snap: mandatory
        #     layout: full 
        width: 1920
        height: 1080
        menu:
            side: right
            width: wide 
        template-partials:
            - title-slide.html
        css: custom.css
        theme: custom.scss
        slide-number: c/t    
        logo: "eclipse_logo_small.png"          
        highlight-style: a11y
        incremental: true 
        background-transition: fade
        footer: "©Philipp Pelz - FAU Erlangen-Nürnberg - Materials Genomics"
---
 
 

## Welcome

### Week 8 — High-Throughput Workflows

**Goals for today:**

- Understand what “high-throughput” means in computational materials science  
- Learn the roles of pymatgen, custodian, FireWorks, and atomate  
- See how automated workflows generate data for surrogate ML models  
- Conceptually design and (optionally) “run” a small FireWorks workflow  

---

## Outline

1. Why high-throughput?  
2. Building blocks: pymatgen & custodian  
3. Workflow engines: FireWorks & atomate  
4. From workflows to surrogate model datasets  
5. Exercise: a small FireWorks-style workflow  
6. Summary  

---

## 1. Why High-Throughput?

Single DFT calculation:

- Gives detailed information for *one* structure  

Materials Genomics:

- Needs data for **thousands** of structures  
- Needs consistency and reproducibility  
- Needs automation and error handling  

High-throughput:

- Run standardized workflows on large sets of materials  
- Store results in structured databases  
- Feed ML models with clean, comparable data  

---

## The Goal of High-Throughput

Transform:

- “One structure, one manual input file”  
into:

- “Thousands of structures, standardized workflows, reliable logs”  

Outputs:

- Formation energies  
- Relaxed structures  
- Band gaps & DOS  
- Elastic tensors  
- Many more properties  

All suitable as training data for ML surrogates.

---

## 2. Building Blocks: pymatgen & custodian

### pymatgen (Python Materials Genomics)

pymatgen provides:

- Data structures for:
  - Structures, lattices, sites  
  - Band structures, DOS  
- Tools for:
  - Symmetry analysis  
  - Featurization  
  - Input/output for many DFT codes  
- Interface to Materials Project API  

It’s the **data and IO layer** for many workflows.

---

## What pymatgen Does in Workflows

- Reads/creates CIF and POSCAR files  
- Generates:
- 
  - k-point meshes  
  - Input parameter sets  
- Parses:
- 
  - DFT output files  
  - Errors and final structures  
- Standardizes structures for databases  

pymatgen = glue between DFT codes and automation.

---

## custodian: The Error Handler

custodian:

- Monitors running calculations  
- Detects known error patterns  
- Applies fixes and restarts calculations  

Examples:

- SCF convergence failures  
- Insufficient k-point density  
- Memory errors  
- Smearing parameter problems  

In high-throughput:

- Manual debugging is impossible  
- custodian automates “DFT babysitting”  

---

## 3. Workflow Engines: FireWorks & atomate

### FireWorks

FireWorks is a **workflow manager**:

- Defines tasks (FireWorks)  
- Connects them into workflows  
- Manages execution on clusters / queues  
- Restarts failed jobs  
- Stores execution history  

Abstractions:

- Firework = a single job (e.g., run VASP relaxation)  
- Workflow = DAG of FireWorks  

---

## Why FireWorks?

Advantages:

- Scales to thousands of jobs  
- Handles dependencies between steps  
- Supports multiple queues and clusters  
- Keeps a record of:
  - What was run  
  - Inputs & outputs  
  - Status (completed, failed, defused)  

FireWorks = the “operating system” for your high-throughput calculations.

---

## atomate: Pre-Built Workflows

atomate:

- Library built on pymatgen + FireWorks + custodian  
- Provides ready-made workflows for:
  - Structure optimization  
  - Static energy calculations  
  - Band structure & DOS  
  - Elastic constants  
  - Dielectric tensors  

Instead of building everything from scratch:
- Use atomate’s workflow templates  
- Customize if needed  

---

## Typical atomate Workflow

Example: “Optimize structure and compute band structure”

Includes:

1. Structure relaxation  
2. Static energy calculation  
3. Band structure along high-symmetry path  
4. DOS calculation  

Each step:
- A Firework with DFT input gen (pymatgen) + error handling (custodian)  

---

## 4. From Workflows to Surrogate Model Datasets

High-throughput workflows produce:

- Consistent DFT results for many materials  
- Stored in MongoDB / DB or exported as JSON/CSV  

These data become:

- Training labels \(y\) for ML models  
- Combined with descriptors \(X\) (Magpie, SOAP, graphs…)  

Thus pipeline is:

1. Structure library (CIFs, prototypes, Materials Project)  
2. High-throughput workflow runs (DFT + automation)  
3. Clean database of properties  
4. Featurization (matminer, graph featurizers, SOAP, etc.)  
5. ML surrogate training & validation  

---

## Data Quality & Consistency

High-throughput requires:

- Standard input settings (functional, cutoff, k-mesh)  
- Standard error-handling strategies  
- Standard post-processing (e.g., hull construction)  

ML surrogates assume:

- Consistent data distribution  
- No hidden changes in calculation setup  

Workflows enforce this consistency.

---

## 5. Exercise: Small FireWorks-Style Workflow (Conceptual)

Goal:
- Show how a simple workflow might look  
- Students don’t need a real cluster; can simulate locally or just conceptually  

---

## Step 1 — Define a Simple Workflow

Example workflow:

1. Relax structure with DFT  
2. Run static energy calculation  
3. Parse results and store them  

Nodes:
- FW1: Relaxation  
- FW2: Static energy (depends on FW1)  

---

## Step 2 — Define FireWorks

Each Firework has:

- A “task” or list of tasks  
- Parameters (structure, INCAR, KPOINTS, etc.)  
- Optional dependencies  

Conceptual representation:

**PYTHONHERE**

- Create a Firework object for relaxation  
- Create a Firework object for static calculation  
- Combine them into a Workflow  

---

## Step 3 — Launch Workflow

Under real conditions:

- FireWorks uses a launchpad (MongoDB backend)  
- `rlaunch` / `qlaunch` commands start jobs  
- Jobs are submitted to queue (SLURM, PBS, etc.)  

Conceptually:

- FireWorks picks the first ready Firework (relaxation)  
- Runs it on available resource  
- After completion, static job is automatically triggered  

---

## Step 4 — Parse & Store Results

After both steps:

- Parse:
  - Relaxed structure  
  - Total energy  
  - Band gap (if relevant)  

Store in:

- MongoDB collection  
- Or CSV / JSON for teaching purposes  

These become:

- Data rows for ML regression  
- Example entries in a mini “materials database”  

---

## Optional: Simulation Without Real DFT

If no DFT:

- Mock the tasks:
  - Pretend to “run” DFT  
  - Instead, generate random but structured outputs  
- Show how FireWorks orchestrates tasks and data flow  

**PYTHONHERE**

This teaches:
- Workflow logic  
- Dependency management  
- Data logging  

without requiring an HPC cluster.

---

## Why This Exercise Is Useful

Students see:

- How “thousands of DFT calculations” are actually orchestrated  
- How pymatgen/custodian/FireWorks/atomate interact  
- How high-throughput == *system + workflow* rather than “many manual runs”  
- The direct path from automation → ML-ready datasets  

---

## 6. Summary

**Today you learned:**

- High-throughput workflows are essential for Materials Genomics  
- pymatgen handles structures and IO  
- custodian automates error handling  
- FireWorks manages job dependencies and execution  
- atomate provides ready-made DFT workflows  
- These workflows generate large, consistent datasets for ML surrogates  

Next week:  
**Week 9 — From High-Throughput Data to Surrogate Models**  
(Data splits, target leakage, and building robust property predictors.)

---

## Questions?

Use the chalkboard!


<div>
<script>
document.getElementById("marimo-frame").onload = function() {
    try {
        let iframeDoc = document.getElementById("marimo-frame").contentWindow.document;
        let marimoBadge = iframeDoc.querySelector("div.fixed.bottom-0.right-0.z-50");
        if (marimoBadge) {
            marimoBadge.style.display = "none";
            console.log("Marimo badge hidden successfully.");
        } else {
            console.log("Badge not found.");
        }
    } catch (error) {
        console.warn("Unable to modify iframe content due to CORS restrictions.");
    }
};
</script>
</div>